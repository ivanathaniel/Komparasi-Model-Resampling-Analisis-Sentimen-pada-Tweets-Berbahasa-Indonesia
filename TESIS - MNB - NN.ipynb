{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_zAi1UaKdLpz",
    "outputId": "ef5975ca-795d-4324-e4b3-b5eff549bbdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "8URXdSl5dRS4",
    "outputId": "f9793066-a2fd-4fce-9423-0f6fe5bd94c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sastrawi\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
      "\r",
      "\u001b[K     |█▋                              | 10kB 16.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 20kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 30kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 40kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 51kB 1.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 61kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 71kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 81kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 92kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 102kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 112kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 122kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 133kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 143kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 153kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 163kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 174kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 184kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 194kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 204kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 215kB 2.8MB/s \n",
      "\u001b[?25hInstalling collected packages: sastrawi\n",
      "Successfully installed sastrawi-1.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zOkb4u1dS8M"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import re\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, InputLayer, Embedding, Dense, Add, Concatenate, ZeroPadding1D, Dropout, SpatialDropout1D, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPool1D, AveragePooling1D, BatchNormalization, Flatten, SimpleRNN, Bidirectional, concatenate\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop, Nadam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models.wrappers import FastText\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJgvTcr-dUeG"
   },
   "outputs": [],
   "source": [
    "maranatha_df = pd.read_excel('MARANATHAv2_filtered_index.xls')\n",
    "marnath_df = pd.read_excel('MARNATHv2_filtered_index.xls')\n",
    "marnat_df = pd.read_excel('MARNATv2_filtered_index.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "aeT22yJodUrM",
    "outputId": "398894c0-1032-4e0f-bcba-b204c4dad14b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-30 17:41:29+00:00</td>\n",
       "      <td>Ini ketika di Maranatha Bandung bulan Juli kem...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-30 17:09:36+00:00</td>\n",
       "      <td>yakin anak maranatha tidak ada yang main twitter</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-30 16:20:08+00:00</td>\n",
       "      <td>Ini waktu pertama temu sama di angkringan mara...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-30 15:52:50+00:00</td>\n",
       "      <td>telkom unpar maranatha tau itu saja bandung wkwkw</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-30 14:25:56+00:00</td>\n",
       "      <td>mohon maaf baru balas. . ini pergelaran juli l...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362</th>\n",
       "      <td>2018-01-13 04:31:00+00:00</td>\n",
       "      <td>Dan hasil keluar sama marnat dan dua aku terim...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>2018-01-10 15:00:03+00:00</td>\n",
       "      <td>Bandung tau aku Unpar hi / arsitektur Unisba i...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>2018-01-07 15:13:59+00:00</td>\n",
       "      <td>untuk yang mau ambil hukum di unpar, hukum unp...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>2018-01-07 07:42:38+00:00</td>\n",
       "      <td>Semoga jadi dosen di marnat supaya tidak enak</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>2018-01-05 14:09:51+00:00</td>\n",
       "      <td>di foto ini saja , berasa kesan anak manajemen...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5367 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime  ... Sentiment\n",
       "0     2019-12-30 17:41:29+00:00  ...   Neutral\n",
       "1     2019-12-30 17:09:36+00:00  ...   Neutral\n",
       "2     2019-12-30 16:20:08+00:00  ...   Neutral\n",
       "3     2019-12-30 15:52:50+00:00  ...  Positive\n",
       "4     2019-12-30 14:25:56+00:00  ...  Positive\n",
       "...                         ...  ...       ...\n",
       "5362  2018-01-13 04:31:00+00:00  ...   Neutral\n",
       "5363  2018-01-10 15:00:03+00:00  ...  Positive\n",
       "5364  2018-01-07 15:13:59+00:00  ...   Neutral\n",
       "5365  2018-01-07 07:42:38+00:00  ...   Neutral\n",
       "5366  2018-01-05 14:09:51+00:00  ...   Neutral\n",
       "\n",
       "[5367 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [maranatha_df, marnath_df, marnat_df]\n",
    "join_df = pd.concat(data)\n",
    "join_df.drop_duplicates()\n",
    "join_df.reset_index(drop=True, inplace=True)\n",
    "join_df.dropna(inplace=True)\n",
    "join_df.sort_values(by='Datetime', ascending=False)\n",
    "join_df['Sentiment'] = join_df.Sentiment.map({9:0, 0:0, 1:1, -1:-1})\n",
    "join_df['Sentiment'] = join_df.Sentiment.map({0:'Neutral', 1:'Positive', -1:'Negative'})\n",
    "join_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUI23Oa3dWL4"
   },
   "outputs": [],
   "source": [
    "factorystemmer = StemmerFactory()\n",
    "stemmer = factorystemmer.create_stemmer()\n",
    "\n",
    "factorystop = StopWordRemoverFactory()\n",
    "stopwords = factorystop.create_stop_word_remover()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() #ubah text menjadi lower case\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text) #hapus tanda baca\n",
    "    text = re.sub('[‘’“”…]', '', text) #hapus tanda baca lain\n",
    "    text = re.sub('[0-9]+', '', text) #hapus angka\n",
    "    text = re.sub('(?:a{0,2}h{1,2}a{0,2}){2,}h?', '', text) #hapus haha-ahah pattern\n",
    "    text = re.sub('(?:e{0,2}h{1,2}e{0,2}){2,}h?', '', text) #hapus hehe-eheh pattern\n",
    "    text = re.sub('(?:i{0,2}h{1,2}i{0,2}){2,}h?', '', text) #hapus hihi-ihih pattern\n",
    "    text = re.sub(r'\\b[wk]*(?:wk|kw)[wk]*\\b', '', text) #hapus wkwk-kwkw pattern\n",
    "    text = re.sub(r'\\s—\\s', '', text) #hapus spasi berlebih\n",
    "    text = re.sub(r'http\\S+', '', text) #hapus link\n",
    "    text = ''.join([i for i in text if not i.isdigit()]) # Remove digits\n",
    "    #text = re.sub('maranatha', '', text) #hapus keyword input maranatha\n",
    "    #text = re.sub('marnath', '', text) #hapus keyword input marnath\n",
    "    #text = re.sub('marnat', '', text) #hapus keyword input marnat\n",
    "    text = stemmer.stem(text) #stemming\n",
    "    text = stopwords.remove(text) #hapus stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "7WVZoXNidYCE",
    "outputId": "29e5fa21-87e6-4ac9-c28d-d03e72efaa5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 52s, sys: 67.9 ms, total: 6min 52s\n",
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text_cleaner = []\n",
    "\n",
    "for text in join_df.Text:\n",
    "    text_cleaner.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "x51IRcyPdZkJ",
    "outputId": "acf0dda2-77e9-436b-84e6-081a0881f5d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>New_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-30 17:41:29+00:00</td>\n",
       "      <td>Ini ketika di Maranatha Bandung bulan Juli kem...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>ketika maranatha bandung bulan juli kemarin di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-30 17:09:36+00:00</td>\n",
       "      <td>yakin anak maranatha tidak ada yang main twitter</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>yakin anak maranatha ada main twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-30 16:20:08+00:00</td>\n",
       "      <td>Ini waktu pertama temu sama di angkringan mara...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>waktu pertama temu sama angkring maranatha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-30 15:52:50+00:00</td>\n",
       "      <td>telkom unpar maranatha tau itu saja bandung wkwkw</td>\n",
       "      <td>Positive</td>\n",
       "      <td>telkom unpar maranatha tau saja bandung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-30 14:25:56+00:00</td>\n",
       "      <td>mohon maaf baru balas. . ini pergelaran juli l...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>mohon maaf baru balas gelar juli lalu gelar wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362</th>\n",
       "      <td>2018-01-13 04:31:00+00:00</td>\n",
       "      <td>Dan hasil keluar sama marnat dan dua aku terim...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>hasil keluar sama marnat dua aku terima aku ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>2018-01-10 15:00:03+00:00</td>\n",
       "      <td>Bandung tau aku Unpar hi / arsitektur Unisba i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>bandung tau aku unpar hi arsitektur unisba ilk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>2018-01-07 15:13:59+00:00</td>\n",
       "      <td>untuk yang mau ambil hukum di unpar, hukum unp...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>yang mau ambil hukum unpar hukum unpar jurus y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>2018-01-07 07:42:38+00:00</td>\n",
       "      <td>Semoga jadi dosen di marnat supaya tidak enak</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>moga jadi dosen marnat tidak enak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>2018-01-05 14:09:51+00:00</td>\n",
       "      <td>di foto ini saja , berasa kesan anak manajemen...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>foto saja asa kesan anak manajemen bisnis marn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5367 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime  ...                                           New_Text\n",
       "0     2019-12-30 17:41:29+00:00  ...  ketika maranatha bandung bulan juli kemarin di...\n",
       "1     2019-12-30 17:09:36+00:00  ...              yakin anak maranatha ada main twitter\n",
       "2     2019-12-30 16:20:08+00:00  ...         waktu pertama temu sama angkring maranatha\n",
       "3     2019-12-30 15:52:50+00:00  ...            telkom unpar maranatha tau saja bandung\n",
       "4     2019-12-30 14:25:56+00:00  ...  mohon maaf baru balas gelar juli lalu gelar wa...\n",
       "...                         ...  ...                                                ...\n",
       "5362  2018-01-13 04:31:00+00:00  ...  hasil keluar sama marnat dua aku terima aku ta...\n",
       "5363  2018-01-10 15:00:03+00:00  ...  bandung tau aku unpar hi arsitektur unisba ilk...\n",
       "5364  2018-01-07 15:13:59+00:00  ...  yang mau ambil hukum unpar hukum unpar jurus y...\n",
       "5365  2018-01-07 07:42:38+00:00  ...                  moga jadi dosen marnat tidak enak\n",
       "5366  2018-01-05 14:09:51+00:00  ...  foto saja asa kesan anak manajemen bisnis marn...\n",
       "\n",
       "[5367 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text = pd.DataFrame({'New_Text' : text_cleaner})\n",
    "clean_df = pd.concat([join_df, new_text], axis = 1)\n",
    "clean_df.replace('', np.nan, inplace=True)\n",
    "clean_df.dropna(inplace=True)\n",
    "clean_df.reset_index(drop=True, inplace=True)\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6OnWYmPXYSJ"
   },
   "outputs": [],
   "source": [
    "def clean_text_token(text):\n",
    "    text = re.sub(r'[^\\w\\d\\s]+', '', text) # Remove punctuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text) #hapus tanda baca\n",
    "    text = re.sub('[‘’“”…]', '', text) #hapus tanda baca lain\n",
    "    text = re.sub('[0-9]+', '', text) #hapus angka\n",
    "    text = re.sub('(?:a{0,2}h{1,2}a{0,2}){2,}h?', '', text) #hapus haha-ahah pattern\n",
    "    text = re.sub('(?:e{0,2}h{1,2}e{0,2}){2,}h?', '', text) #hapus hehe-eheh pattern\n",
    "    text = re.sub('(?:i{0,2}h{1,2}i{0,2}){2,}h?', '', text) #hapus hihi-ihih pattern\n",
    "    text = re.sub(r'\\b[wk]*(?:wk|kw)[wk]*\\b', '', text) #hapus wkwk-kwkw pattern\n",
    "    text = re.sub(r'\\s—\\s', '', text) #hapus spasi berlebih\n",
    "    text = re.sub(r'http\\S+', '', text) #hapus link\n",
    "    text = ''.join([i for i in text if not i.isdigit()]) # Remove digits\n",
    "    text = stemmer.stem(text) #stemming\n",
    "    text = stopwords.remove(text) #hapus stopwords\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "clean_df['Tokenize'] = clean_df['Text'].apply(lambda x: clean_text_token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "colab_type": "code",
    "id": "sByrxprExZMi",
    "outputId": "16e130ec-99e2-4468-ac7b-eca5a61bdb53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>New_Text</th>\n",
       "      <th>Tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-30 17:41:29+00:00</td>\n",
       "      <td>Ini ketika di Maranatha Bandung bulan Juli kem...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>ketika maranatha bandung bulan juli kemarin di...</td>\n",
       "      <td>[ketika, maranatha, bandung, bulan, juli, kema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-30 17:09:36+00:00</td>\n",
       "      <td>yakin anak maranatha tidak ada yang main twitter</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>yakin anak maranatha ada main twitter</td>\n",
       "      <td>[yakin, anak, maranatha, ada, main, twitter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-30 16:20:08+00:00</td>\n",
       "      <td>Ini waktu pertama temu sama di angkringan mara...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>waktu pertama temu sama angkring maranatha</td>\n",
       "      <td>[waktu, pertama, temu, sama, angkring, maranatha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-30 15:52:50+00:00</td>\n",
       "      <td>telkom unpar maranatha tau itu saja bandung wkwkw</td>\n",
       "      <td>Positive</td>\n",
       "      <td>telkom unpar maranatha tau saja bandung</td>\n",
       "      <td>[telkom, unpar, maranatha, tau, saja, bandung]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-30 14:25:56+00:00</td>\n",
       "      <td>mohon maaf baru balas. . ini pergelaran juli l...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>mohon maaf baru balas gelar juli lalu gelar wa...</td>\n",
       "      <td>[mohon, maaf, baru, balas, gelar, juli, lalu, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362</th>\n",
       "      <td>2018-01-13 04:31:00+00:00</td>\n",
       "      <td>Dan hasil keluar sama marnat dan dua aku terim...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>hasil keluar sama marnat dua aku terima aku ta...</td>\n",
       "      <td>[hasil, keluar, sama, marnat, dua, aku, terima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>2018-01-10 15:00:03+00:00</td>\n",
       "      <td>Bandung tau aku Unpar hi / arsitektur Unisba i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>bandung tau aku unpar hi arsitektur unisba ilk...</td>\n",
       "      <td>[bandung, tau, aku, unpar, hi, arsitektur, uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>2018-01-07 15:13:59+00:00</td>\n",
       "      <td>untuk yang mau ambil hukum di unpar, hukum unp...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>yang mau ambil hukum unpar hukum unpar jurus y...</td>\n",
       "      <td>[yang, mau, ambil, hukum, unpar, hukum, unpar,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>2018-01-07 07:42:38+00:00</td>\n",
       "      <td>Semoga jadi dosen di marnat supaya tidak enak</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>moga jadi dosen marnat tidak enak</td>\n",
       "      <td>[moga, jadi, dosen, marnat, tidak, enak]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>2018-01-05 14:09:51+00:00</td>\n",
       "      <td>di foto ini saja , berasa kesan anak manajemen...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>foto saja asa kesan anak manajemen bisnis marn...</td>\n",
       "      <td>[foto, saja, asa, kesan, anak, manajemen, bisn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5367 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime  ...                                           Tokenize\n",
       "0     2019-12-30 17:41:29+00:00  ...  [ketika, maranatha, bandung, bulan, juli, kema...\n",
       "1     2019-12-30 17:09:36+00:00  ...       [yakin, anak, maranatha, ada, main, twitter]\n",
       "2     2019-12-30 16:20:08+00:00  ...  [waktu, pertama, temu, sama, angkring, maranatha]\n",
       "3     2019-12-30 15:52:50+00:00  ...     [telkom, unpar, maranatha, tau, saja, bandung]\n",
       "4     2019-12-30 14:25:56+00:00  ...  [mohon, maaf, baru, balas, gelar, juli, lalu, ...\n",
       "...                         ...  ...                                                ...\n",
       "5362  2018-01-13 04:31:00+00:00  ...  [hasil, keluar, sama, marnat, dua, aku, terima...\n",
       "5363  2018-01-10 15:00:03+00:00  ...  [bandung, tau, aku, unpar, hi, arsitektur, uni...\n",
       "5364  2018-01-07 15:13:59+00:00  ...  [yang, mau, ambil, hukum, unpar, hukum, unpar,...\n",
       "5365  2018-01-07 07:42:38+00:00  ...           [moga, jadi, dosen, marnat, tidak, enak]\n",
       "5366  2018-01-05 14:09:51+00:00  ...  [foto, saja, asa, kesan, anak, manajemen, bisn...\n",
       "\n",
       "[5367 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQ_pzX-b55J0"
   },
   "outputs": [],
   "source": [
    "#clean_df.to_excel('tesis_clean_df.xls', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djA-5JGLIxwS"
   },
   "outputs": [],
   "source": [
    "data = clean_df[['New_Text', 'Sentiment', 'Tokenize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798
    },
    "colab_type": "code",
    "id": "O8eYEVA9JBeD",
    "outputId": "109dbd99-eb89-4ad6-dbcd-5fe32b5f0e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ketika maranatha bandung bulan juli kemarin di...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[ketika, maranatha, bandung, bulan, juli, kema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yakin anak maranatha ada main twitter</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[yakin, anak, maranatha, ada, main, twitter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waktu pertama temu sama angkring maranatha</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[waktu, pertama, temu, sama, angkring, maranatha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>telkom unpar maranatha tau saja bandung</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[telkom, unpar, maranatha, tau, saja, bandung]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mohon maaf baru balas gelar juli lalu gelar wa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[mohon, maaf, baru, balas, gelar, juli, lalu, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iya juga mahasiswa universitas maranatha jurus...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[iya, juga, mahasiswa, universitas, maranatha,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>regu alumni maranatha</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[regu, alumni, maranatha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unjani maranatha bhakti kencana kalau salah un...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[unjani, maranatha, bhakti, kencana, kalau, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>teman aku maranatha</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[teman, aku, maranatha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>teman aku maranatha bandung fakultas dokter gigi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[teman, aku, maranatha, bandung, fakultas, dok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yang daerah kampus maranatha enak onigiri indo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[yang, daerah, kampus, maranatha, enak, onigir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dekat maranatha</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[dekat, maranatha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pilih akhir memang mama tante aku lulus kampus...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[pilih, akhir, memang, mama, tante, aku, lulus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>unpar maranatha paling</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[unpar, maranatha, paling]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kelas sultan unpar maranatha kelas macet telko...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[kelas, sultan, unpar, maranatha, kelas, macet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>telkom unpar maranatha bus</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[telkom, unpar, maranatha, bus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hayo jangan dekat dekat maranatha bukan</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[hayo, jangan, dekat, dekat, maranatha, bukan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pempek pak raden di lemah neundeut dekat maran...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[pempek, pak, raden, di, lemah, neundeut, deka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>foto sama terima beasiswa osc itenas maranatha...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[foto, sama, terima, beasiswa, osc, itenas, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jalan terus buah batu bojong soang baru lampu ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[jalan, terus, buah, batu, bojong, soang, baru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>maranatha mahal banyak cina kata cantik cantik...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[maranatha, mahal, banyak, cina, kata, cantik,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bonus totebag maranatha teh gelas karet nasi k...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bonus, totebag, maranatha, teh, gelas, karet,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kemarin baru buka depan maranatha</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[kemarin, baru, buka, depan, maranatha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bapak dulu kuliah maranatha ajar agama kristen...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[bapak, dulu, kuliah, maranatha, ajar, agama, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jangan kuliah maranatha kalau bukan orang cina</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[jangan, kuliah, maranatha, kalau, bukan, oran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             New_Text  ...                                           Tokenize\n",
       "0   ketika maranatha bandung bulan juli kemarin di...  ...  [ketika, maranatha, bandung, bulan, juli, kema...\n",
       "1               yakin anak maranatha ada main twitter  ...       [yakin, anak, maranatha, ada, main, twitter]\n",
       "2          waktu pertama temu sama angkring maranatha  ...  [waktu, pertama, temu, sama, angkring, maranatha]\n",
       "3             telkom unpar maranatha tau saja bandung  ...     [telkom, unpar, maranatha, tau, saja, bandung]\n",
       "4   mohon maaf baru balas gelar juli lalu gelar wa...  ...  [mohon, maaf, baru, balas, gelar, juli, lalu, ...\n",
       "5   iya juga mahasiswa universitas maranatha jurus...  ...  [iya, juga, mahasiswa, universitas, maranatha,...\n",
       "6                               regu alumni maranatha  ...                          [regu, alumni, maranatha]\n",
       "7   unjani maranatha bhakti kencana kalau salah un...  ...  [unjani, maranatha, bhakti, kencana, kalau, sa...\n",
       "8                                 teman aku maranatha  ...                            [teman, aku, maranatha]\n",
       "9    teman aku maranatha bandung fakultas dokter gigi  ...  [teman, aku, maranatha, bandung, fakultas, dok...\n",
       "10  yang daerah kampus maranatha enak onigiri indo...  ...  [yang, daerah, kampus, maranatha, enak, onigir...\n",
       "11                                    dekat maranatha  ...                                 [dekat, maranatha]\n",
       "12  pilih akhir memang mama tante aku lulus kampus...  ...  [pilih, akhir, memang, mama, tante, aku, lulus...\n",
       "13                             unpar maranatha paling  ...                         [unpar, maranatha, paling]\n",
       "14  kelas sultan unpar maranatha kelas macet telko...  ...  [kelas, sultan, unpar, maranatha, kelas, macet...\n",
       "15                         telkom unpar maranatha bus  ...                    [telkom, unpar, maranatha, bus]\n",
       "16            hayo jangan dekat dekat maranatha bukan  ...     [hayo, jangan, dekat, dekat, maranatha, bukan]\n",
       "17  pempek pak raden di lemah neundeut dekat maran...  ...  [pempek, pak, raden, di, lemah, neundeut, deka...\n",
       "18  foto sama terima beasiswa osc itenas maranatha...  ...  [foto, sama, terima, beasiswa, osc, itenas, ma...\n",
       "19  jalan terus buah batu bojong soang baru lampu ...  ...  [jalan, terus, buah, batu, bojong, soang, baru...\n",
       "20  maranatha mahal banyak cina kata cantik cantik...  ...  [maranatha, mahal, banyak, cina, kata, cantik,...\n",
       "21  bonus totebag maranatha teh gelas karet nasi k...  ...  [bonus, totebag, maranatha, teh, gelas, karet,...\n",
       "22                  kemarin baru buka depan maranatha  ...            [kemarin, baru, buka, depan, maranatha]\n",
       "23  bapak dulu kuliah maranatha ajar agama kristen...  ...  [bapak, dulu, kuliah, maranatha, ajar, agama, ...\n",
       "24     jangan kuliah maranatha kalau bukan orang cina  ...  [jangan, kuliah, maranatha, kalau, bukan, oran...\n",
       "\n",
       "[25 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nu8l3n2yQeN5"
   },
   "source": [
    "### **Multinomial Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RlRB6S04dcd5"
   },
   "outputs": [],
   "source": [
    "tvec3 = TfidfVectorizer(ngram_range=(1, 3)) #tfidf trigram\n",
    "cvec3 = CountVectorizer(ngram_range=(1, 3))\n",
    "mnb = MultinomialNB()\n",
    "cnb = ComplementNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-NB8_aYQmDU"
   },
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSsBeH1cdrKu"
   },
   "outputs": [],
   "source": [
    "#MultinomialNB classifier\n",
    "def mnb_cv(splits, X, Y, pipeline, average_method):\n",
    "    \n",
    "    kfoldmnb = StratifiedKFold(n_splits=splits, shuffle=True, random_state=5)\n",
    "    #accuracymnb = []\n",
    "    precisionmnb = []\n",
    "    recallmnb = []\n",
    "    f1mnb = []\n",
    "    for train, test in kfoldmnb.split(X, Y):\n",
    "        mnb_fit = pipeline.fit(X[train], Y[train])\n",
    "        predictionmnb = mnb_fit.predict(X[test])\n",
    "        scoresmnb = mnb_fit.score(X[test],Y[test])\n",
    "        class_names = ['Negative','Neutral','Positive']\n",
    "        cm = confusion_matrix((Y[test]), predictionmnb)\n",
    "        mnbdf_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "        \n",
    "    \n",
    "        #accuracymnb.append(scoresmnb * 100)\n",
    "        #print('Accuracy: ', scoresmnb * 100)\n",
    "        precisionmnb.append(precision_score(Y[test], predictionmnb, average=average_method)*100)\n",
    "        print(' '*10, class_names)\n",
    "        print('Precision:',precision_score(Y[test], predictionmnb, average=None))\n",
    "        recallmnb.append(recall_score(Y[test], predictionmnb, average=average_method)*100)\n",
    "        print('Recall:   ',recall_score(Y[test], predictionmnb, average=None))\n",
    "        f1mnb.append(f1_score(Y[test], predictionmnb, average=average_method)*100)\n",
    "        print('F1 score: ',f1_score(Y[test], predictionmnb, average=None))\n",
    "        print('-'*50)\n",
    "\n",
    "        #mnbaccumean = np.mean(accuracymnb)\n",
    "        mnbprecmean = np.mean(precisionmnb)\n",
    "        mnbrecamean = np.mean(recallmnb)\n",
    "        mnbf1scmean = np.mean(f1mnb)\n",
    "            \n",
    "    #print('Accuracy: %.2f%% (+/- %.2f%%)' % (mnbaccumean, np.std(accuracymnb)))\n",
    "    print('Precision: %.2f%% (+/- %.2f%%)' % (mnbprecmean, np.std(precisionmnb)))\n",
    "    print('Recall: %.2f%% (+/- %.2f%%)' % (mnbrecamean, np.std(recallmnb)))\n",
    "    print('F1 score: %.2f%% (+/- %.2f%%)' % (mnbf1scmean, np.std(f1mnb)))\n",
    "    print(' ')\n",
    "    print('Confusion matrix\\n', mnbdf_cm)\n",
    "    return kfoldmnb, precisionmnb, recallmnb, f1mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FBtpTkwQuEJa"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2-p9A0EiI9p"
   },
   "outputs": [],
   "source": [
    "# Resampling Over Sampling\n",
    "ROSnb = RandomOverSampler(sampling_strategy='not majority', random_state=5)\n",
    "SMOTEnb = SMOTE(sampling_strategy='not majority', random_state=5)\n",
    "\n",
    "# Resampling Under Sampling\n",
    "RUSnb = RandomUnderSampler(sampling_strategy='not minority', random_state=5)\n",
    "TOMnb = TomekLinks(sampling_strategy='majority')\n",
    "\n",
    "# Resampling SMOTETomek\n",
    "SMOTETomnb = SMOTETomek(random_state=5, \n",
    "                       smote=SMOTE(sampling_strategy='not majority', random_state=5), \n",
    "                       tomek=TomekLinks(sampling_strategy='majority')\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XD2vHldfiNmA"
   },
   "outputs": [],
   "source": [
    "mnb_SMOTETOM_tvec3_pipeline = make_pipeline(tvec3, SMOTETomnb, mnb) #trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m5VyHTUciQTS",
    "outputId": "189f7393-32ca-4efc-a021-ed786a2a36f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.27586207 0.85964912 0.43382353]\n",
      "Recall:    [0.65306122 0.62659847 0.60824742]\n",
      "F1 score:  [0.38787879 0.72485207 0.50643777]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.25471698 0.87234043 0.44295302]\n",
      "Recall:    [0.55102041 0.62915601 0.68041237]\n",
      "F1 score:  [0.3483871  0.73105498 0.53658537]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.25490196 0.89160839 0.51006711]\n",
      "Recall:    [0.53061224 0.65217391 0.78350515]\n",
      "F1 score:  [0.34437086 0.75332349 0.61788618]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.26956522 0.88235294 0.4       ]\n",
      "Recall:    [0.63265306 0.61381074 0.6185567 ]\n",
      "F1 score:  [0.37804878 0.7239819  0.48582996]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.24545455 0.87769784 0.44295302]\n",
      "Recall:    [0.55102041 0.62404092 0.68041237]\n",
      "F1 score:  [0.33962264 0.72944694 0.53658537]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.30927835 0.87412587 0.42207792]\n",
      "Recall:    [0.6122449  0.63938619 0.67010309]\n",
      "F1 score:  [0.4109589  0.73855244 0.51792829]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.28099174 0.86868687 0.46218487]\n",
      "Recall:    [0.68       0.66153846 0.56701031]\n",
      "F1 score:  [0.39766082 0.7510917  0.50925926]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.31313131 0.88552189 0.46428571]\n",
      "Recall:    [0.63265306 0.67435897 0.67010309]\n",
      "F1 score:  [0.41891892 0.76564774 0.54852321]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.24193548 0.88043478 0.45588235]\n",
      "Recall:    [0.6122449  0.62307692 0.63917526]\n",
      "F1 score:  [0.34682081 0.72972973 0.53218884]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.27272727 0.87719298 0.43421053]\n",
      "Recall:    [0.55102041 0.64102564 0.68041237]\n",
      "F1 score:  [0.36486486 0.74074074 0.53012048]\n",
      "--------------------------------------------------\n",
      "Precision: 53.19% (+/- 1.21%)\n",
      "Recall: 63.30% (+/- 1.38%)\n",
      "F1 score: 54.82% (+/- 1.53%)\n",
      " \n",
      "Confusion matrix\n",
      "           Negative  Neutral  Positive\n",
      "Negative        27       16         6\n",
      "Neutral         60      250        80\n",
      "Positive        12       19        66\n"
     ]
    }
   ],
   "source": [
    "mnbsmotetomtvec3 = mnb_cv(10, data.New_Text, data.Sentiment, mnb_SMOTETOM_tvec3_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMfmKx6RQus3"
   },
   "source": [
    "#### Non Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UlWxfrTiaa1"
   },
   "outputs": [],
   "source": [
    "X = data.New_Text\n",
    "Y = data.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7pAouW7S9W0"
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, shuffle=True, random_state = 5, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5Hy_Jmv2Rbs"
   },
   "outputs": [],
   "source": [
    "xtraintvec = tvec3.fit_transform(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "DFQXR6T32TgB",
    "outputId": "791a7b8b-8f03-4399-ac43-8dd516e89c15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "xres, yres = SMOTETomnb.fit_resample(xtraintvec, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Lda3CHusn0QJ",
    "outputId": "2b4b7045-5c43-401d-bb7e-572e6a34136e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8787, 60917), (8787,), (1342,), (1342,))"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xres.shape, yres.shape, xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "97iokM1MoPCE",
    "outputId": "f9918699-5b78-4616-9db9-a5cfb609af5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil SMOTETomek pada train data label positive: 3125\n",
      "Hasil SMOTETomek pada train data label neutral: 3125\n",
      "Hasil SMOTETomek pada train data label negative: 3125\n"
     ]
    }
   ],
   "source": [
    "pos_weight = len([s for s in yresskf if s=='Positive'])\n",
    "neg_weight = len([s for s in yresskf if s=='Negative'])\n",
    "neu_weight = len([s for s in yresskf if s=='Neutral'])\n",
    "print('Hasil SMOTETomek pada train data label positive: %s' %(pos_weight))\n",
    "print('Hasil SMOTETomek pada train data label neutral: %s' %(neu_weight))\n",
    "print('Hasil SMOTETomek pada train data label negative: %s' %(neg_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Hs7y-RE0o0tZ",
    "outputId": "85048dac-cdc9-409a-c53f-8d25f8c9d959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n",
      "123\n",
      "965\n"
     ]
    }
   ],
   "source": [
    "pos_weight = len([s for s in ytest if s=='Positive'])\n",
    "neg_weight = len([s for s in ytest if s=='Negative'])\n",
    "neu_weight = len([s for s in ytest if s=='Neutral'])\n",
    "print(pos_weight)\n",
    "print(neg_weight)\n",
    "print(neu_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ge4-9EI02VeN"
   },
   "outputs": [],
   "source": [
    "xtesttvec = tvec3.transform(xtest)\n",
    "mnb.fit(xres, yres)\n",
    "preds = mnb.predict(xtesttvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGGs-90b2Yvp"
   },
   "outputs": [],
   "source": [
    "score = mnb.score(xtesttvec, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "-iOXzf-H2amH",
    "outputId": "251cbf9f-708b-45f1-8457-694c04dc1052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.26      0.65      0.37       123\n",
      "     Neutral       0.86      0.60      0.71       965\n",
      "    Positive       0.45      0.64      0.52       242\n",
      "\n",
      "    accuracy                           0.61      1330\n",
      "   macro avg       0.52      0.63      0.53      1330\n",
      "weighted avg       0.73      0.61      0.64      1330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "smUgPiDi63Gi",
    "outputId": "64b4dbe8-6474-4290-e8a8-56b550ff9262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.25889968 0.85798817 0.44637681]\n",
      "Recall:    [0.6504065  0.60103627 0.63636364]\n",
      "F1 score:  [0.37037037 0.70688605 0.52470187]\n",
      "          \n",
      "Precision: 52.11% (+/- 0.25%)\n",
      "Recall: 62.93% (+/- 0.02%)\n",
      "F1 score: 53.40% (+/- 0.14%)\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Negative','Neutral','Positive']\n",
    "\n",
    "print(' '*10, class_names)\n",
    "print('Precision:',precision_score(ytest, preds, average=None))\n",
    "print('Recall:   ',recall_score(ytest, preds, average=None))\n",
    "print('F1 score: ',f1_score(ytest, preds, average=None))\n",
    "print(' '*10)\n",
    "print('Precision: %.2f%% (+/- %.2f%%)' % (np.mean(precision_score(ytest, preds, average=None)*100), np.std(precision_score(ytest, preds, average=None))))\n",
    "print('Recall: %.2f%% (+/- %.2f%%)' % (np.mean(recall_score(ytest, preds, average=None)*100), np.std(recall_score(ytest, preds, average=None))))\n",
    "print('F1 score: %.2f%% (+/- %.2f%%)' % (np.mean(f1_score(ytest, preds, average=None)*100), np.std(f1_score(ytest, preds, average=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "Dn0vbavfIYb7",
    "outputId": "c9eafaf5-fd62-4f62-a559-bcd956587519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "           Negative  Neutral  Positive\n",
      "Negative        80       35         8\n",
      "Neutral        202      580       183\n",
      "Positive        27       61       154\n"
     ]
    }
   ],
   "source": [
    "mnbcm = confusion_matrix((ytest), preds)\n",
    "mnbcm_df = pd.DataFrame(mnbcm, index=class_names, columns=class_names)\n",
    "print('Confusion matrix\\n', mnbcm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OY9x0mwS4dqy"
   },
   "source": [
    "##### Non Pipeline Stritified KFold ver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2vAZuaSb4qv"
   },
   "source": [
    "###### X = Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAJigo0BW0pF"
   },
   "outputs": [],
   "source": [
    "#X = data.Tokenize\n",
    "#X = [str (item) for item in X]\n",
    "#X = np.array(X)\n",
    "#Y = data.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "f_Vpd_J8XsQs",
    "outputId": "b5f9e89c-78b2-4d75-eba6-1d062854d412"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"['ketika', 'maranatha', 'bandung', 'bulan', 'juli', 'kemarin', 'di', 'culik', 'tabuh']\",\n",
       "       \"['yakin', 'anak', 'maranatha', 'ada', 'main', 'twitter']\",\n",
       "       \"['waktu', 'pertama', 'temu', 'sama', 'angkring', 'maranatha']\",\n",
       "       ...,\n",
       "       \"['yang', 'mau', 'ambil', 'hukum', 'unpar', 'hukum', 'unpar', 'jurus', 'yang', 'ada', 'jurus', 'aku', 'tau', 'atmajaya', 'pancasila', 'marnat', 'di', 'guru', 'tinggi', 'negeri', 'aku', 'tau']\",\n",
       "       \"['moga', 'jadi', 'dosen', 'marnat', 'tidak', 'enak']\",\n",
       "       \"['foto', 'saja', 'asa', 'kesan', 'anak', 'manajemen', 'bisnis', 'marnat', 'sedang', 'selesai', 'presentasi', 'langsung', 'pergi', 'braga']\"],\n",
       "      dtype='<U431')"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0JEwZSpwcBG1"
   },
   "source": [
    "###### Stritified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VU9qAkeSw1wB",
    "outputId": "5249f7b7-bccc-466f-ae39-8a194c0f7b9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \n",
      "Accuracy:  62.290502793296085\n",
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.2605042  0.87613843 0.43902439]\n",
      "Recall:    [0.63265306 0.61508951 0.64948454]\n",
      "F1 score:  [0.36904762 0.72276484 0.52390852]\n",
      "--------------------------------------------------\n",
      "Precision: 52.52% (+/- 0.26%)\n",
      "Recall: 63.24% (+/- 0.01%)\n",
      "F1 score: 53.86% (+/- 0.14%)\n",
      "Confusion matrix\n",
      "           Negative  Neutral  Positive\n",
      "Negative        62       26        10\n",
      "Neutral        150      481       151\n",
      "Positive        26       42       126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \n",
      "Accuracy:  63.50093109869647\n",
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.24186047 0.87676056 0.45360825]\n",
      "Recall:    [0.52525253 0.63764405 0.68041237]\n",
      "F1 score:  [0.33121019 0.73832468 0.5443299 ]\n",
      "--------------------------------------------------\n",
      "Precision: 52.41% (+/- 0.26%)\n",
      "Recall: 61.44% (+/- 0.07%)\n",
      "F1 score: 53.80% (+/- 0.17%)\n",
      "Confusion matrix\n",
      "           Negative  Neutral  Positive\n",
      "Negative        52       31        16\n",
      "Neutral        140      498       143\n",
      "Positive        23       39       132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \n",
      "Accuracy:  65.05125815470643\n",
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.29015544 0.8791019  0.44186047]\n",
      "Recall:    [0.57142857 0.65172855 0.68556701]\n",
      "F1 score:  [0.38487973 0.74852941 0.53737374]\n",
      "--------------------------------------------------\n",
      "Precision: 53.70% (+/- 0.25%)\n",
      "Recall: 63.62% (+/- 0.05%)\n",
      "F1 score: 55.69% (+/- 0.15%)\n",
      "Confusion matrix\n",
      "           Negative  Neutral  Positive\n",
      "Negative        56       30        12\n",
      "Neutral        116      509       156\n",
      "Positive        21       40       133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \n",
      "Accuracy:  64.6784715750233\n",
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.30136986 0.875      0.43333333]\n",
      "Recall:    [0.67346939 0.65428937 0.60309278]\n",
      "F1 score:  [0.41640379 0.74871795 0.50431034]\n",
      "--------------------------------------------------\n",
      "Precision: 53.66% (+/- 0.25%)\n",
      "Recall: 64.36% (+/- 0.03%)\n",
      "F1 score: 55.65% (+/- 0.14%)\n",
      "Confusion matrix\n",
      "           Negative  Neutral  Positive\n",
      "Negative        66       21        11\n",
      "Neutral        128      511       142\n",
      "Positive        25       52       117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \n",
      "Accuracy:  64.58527493010251\n",
      "           ['Negative', 'Neutral', 'Positive']\n",
      "Precision: [0.2735426  0.88327526 0.45289855]\n",
      "Recall:    [0.62244898 0.64916773 0.6443299 ]\n",
      "F1 score:  [0.38006231 0.74833948 0.53191489]\n",
      "--------------------------------------------------\n",
      "Precision: 53.66% (+/- 0.26%)\n",
      "Recall: 63.86% (+/- 0.01%)\n",
      "F1 score: 55.34% (+/- 0.15%)\n",
      "Confusion matrix\n",
      "           Negative  Neutral  Positive\n",
      "Negative        61       25        12\n",
      "Neutral        135      507       139\n",
      "Positive        27       42       125\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)\n",
    "\n",
    "accuracymnbskf = []\n",
    "precisionmnbskf = []\n",
    "recallmnbskf = []\n",
    "f1mnbskf = []\n",
    "for train_skf, test_skf in skf.split(X, Y):\n",
    "  xtraintvecskf = tvec3.fit_transform(X[train_skf])\n",
    "  xtesttvecskf = tvec3.transform(X[test_skf])\n",
    "  xresskf, yresskf = SMOTETomnb.fit_resample(xtraintvecskf, Y[train_skf])\n",
    "  mnb_fitskf = mnb.fit(xresskf, yresskf)\n",
    "  predictionmnbskf = mnb_fitskf.predict(xtesttvecskf)\n",
    "  scoresmnbskf = mnb_fitskf.score(xtesttvecskf, Y[test_skf])\n",
    "  class_names_skf = ['Negative','Neutral','Positive']\n",
    "  cmskf = confusion_matrix((Y[test_skf]), predictionmnbskf)\n",
    "  mnbdf_cmskf = pd.DataFrame(cmskf, index=class_names_skf, columns=class_names_skf)\n",
    "\n",
    "  print(' '*10)\n",
    "  accuracymnbskf.append(scoresmnbskf * 100)\n",
    "  print('Accuracy: ', scoresmnbskf * 100)\n",
    "  print(' '*10, class_names_skf)\n",
    "  precisionmnbskf.append(precision_score(Y[test_skf], predictionmnbskf, average='macro')*100)\n",
    "  print('Precision:',precision_score(Y[test_skf], predictionmnbskf, average=None))\n",
    "  recallmnbskf.append(recall_score(Y[test_skf], predictionmnbskf, average='macro')*100)\n",
    "  print('Recall:   ',recall_score(Y[test_skf], predictionmnbskf, average=None))\n",
    "  f1mnbskf.append(f1_score(Y[test_skf], predictionmnbskf, average='macro')*100)\n",
    "  print('F1 score: ',f1_score(Y[test_skf], predictionmnbskf, average=None))\n",
    "  print('-'*50)\n",
    "  print('Precision: %.2f%% (+/- %.2f%%)' % (np.mean(precision_score(Y[test_skf], predictionmnbskf, average=None)*100), \n",
    "                                            np.std(precision_score(Y[test_skf], predictionmnbskf, average=None))))\n",
    "  print('Recall: %.2f%% (+/- %.2f%%)' % (np.mean(recall_score(Y[test_skf], predictionmnbskf, average=None)*100), \n",
    "                                         np.std(recall_score(Y[test_skf], predictionmnbskf, average=None))))\n",
    "  print('F1 score: %.2f%% (+/- %.2f%%)' % (np.mean(f1_score(Y[test_skf], predictionmnbskf, average=None)*100), \n",
    "                                           np.std(f1_score(Y[test_skf], predictionmnbskf, average=None))))\n",
    "  print('Confusion matrix\\n', mnbdf_cmskf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_vCwDsNCPlt"
   },
   "source": [
    "#### Test Classifier MNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4oK_DLvUluim"
   },
   "source": [
    "##### Download test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "2sw1dDmEl_gr",
    "outputId": "3e8a7fbe-69ac-4b73-daa1-4752d3c0a91b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GetOldTweets3 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n",
      "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n",
      "Requirement already satisfied: pyquery>=1.2.10 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (1.4.1)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.6/dist-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install GetOldTweets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6Z4WU8Eltdf"
   },
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKeNWEgWmBAq"
   },
   "outputs": [],
   "source": [
    "# Function that pulls tweets based on a general search query and turns to csv file\n",
    "\n",
    "# Parameters: (text query you want to search), (max number of most recent tweets to pull from)\n",
    "def text_query_to_csv(text_query, count):\n",
    "    # Creation of query object\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query)\\\n",
    "                                                .setLang('id')\\\n",
    "                                                .setMaxTweets(count)\\\n",
    "                                                .setSince(start_date)\\\n",
    "                                                .setUntil(end_date)\n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    text_tweets = [[tweet.date, tweet.text] for tweet in tweets]\n",
    "\n",
    "    tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Text'])\n",
    "\n",
    "    tweets_df.to_csv('{}-{}-tweets.csv'.format(text_query, int(count)), sep=',')\n",
    "    \n",
    "text_query1 = 'maranatha'\n",
    "text_query2 = 'marnath'\n",
    "text_query3 = 'marnat'\n",
    "start_date = '2020-02-01'\n",
    "end_date = '2020-05-31'\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbPDPSD3oNFT"
   },
   "outputs": [],
   "source": [
    "text_query_to_csv(text_query1, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6qu0y8QoByf"
   },
   "outputs": [],
   "source": [
    "text_query_to_csv(text_query2, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYONDgcwoCFn"
   },
   "outputs": [],
   "source": [
    "text_query_to_csv(text_query3, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QahhkMDgoY76"
   },
   "outputs": [],
   "source": [
    "test_maranatha_df = pd.read_csv('/content/maranatha-0-tweets.csv')\n",
    "test_marnath_df = pd.read_csv('/content/marnath-0-tweets.csv')\n",
    "test_marnat_df = pd.read_csv('/content/marnat-0-tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "MxrkO9Wrpcgd",
    "outputId": "842a7d4a-0a29-430c-ec48-24d2cbea1442"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-30 22:44:47+00:00</td>\n",
       "      <td>Ya, Cina Maranatha karena peduli soal Saya dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-30 22:44:09+00:00</td>\n",
       "      <td>Kalau virus Corona itu, berasal atau karena.. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-05-30 20:12:20+00:00</td>\n",
       "      <td>unpar? ciputra? atmajaya? sampoerna? maranatha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-05-30 18:39:08+00:00</td>\n",
       "      <td>kenapa ga Maranatha Bandung aja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-30 18:20:31+00:00</td>\n",
       "      <td>blm bisa Rt lgi di setrap ini akun sy katanya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>752</td>\n",
       "      <td>2020-02-02 04:47:26+00:00</td>\n",
       "      <td>Temen si yolla tah, marnat husein teh tinggal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>753</td>\n",
       "      <td>2020-02-01 20:47:23+00:00</td>\n",
       "      <td>Senin ketemu di marnat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>754</td>\n",
       "      <td>2020-02-01 19:19:49+00:00</td>\n",
       "      <td>Nak marnat bund ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>755</td>\n",
       "      <td>2020-02-01 14:43:44+00:00</td>\n",
       "      <td>Euy info dong,kos kos an elite daerah cimahi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>756</td>\n",
       "      <td>2020-02-01 07:17:41+00:00</td>\n",
       "      <td>ya ngapain atuh,, orcin aja nuntut ilmu ke mar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1588 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ...                                               Text\n",
       "0              0  ...  Ya, Cina Maranatha karena peduli soal Saya dan...\n",
       "1              1  ...  Kalau virus Corona itu, berasal atau karena.. ...\n",
       "2              2  ...  unpar? ciputra? atmajaya? sampoerna? maranatha...\n",
       "3              3  ...                    kenapa ga Maranatha Bandung aja\n",
       "4              4  ...   blm bisa Rt lgi di setrap ini akun sy katanya...\n",
       "...          ...  ...                                                ...\n",
       "1583         752  ...  Temen si yolla tah, marnat husein teh tinggal ...\n",
       "1584         753  ...                             Senin ketemu di marnat\n",
       "1585         754  ...                                  Nak marnat bund ?\n",
       "1586         755  ...  Euy info dong,kos kos an elite daerah cimahi a...\n",
       "1587         756  ...  ya ngapain atuh,, orcin aja nuntut ilmu ke mar...\n",
       "\n",
       "[1588 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = [test_maranatha_df, test_marnath_df, test_marnat_df]\n",
    "test_df = pd.concat(test_data)\n",
    "test_df.drop_duplicates()\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df.sort_values(by='Datetime', ascending=False)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "d-uKxKac0d92",
    "outputId": "458a4691-ce76-4156-8bdd-e7e13c65c577"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "mnb_pipeline = mnb_SMOTETOM_tvec3_pipeline.fit(xtrain, ytrain)\n",
    "mnb_non_pipeline = mnb.fit(xres, yres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HijuoiWT1rd3"
   },
   "outputs": [],
   "source": [
    "test_text = test_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "uo5kJvpi1uL8",
    "outputId": "a3f25d0f-d63e-469a-9e18-0c4a499f8e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text = 0       Ya, Cina Maranatha karena peduli soal Saya dan...\n",
      "1       Kalau virus Corona itu, berasal atau karena.. ...\n",
      "2       unpar? ciputra? atmajaya? sampoerna? maranatha...\n",
      "3                         kenapa ga Maranatha Bandung aja\n",
      "4        blm bisa Rt lgi di setrap ini akun sy katanya...\n",
      "                              ...                        \n",
      "1583    Temen si yolla tah, marnat husein teh tinggal ...\n",
      "1584                               Senin ketemu di marnat\n",
      "1585                                    Nak marnat bund ?\n",
      "1586    Euy info dong,kos kos an elite daerah cimahi a...\n",
      "1587    ya ngapain atuh,, orcin aja nuntut ilmu ke mar...\n",
      "Name: Text, Length: 1588, dtype: object \n",
      " Predicted = ['Negative' 'Negative' 'Negative' ... 'Neutral' 'Neutral' 'Neutral']\n"
     ]
    }
   ],
   "source": [
    "predict_mnb_pipeline = mnb_pipeline.predict(test_text)\n",
    "print('Input Text = %s \\n Predicted = %s' % (test_text, predict_mnb_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jG1fsVgN6RxR"
   },
   "outputs": [],
   "source": [
    "test_text_non_pipeline = tvec3.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9DJphdr2gfQ"
   },
   "source": [
    "##### Test Tweets February-Mei 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "luLNL97d2nqM"
   },
   "outputs": [],
   "source": [
    "maranatha_test_df = pd.read_excel('/content/drive/My Drive/Tesis/MARANATHA_TEST_NEW_nonindex_norm.xls')\n",
    "marnath_test_df = pd.read_excel('/content/drive/My Drive/Tesis/MARNATH_TEST_nonindex_norm.xls')\n",
    "marnat_test_df = pd.read_excel('/content/drive/My Drive/Tesis/MARNAT_TEST_nonindex_norm.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "8GAUMvFp3onm",
    "outputId": "c6da03a4-e85e-4bd4-f77a-2bcf798d6caa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-30 22:44:47+00:00</td>\n",
       "      <td>Ya, Cina MARANATHA karena peduli soal Saya dan...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-30 22:44:09+00:00</td>\n",
       "      <td>Kalau virus Corona itu, berasal atau karena.. ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-30 20:12:20+00:00</td>\n",
       "      <td>unpar? ciputra? atmajaya? sampoerna? MARANATHA...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-30 18:39:08+00:00</td>\n",
       "      <td>kenapa tidak MARANATHA Bandung saja</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-30 12:35:27+00:00</td>\n",
       "      <td>Di Unpar dan MARANATHA Bandung. tinggal di kot...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2020-02-02 11:47:46+00:00</td>\n",
       "      <td>Angkringan marnat bisa tambah bayar tidak</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2020-02-02 04:47:26+00:00</td>\n",
       "      <td>Teman dia, marnat husein hanya langkah</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>2020-02-01 20:47:23+00:00</td>\n",
       "      <td>Senin temu di marnat</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>2020-02-01 14:43:44+00:00</td>\n",
       "      <td>Tolong info,kost bagus daerah cimahi atau bela...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2020-02-01 07:17:41+00:00</td>\n",
       "      <td>ya untuk apa dia saja tuntut ilmu ke marnat</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime  ... Sentiment\n",
       "0     2020-05-30 22:44:47+00:00  ...  Positive\n",
       "1     2020-05-30 22:44:09+00:00  ...   Neutral\n",
       "2     2020-05-30 20:12:20+00:00  ...   Neutral\n",
       "3     2020-05-30 18:39:08+00:00  ...   Neutral\n",
       "4     2020-05-30 12:35:27+00:00  ...   Neutral\n",
       "...                         ...  ...       ...\n",
       "1196  2020-02-02 11:47:46+00:00  ...   Neutral\n",
       "1197  2020-02-02 04:47:26+00:00  ...   Neutral\n",
       "1198  2020-02-01 20:47:23+00:00  ...   Neutral\n",
       "1199  2020-02-01 14:43:44+00:00  ...  Positive\n",
       "1200  2020-02-01 07:17:41+00:00  ...   Neutral\n",
       "\n",
       "[1201 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = [maranatha_test_df, marnath_test_df, marnat_test_df]\n",
    "test_df = pd.concat(data_test)\n",
    "test_df.drop_duplicates()\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df.sort_values(by='Datetime', ascending=False)\n",
    "test_df['Sentiment'] = test_df.Sentiment.map({0:'Neutral', 1:'Positive', -1:'Negative'})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "t288hLcE6KUy",
    "outputId": "cee836fa-195a-454b-c649-7d92f6efcc92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.3 s, sys: 9.88 ms, total: 37.3 s\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_text_cleaner = []\n",
    "\n",
    "for text in test_df.Text:\n",
    "    test_text_cleaner.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "3i9Nrq3N6eaH",
    "outputId": "bdf2b0c7-2dcd-41d9-d6bc-ca9addee1c36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>New_Test_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-30 22:44:47+00:00</td>\n",
       "      <td>Ya, Cina MARANATHA karena peduli soal Saya dan...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>cina maranatha peduli soal dan karina mungkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-30 22:44:09+00:00</td>\n",
       "      <td>Kalau virus Corona itu, berasal atau karena.. ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>kalau virus corona asal karena cina maranatha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-30 20:12:20+00:00</td>\n",
       "      <td>unpar? ciputra? atmajaya? sampoerna? MARANATHA...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>unpar ciputra atmajaya sampoerna maranatha bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-30 18:39:08+00:00</td>\n",
       "      <td>kenapa tidak MARANATHA Bandung saja</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>tidak maranatha bandung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-30 12:35:27+00:00</td>\n",
       "      <td>Di Unpar dan MARANATHA Bandung. tinggal di kot...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>unpar maranatha bandung tinggal kota mana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2020-02-02 11:47:46+00:00</td>\n",
       "      <td>Angkringan marnat bisa tambah bayar tidak</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>angkring marnat tambah bayar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2020-02-02 04:47:26+00:00</td>\n",
       "      <td>Teman dia, marnat husein hanya langkah</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>teman marnat husein langkah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>2020-02-01 20:47:23+00:00</td>\n",
       "      <td>Senin temu di marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>senin temu marnat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>2020-02-01 14:43:44+00:00</td>\n",
       "      <td>Tolong info,kost bagus daerah cimahi atau bela...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>info kost bagus daerah cimahi belakang marnat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2020-02-01 07:17:41+00:00</td>\n",
       "      <td>ya untuk apa dia saja tuntut ilmu ke marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>untuk apa saja tuntut ilmu marnat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime  ...                                      New_Test_Text\n",
       "0     2020-05-30 22:44:47+00:00  ...      cina maranatha peduli soal dan karina mungkin\n",
       "1     2020-05-30 22:44:09+00:00  ...      kalau virus corona asal karena cina maranatha\n",
       "2     2020-05-30 20:12:20+00:00  ...  unpar ciputra atmajaya sampoerna maranatha bus...\n",
       "3     2020-05-30 18:39:08+00:00  ...                            tidak maranatha bandung\n",
       "4     2020-05-30 12:35:27+00:00  ...          unpar maranatha bandung tinggal kota mana\n",
       "...                         ...  ...                                                ...\n",
       "1196  2020-02-02 11:47:46+00:00  ...                       angkring marnat tambah bayar\n",
       "1197  2020-02-02 04:47:26+00:00  ...                        teman marnat husein langkah\n",
       "1198  2020-02-01 20:47:23+00:00  ...                                  senin temu marnat\n",
       "1199  2020-02-01 14:43:44+00:00  ...      info kost bagus daerah cimahi belakang marnat\n",
       "1200  2020-02-01 07:17:41+00:00  ...                  untuk apa saja tuntut ilmu marnat\n",
       "\n",
       "[1201 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_text = pd.DataFrame({'New_Test_Text' : test_text_cleaner})\n",
    "new_test_df = pd.concat([test_df, new_test_text], axis = 1)\n",
    "new_test_df.replace('', np.nan, inplace=True)\n",
    "new_test_df.dropna(inplace=True)\n",
    "new_test_df.reset_index(drop=True, inplace=True)\n",
    "new_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qeDnIsNH8hYy"
   },
   "outputs": [],
   "source": [
    "new_test_df['Tokenize'] = new_test_df['Text'].apply(lambda x: clean_text_token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "colab_type": "code",
    "id": "o59av3CM8tgj",
    "outputId": "7e8adb05-17b6-4c4e-f3f8-6dc2129dec01"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>New_Test_Text</th>\n",
       "      <th>Tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-30 22:44:47+00:00</td>\n",
       "      <td>Ya, Cina MARANATHA karena peduli soal Saya dan...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>cina maranatha peduli soal dan karina mungkin</td>\n",
       "      <td>[cina, maranatha, peduli, soal, dan, karina, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-30 22:44:09+00:00</td>\n",
       "      <td>Kalau virus Corona itu, berasal atau karena.. ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>kalau virus corona asal karena cina maranatha</td>\n",
       "      <td>[kalau, virus, corona, asal, karena, cina, mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-30 20:12:20+00:00</td>\n",
       "      <td>unpar? ciputra? atmajaya? sampoerna? MARANATHA...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>unpar ciputra atmajaya sampoerna maranatha bus...</td>\n",
       "      <td>[unpar, ciputra, atmajaya, sampoerna, maranath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-30 18:39:08+00:00</td>\n",
       "      <td>kenapa tidak MARANATHA Bandung saja</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>tidak maranatha bandung</td>\n",
       "      <td>[tidak, maranatha, bandung]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-30 12:35:27+00:00</td>\n",
       "      <td>Di Unpar dan MARANATHA Bandung. tinggal di kot...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>unpar maranatha bandung tinggal kota mana</td>\n",
       "      <td>[unpar, maranatha, bandung, tinggal, kota, mana]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2020-02-02 11:47:46+00:00</td>\n",
       "      <td>Angkringan marnat bisa tambah bayar tidak</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>angkring marnat tambah bayar</td>\n",
       "      <td>[angkring, marnat, tambah, bayar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2020-02-02 04:47:26+00:00</td>\n",
       "      <td>Teman dia, marnat husein hanya langkah</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>teman marnat husein langkah</td>\n",
       "      <td>[teman, marnat, husein, langkah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>2020-02-01 20:47:23+00:00</td>\n",
       "      <td>Senin temu di marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>senin temu marnat</td>\n",
       "      <td>[senin, temu, marnat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>2020-02-01 14:43:44+00:00</td>\n",
       "      <td>Tolong info,kost bagus daerah cimahi atau bela...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>info kost bagus daerah cimahi belakang marnat</td>\n",
       "      <td>[infokost, bagus, daerah, cimahi, belakang, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2020-02-01 07:17:41+00:00</td>\n",
       "      <td>ya untuk apa dia saja tuntut ilmu ke marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>untuk apa saja tuntut ilmu marnat</td>\n",
       "      <td>[untuk, apa, saja, tuntut, ilmu, marnat]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime  ...                                           Tokenize\n",
       "0     2020-05-30 22:44:47+00:00  ...  [cina, maranatha, peduli, soal, dan, karina, m...\n",
       "1     2020-05-30 22:44:09+00:00  ...  [kalau, virus, corona, asal, karena, cina, mar...\n",
       "2     2020-05-30 20:12:20+00:00  ...  [unpar, ciputra, atmajaya, sampoerna, maranath...\n",
       "3     2020-05-30 18:39:08+00:00  ...                        [tidak, maranatha, bandung]\n",
       "4     2020-05-30 12:35:27+00:00  ...   [unpar, maranatha, bandung, tinggal, kota, mana]\n",
       "...                         ...  ...                                                ...\n",
       "1196  2020-02-02 11:47:46+00:00  ...                  [angkring, marnat, tambah, bayar]\n",
       "1197  2020-02-02 04:47:26+00:00  ...                   [teman, marnat, husein, langkah]\n",
       "1198  2020-02-01 20:47:23+00:00  ...                              [senin, temu, marnat]\n",
       "1199  2020-02-01 14:43:44+00:00  ...  [infokost, bagus, daerah, cimahi, belakang, ma...\n",
       "1200  2020-02-01 07:17:41+00:00  ...           [untuk, apa, saja, tuntut, ilmu, marnat]\n",
       "\n",
       "[1201 rows x 5 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "WSZmcelW84Yt",
    "outputId": "2005d3f9-6abe-4f84-9915-81fb8cbf3b9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New_Test_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cina maranatha peduli soal dan karina mungkin</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[cina, maranatha, peduli, soal, dan, karina, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kalau virus corona asal karena cina maranatha</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[kalau, virus, corona, asal, karena, cina, mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unpar ciputra atmajaya sampoerna maranatha bus...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[unpar, ciputra, atmajaya, sampoerna, maranath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tidak maranatha bandung</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[tidak, maranatha, bandung]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unpar maranatha bandung tinggal kota mana</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[unpar, maranatha, bandung, tinggal, kota, mana]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>angkring marnat tambah bayar</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[angkring, marnat, tambah, bayar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>teman marnat husein langkah</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[teman, marnat, husein, langkah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>senin temu marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[senin, temu, marnat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>info kost bagus daerah cimahi belakang marnat</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[infokost, bagus, daerah, cimahi, belakang, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>untuk apa saja tuntut ilmu marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[untuk, apa, saja, tuntut, ilmu, marnat]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          New_Test_Text  ...                                           Tokenize\n",
       "0         cina maranatha peduli soal dan karina mungkin  ...  [cina, maranatha, peduli, soal, dan, karina, m...\n",
       "1         kalau virus corona asal karena cina maranatha  ...  [kalau, virus, corona, asal, karena, cina, mar...\n",
       "2     unpar ciputra atmajaya sampoerna maranatha bus...  ...  [unpar, ciputra, atmajaya, sampoerna, maranath...\n",
       "3                               tidak maranatha bandung  ...                        [tidak, maranatha, bandung]\n",
       "4             unpar maranatha bandung tinggal kota mana  ...   [unpar, maranatha, bandung, tinggal, kota, mana]\n",
       "...                                                 ...  ...                                                ...\n",
       "1196                       angkring marnat tambah bayar  ...                  [angkring, marnat, tambah, bayar]\n",
       "1197                        teman marnat husein langkah  ...                   [teman, marnat, husein, langkah]\n",
       "1198                                  senin temu marnat  ...                              [senin, temu, marnat]\n",
       "1199      info kost bagus daerah cimahi belakang marnat  ...  [infokost, bagus, daerah, cimahi, belakang, ma...\n",
       "1200                  untuk apa saja tuntut ilmu marnat  ...           [untuk, apa, saja, tuntut, ilmu, marnat]\n",
       "\n",
       "[1201 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = new_test_df[['New_Test_Text', 'Sentiment', 'Tokenize']]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "lbaXSbcD9zsv",
    "outputId": "a2a32c95-5932-4d95-fdb5-3d0b91ef87f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "mnb_pipeline = mnb_SMOTETOM_tvec3_pipeline.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5db2r-Zb3pMj"
   },
   "outputs": [],
   "source": [
    "test_text = test_data['New_Test_Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "VnT-Qsrt96qa",
    "outputId": "37a76ee0-c10d-4bfd-d2ea-b36bb1efcb9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text = 0           cina maranatha peduli soal dan karina mungkin\n",
      "1           kalau virus corona asal karena cina maranatha\n",
      "2       unpar ciputra atmajaya sampoerna maranatha bus...\n",
      "3                                 tidak maranatha bandung\n",
      "4               unpar maranatha bandung tinggal kota mana\n",
      "                              ...                        \n",
      "1196                         angkring marnat tambah bayar\n",
      "1197                          teman marnat husein langkah\n",
      "1198                                    senin temu marnat\n",
      "1199        info kost bagus daerah cimahi belakang marnat\n",
      "1200                    untuk apa saja tuntut ilmu marnat\n",
      "Name: New_Test_Text, Length: 1201, dtype: object \n",
      " Predicted = ['Neutral' 'Negative' 'Positive' ... 'Neutral' 'Neutral' 'Neutral']\n"
     ]
    }
   ],
   "source": [
    "predict_mnb_pipeline = mnb_pipeline.predict(test_text)\n",
    "print('Input Text = %s \\n Predicted = %s' % (test_text, predict_mnb_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "qydr8w7e962p",
    "outputId": "feed69c8-8e47-4e1c-f7fa-e9badb19d9b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Predict Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-30 22:44:47+00:00</td>\n",
       "      <td>Ya, Cina MARANATHA karena peduli soal Saya dan...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-30 22:44:09+00:00</td>\n",
       "      <td>Kalau virus Corona itu, berasal atau karena.. ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-30 20:12:20+00:00</td>\n",
       "      <td>unpar? ciputra? atmajaya? sampoerna? MARANATHA...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-30 18:39:08+00:00</td>\n",
       "      <td>kenapa tidak MARANATHA Bandung saja</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-30 12:35:27+00:00</td>\n",
       "      <td>Di Unpar dan MARANATHA Bandung. tinggal di kot...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2020-02-02 11:47:46+00:00</td>\n",
       "      <td>Angkringan marnat bisa tambah bayar tidak</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2020-02-02 04:47:26+00:00</td>\n",
       "      <td>Teman dia, marnat husein hanya langkah</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>2020-02-01 20:47:23+00:00</td>\n",
       "      <td>Senin temu di marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>2020-02-01 14:43:44+00:00</td>\n",
       "      <td>Tolong info,kost bagus daerah cimahi atau bela...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2020-02-01 07:17:41+00:00</td>\n",
       "      <td>ya untuk apa dia saja tuntut ilmu ke marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime  ... Predict Sentiment\n",
       "0     2020-05-30 22:44:47+00:00  ...           Neutral\n",
       "1     2020-05-30 22:44:09+00:00  ...          Negative\n",
       "2     2020-05-30 20:12:20+00:00  ...          Positive\n",
       "3     2020-05-30 18:39:08+00:00  ...           Neutral\n",
       "4     2020-05-30 12:35:27+00:00  ...           Neutral\n",
       "...                         ...  ...               ...\n",
       "1196  2020-02-02 11:47:46+00:00  ...          Negative\n",
       "1197  2020-02-02 04:47:26+00:00  ...           Neutral\n",
       "1198  2020-02-01 20:47:23+00:00  ...           Neutral\n",
       "1199  2020-02-01 14:43:44+00:00  ...           Neutral\n",
       "1200  2020-02-01 07:17:41+00:00  ...           Neutral\n",
       "\n",
       "[1201 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment = pd.DataFrame({'Predict Sentiment' : predict_mnb_pipeline})\n",
    "predict_df = pd.concat([test_df, predict_sentiment], axis = 1)\n",
    "predict_df.replace('', np.nan, inplace=True)\n",
    "predict_df.dropna(inplace=True)\n",
    "predict_df.reset_index(drop=True, inplace=True)\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uJYGo9eY97BC"
   },
   "outputs": [],
   "source": [
    "predict_df.to_excel('/content/drive/My Drive/Colab Notebooks/tesis_mnb_tvec_smotetomek_predict_NONKEYWORD_norm_TEST.xls', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rd4DVP_NP_tk"
   },
   "source": [
    "### **Split Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMvEMfNVQPpt"
   },
   "source": [
    "#### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0s4NJYnbUK-"
   },
   "outputs": [],
   "source": [
    "def tokenize(msg):\n",
    "    clean = [char for char in msg if char not in string.punctuation]\n",
    "    clean = ''.join(clean)\n",
    "    return clean.lower().split()\n",
    "\n",
    "def find_maxlen(reviews):\n",
    "    longest = 0\n",
    "    strlong = \"test\"\n",
    "    for review in reviews:\n",
    "        if len(tokenize(review)) > longest:\n",
    "            longest = len(tokenize(review))\n",
    "            strlong = review\n",
    "    return longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HEkZ7z6_bVhL",
    "outputId": "682e6b3a-0098-47eb-94e3-4ffd9197892e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_maxlen(data['New_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NfM59FQbXjm8",
    "outputId": "bf362aba-cf52-45e3-eab2-afdf1b816581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Tokens 6347\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data.Tokenize)\n",
    "sequences = tokenizer.texts_to_sequences(data.Tokenize)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Number of Unique Tokens',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psp2J_SOy2pN"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 50\n",
    "MAX_NB_WORDS = 6500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjsIgDhUyIXv"
   },
   "outputs": [],
   "source": [
    "label_names = ['Neutral', 'Positive', 'Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gazgNZqpU54N"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "train_y = data['Sentiment'].values\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_y)\n",
    "y = np_utils.to_categorical((label_encoder.transform(train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "DNDZtfoUXjzG",
    "outputId": "4ed1f541-2976-46cd-9126-e214bacbdc1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data Tensor: (5318, 50)\n",
      "Shape of Label Tensor: (5318, 3)\n"
     ]
    }
   ],
   "source": [
    "x = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "#y = data[label_names].values\n",
    "\n",
    "print('Shape of Data Tensor:', x.shape)\n",
    "print('Shape of Label Tensor:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "XgcIuaOiU6C2",
    "outputId": "a5c728d6-6a80-41d5-99f4-83bc4619079e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vT7QTy5yACu"
   },
   "outputs": [],
   "source": [
    "x_train, x_val_test, y_train, y_val_test = train_test_split(x, y, test_size=0.3, random_state=5, stratify=y)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size=0.5, random_state=5, stratify=y_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "RP7xVk3yzmRW",
    "outputId": "e49bd0b8-b85d-4ad7-cfca-2cc4f86a0187"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_res, y_res = SMOTETomnb.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngkbqFMcQK_X"
   },
   "source": [
    "#### Split Dataset TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdOgJ5xIqGrV"
   },
   "outputs": [],
   "source": [
    "x2 = data.New_Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhsz0JsXquUZ"
   },
   "outputs": [],
   "source": [
    "x2train, x2val_test, y2train, y2val_test = train_test_split(x2, y, random_state = 5, stratify = y)\n",
    "x2val, x2test, y2val, y2test = train_test_split(x2val_test, y2val_test, random_state = 5, stratify = y2val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90Nppvz7q55V"
   },
   "outputs": [],
   "source": [
    "td = 1000\n",
    "vec = TfidfVectorizer(max_features=td, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbxh7UnjrA4S"
   },
   "outputs": [],
   "source": [
    "x2train_vec = vec.fit_transform(x2train)\n",
    "x2val_vec = vec.transform(x2val)\n",
    "x2test_vec = vec.transform(x2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "N4WHxASdgfeb",
    "outputId": "d118b93e-1c04-4b04-eacb-dcf516032d33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4025, 1000), (1006, 1000), (336, 1000))"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2train_vec.shape, x2val_vec.shape, x2test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "l-D1XJiQrScM",
    "outputId": "44b57e83-76d7-4a8f-8161-d763c983225d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x2res, y2res = SMOTETomnb.fit_resample(x2train_vec, y2train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z5U10zFdPanK"
   },
   "source": [
    "### **Embbeding Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mbkelbGPlU6"
   },
   "source": [
    "#### Download Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "OOOSDm9zclys",
    "outputId": "225dbece-1fc9-403a-ac4e-5526b54db31a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-24 10:50:35--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1227018698 (1.1G) [binary/octet-stream]\n",
      "Saving to: ‘cc.id.300.vec.gz’\n",
      "\n",
      "cc.id.300.vec.gz    100%[===================>]   1.14G  12.3MB/s    in 97s     \n",
      "\n",
      "2020-07-24 10:52:13 (12.1 MB/s) - ‘cc.id.300.vec.gz’ saved [1227018698/1227018698]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CxIp9txeLLo"
   },
   "outputs": [],
   "source": [
    "!gunzip '/content/cc.id.300.vec.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7q0236PuIFu"
   },
   "source": [
    "#### FASTTEXT Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vkwWvO8acl5r",
    "outputId": "03ae7c24-8f69-4a43-ef27-159b191278d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 2000000 word vectors in FastText.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('/content/cc.id.300.vec',encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Total %s word vectors in FastText.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPDYgQRK1RQ_"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCK-zL_EcmBA"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qu-S5C66KUkF"
   },
   "source": [
    "### SET NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnvpO-YaZKz8"
   },
   "outputs": [],
   "source": [
    "num_classes = len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kUXT7HD9fEBS"
   },
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.001)\n",
    "sgd = SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "adagrad = Adagrad(learning_rate=0.01)\n",
    "adadelta = Adadelta(learning_rate=1.0, rho=0.95)\n",
    "rmsprop = RMSprop(learning_rate=0.001, rho=0.9)\n",
    "nadam = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqZctqt6N38R"
   },
   "outputs": [],
   "source": [
    "def predict(sentences, model):\n",
    "  y_prob = model.predict(sentences)\n",
    "  y_prob = y_prob.squeeze()\n",
    "  y_pred = (y_prob > 0.5) \n",
    "  return y_pred\n",
    "\n",
    "def predict_vec(sentences, model):\n",
    "    y2prob = model.predict(x2test_vec)\n",
    "    y2prob = y2prob.squeeze()\n",
    "    y2pred = (y2prob > 0.5) \n",
    "    return y2pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_i7LAULVY1T"
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "  precision = true_positives / (predicted_positives + K.epsilon())\n",
    "  recall = true_positives / (possible_positives + K.epsilon())\n",
    "  f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "  return f1_val\n",
    "\n",
    "def f1_vec(y_true, y2pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y2pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y2pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val_vec = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQyVCLB8K22A"
   },
   "outputs": [],
   "source": [
    "def TP(y_true, y_pred):\n",
    "  tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) # TP\n",
    "  y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "  n_pos = K.sum(y_pos)\n",
    "  y_neg = 1 - y_pos\n",
    "  n_neg = K.sum(y_neg)\n",
    "  n = n_pos + n_neg\n",
    "  return tp/n\n",
    "\n",
    "def TN(y_true, y_pred):\n",
    "  y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "  n_pos = K.sum(y_pos)\n",
    "  y_neg = 1 - y_pos\n",
    "  n_neg = K.sum(y_neg)\n",
    "  n = n_pos + n_neg\n",
    "  y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "  y_pred_neg = 1 - y_pred_pos\n",
    "  tn = K.sum(K.round(K.clip(y_neg * y_pred_neg, 0, 1))) # TN\n",
    "  return tn/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2OSj3a0jXLqJ"
   },
   "source": [
    "### **CNN LSTM TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "Fw-QY_HQsNwn",
    "outputId": "09ecf2cd-9856-4325-d424-d477e155962f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-self-attention\n",
      "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
      "Building wheels for collected packages: keras-self-attention\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=a8defc3e956206dc8bad0452a5811b0fef67f575035557eb3ed89ccf6f963005\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
      "Successfully built keras-self-attention\n",
      "Installing collected packages: keras-self-attention\n",
      "Successfully installed keras-self-attention-0.46.0\n"
     ]
    }
   ],
   "source": [
    "pip install keras-self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A91avU7dsOub"
   },
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "idX7set7qEZw",
    "outputId": "6c32d8d9-7eb0-4674-e8d9-8834f8885b8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_cnn_lstm = load_model('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_unres2.h5', \n",
    "                            custom_objects={'SeqSelfAttention': SeqSelfAttention, 'f1':f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ij_z2vUTAl3q"
   },
   "outputs": [],
   "source": [
    "cnn_lstm_text = test_data['Tokenize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AE4bv46nCVlO"
   },
   "outputs": [],
   "source": [
    "test_tokenizer = Tokenizer()\n",
    "test_tokenizer.fit_on_texts(cnn_lstm_text)\n",
    "test_seq = test_tokenizer.texts_to_sequences(cnn_lstm_text)\n",
    "\n",
    "test_padded = pad_sequences(test_seq, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDxTLHsUqdM9"
   },
   "outputs": [],
   "source": [
    "predict_cnn_lstm = predict(test_padded, model_cnn_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "dVE-9tKqu2-H",
    "outputId": "c62e8436-226b-44d0-fc44-19a871f2d1b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       ...,\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False]])"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cnn_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTSqE_tozPtm"
   },
   "outputs": [],
   "source": [
    "predict_sentiment_cnn_lstm = pd.DataFrame(predict_cnn_lstm, columns=['Negative', 'Neutral', 'Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "5uuvj_l84HJI",
    "outputId": "ec7623bd-0194-48a4-e4ae-fe71929973c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Negative  Neutral  Positive\n",
       "0        False     True     False\n",
       "1         True    False     False\n",
       "2        False    False      True\n",
       "3        False    False      True\n",
       "4        False     True     False\n",
       "...        ...      ...       ...\n",
       "1196     False     True     False\n",
       "1197     False     True     False\n",
       "1198     False     True     False\n",
       "1199     False     True     False\n",
       "1200     False     True     False\n",
       "\n",
       "[1201 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment_cnn_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "-zpJLsg0wFGr",
    "outputId": "33c28883-8de0-48f2-8c09-845ce986321a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Neutral\n",
       "1       Negative\n",
       "2       Positive\n",
       "3       Positive\n",
       "4        Neutral\n",
       "          ...   \n",
       "1196     Neutral\n",
       "1197     Neutral\n",
       "1198     Neutral\n",
       "1199     Neutral\n",
       "1200     Neutral\n",
       "Length: 1201, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_sentiment (row):\n",
    "  if row['Negative'] == True :\n",
    "    return 'Negative'\n",
    "  if row['Neutral'] == True :\n",
    "    return 'Neutral'\n",
    "  if row['Positive'] == True :\n",
    "    return 'Positive'\n",
    "  return None\n",
    "\n",
    "predict_sentiment_cnn_lstm.apply(lambda row: label_sentiment(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpMWUSsgOC6V"
   },
   "outputs": [],
   "source": [
    "predict_df['CNN-LSTM Predict Sentiment'] = predict_sentiment_cnn_lstm.apply(lambda row: label_sentiment(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "Ut5RiBspODGr",
    "outputId": "26276030-d381-4fd8-fe5c-834b7179dd66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Predict Sentiment</th>\n",
       "      <th>CNN-LSTM Predict Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-30 22:44:47+00:00</td>\n",
       "      <td>Ya, Cina MARANATHA karena peduli soal Saya dan...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-30 22:44:09+00:00</td>\n",
       "      <td>Kalau virus Corona itu, berasal atau karena.. ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-30 20:12:20+00:00</td>\n",
       "      <td>unpar? ciputra? atmajaya? sampoerna? MARANATHA...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-30 18:39:08+00:00</td>\n",
       "      <td>kenapa tidak MARANATHA Bandung saja</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-30 12:35:27+00:00</td>\n",
       "      <td>Di Unpar dan MARANATHA Bandung. tinggal di kot...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2020-02-02 11:47:46+00:00</td>\n",
       "      <td>Angkringan marnat bisa tambah bayar tidak</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2020-02-02 04:47:26+00:00</td>\n",
       "      <td>Teman dia, marnat husein hanya langkah</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>2020-02-01 20:47:23+00:00</td>\n",
       "      <td>Senin temu di marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>2020-02-01 14:43:44+00:00</td>\n",
       "      <td>Tolong info,kost bagus daerah cimahi atau bela...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2020-02-01 07:17:41+00:00</td>\n",
       "      <td>ya untuk apa dia saja tuntut ilmu ke marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime  ... CNN-LSTM Predict Sentiment\n",
       "0     2020-05-30 22:44:47+00:00  ...                    Neutral\n",
       "1     2020-05-30 22:44:09+00:00  ...                   Negative\n",
       "2     2020-05-30 20:12:20+00:00  ...                   Positive\n",
       "3     2020-05-30 18:39:08+00:00  ...                   Positive\n",
       "4     2020-05-30 12:35:27+00:00  ...                    Neutral\n",
       "...                         ...  ...                        ...\n",
       "1196  2020-02-02 11:47:46+00:00  ...                    Neutral\n",
       "1197  2020-02-02 04:47:26+00:00  ...                    Neutral\n",
       "1198  2020-02-01 20:47:23+00:00  ...                    Neutral\n",
       "1199  2020-02-01 14:43:44+00:00  ...                    Neutral\n",
       "1200  2020-02-01 07:17:41+00:00  ...                    Neutral\n",
       "\n",
       "[1201 rows x 5 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ltsg7eYUO0s"
   },
   "outputs": [],
   "source": [
    "#predict_df.to_excel('/content/drive/My Drive/Colab Notebooks/tesis_mnb_cnn_predict_norm.xls', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "yTYI2v8FV13T",
    "outputId": "edc51924-f297-4c5a-aa9e-03c6c39abf6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "model_cnn_lstm_test_res = load_model('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_res.h5', \n",
    "                            custom_objects={'SeqSelfAttention': SeqSelfAttention, 'f1':f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AWKn0drKV2EE"
   },
   "outputs": [],
   "source": [
    "predict_cnn_lstm_test_res = predict(test_padded, model_cnn_lstm_test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "TG1dTDEmV2Sb",
    "outputId": "80d78c55-9347-4d26-952e-715bf962126d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       ...,\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False]])"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cnn_lstm_test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "huK02vm2V2jQ"
   },
   "outputs": [],
   "source": [
    "predict_sentiment_cnn_lstm_res = pd.DataFrame(predict_cnn_lstm_test_res, columns=['Negative', 'Neutral', 'Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "txEJmH4XV2zu",
    "outputId": "a280544a-8d74-4950-c308-8ab8f66c6d38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Negative  Neutral  Positive\n",
       "0        False     True     False\n",
       "1        False     True     False\n",
       "2        False    False      True\n",
       "3        False     True     False\n",
       "4        False     True     False\n",
       "...        ...      ...       ...\n",
       "1196     False     True     False\n",
       "1197     False     True     False\n",
       "1198     False     True     False\n",
       "1199     False     True     False\n",
       "1200     False     True     False\n",
       "\n",
       "[1201 rows x 3 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment_cnn_lstm_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ub5ECEwEWrB5"
   },
   "outputs": [],
   "source": [
    "predict_df['CNN-LSTM-SmoteTomek Predict Sentiment'] = predict_sentiment_cnn_lstm_res.apply(lambda row: label_sentiment(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "id": "q4_9uRutWrO_",
    "outputId": "1f3e09d2-ac50-41ec-85a9-5106ca6f4669"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Predict Sentiment</th>\n",
       "      <th>CNN-LSTM Predict Sentiment</th>\n",
       "      <th>CNN-LSTM-SmoteTomek Predict Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-30 22:44:47+00:00</td>\n",
       "      <td>Ya, Cina MARANATHA karena peduli soal Saya dan...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-30 22:44:09+00:00</td>\n",
       "      <td>Kalau virus Corona itu, berasal atau karena.. ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-30 20:12:20+00:00</td>\n",
       "      <td>unpar? ciputra? atmajaya? sampoerna? MARANATHA...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-30 18:39:08+00:00</td>\n",
       "      <td>kenapa tidak MARANATHA Bandung saja</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-30 12:35:27+00:00</td>\n",
       "      <td>Di Unpar dan MARANATHA Bandung. tinggal di kot...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2020-02-02 11:47:46+00:00</td>\n",
       "      <td>Angkringan marnat bisa tambah bayar tidak</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2020-02-02 04:47:26+00:00</td>\n",
       "      <td>Teman dia, marnat husein hanya langkah</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>2020-02-01 20:47:23+00:00</td>\n",
       "      <td>Senin temu di marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>2020-02-01 14:43:44+00:00</td>\n",
       "      <td>Tolong info,kost bagus daerah cimahi atau bela...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2020-02-01 07:17:41+00:00</td>\n",
       "      <td>ya untuk apa dia saja tuntut ilmu ke marnat</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime  ... CNN-LSTM-SmoteTomek Predict Sentiment\n",
       "0     2020-05-30 22:44:47+00:00  ...                               Neutral\n",
       "1     2020-05-30 22:44:09+00:00  ...                               Neutral\n",
       "2     2020-05-30 20:12:20+00:00  ...                              Positive\n",
       "3     2020-05-30 18:39:08+00:00  ...                               Neutral\n",
       "4     2020-05-30 12:35:27+00:00  ...                               Neutral\n",
       "...                         ...  ...                                   ...\n",
       "1196  2020-02-02 11:47:46+00:00  ...                               Neutral\n",
       "1197  2020-02-02 04:47:26+00:00  ...                               Neutral\n",
       "1198  2020-02-01 20:47:23+00:00  ...                               Neutral\n",
       "1199  2020-02-01 14:43:44+00:00  ...                               Neutral\n",
       "1200  2020-02-01 07:17:41+00:00  ...                               Neutral\n",
       "\n",
       "[1201 rows x 6 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQ0BN4I-XBkL"
   },
   "outputs": [],
   "source": [
    "predict_df.to_excel('/content/drive/My Drive/Colab Notebooks/tesis_mnb_cnn_res_predict_sum_norm_TEST.xls', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAm3Qrvcg-mo"
   },
   "source": [
    "### **NN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HPvhpNZ36-0"
   },
   "source": [
    "### **RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "Eh8gmqo1UODT",
    "outputId": "8c7a1263-bba8-46ff-f5c0-0a41267883c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RNN UNRES\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 300)           1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 16)                5072      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,910,123\n",
      "Trainable params: 1,910,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model RNN RES\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 300)           1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 16)                5072      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,910,123\n",
      "Trainable params: 1,910,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.5\n",
    "output_size = 16\n",
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "rnn_activation = 'tanh' #'relu' \n",
    "\n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "#emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "#                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "s_drop = SpatialDropout1D(dropout_rate)(embedding)\n",
    "rnn = SimpleRNN(units=output_size, activation=rnn_activation, return_sequences=True)(s_drop)\n",
    "rnn = SimpleRNN(units=output_size, activation=rnn_activation, return_sequences=False)(s_drop)\n",
    "drop = Dropout(dropout_rate)(rnn)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "model_rnn_unres = Model(inputs, output)\n",
    "model_rnn_res = Model(inputs, output)\n",
    "\n",
    "\n",
    "model_rnn_unres.compile(loss='categorical_crossentropy', metrics=['acc', f1], optimizer=rmsprop)\n",
    "model_rnn_res.compile(loss='categorical_crossentropy', metrics=['acc', f1], optimizer=rmsprop)\n",
    "\n",
    "callbacks_unres = [EarlyStopping(monitor='val_loss', verbose= 1, patience=20, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=0.001)]\n",
    "\n",
    "callbacks_res = [EarlyStopping(monitor='val_loss', verbose= 1, patience=20, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_res.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=0.001)]\n",
    "\n",
    "print('Model RNN UNRES')\n",
    "model_rnn_unres.summary()\n",
    "print('Model RNN RES')\n",
    "model_rnn_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E-Yk2vbjgMO6",
    "outputId": "2d3d77dd-cc5e-4716-ae69-5f9750615bfb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3756 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.7713 - acc: 0.7183 - f1: 0.7021 - val_loss: 0.6561 - val_acc: 0.7640 - val_f1: 0.7669\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65612, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres.h5\n",
      "Epoch 2/100\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.5800 - acc: 0.7923 - f1: 0.7848 - val_loss: 0.6556 - val_acc: 0.7453 - val_f1: 0.7386\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65612 to 0.65560, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres.h5\n",
      "Epoch 3/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.4639 - acc: 0.8384 - f1: 0.8351 - val_loss: 0.6594 - val_acc: 0.7739 - val_f1: 0.7552\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.65560\n",
      "Epoch 4/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.3838 - acc: 0.8677 - f1: 0.8669 - val_loss: 0.6731 - val_acc: 0.7702 - val_f1: 0.7705\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.65560\n",
      "Epoch 5/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.3311 - acc: 0.8903 - f1: 0.8904 - val_loss: 0.7185 - val_acc: 0.7565 - val_f1: 0.7468\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.65560\n",
      "Epoch 6/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.2947 - acc: 0.9073 - f1: 0.9069 - val_loss: 0.7430 - val_acc: 0.7491 - val_f1: 0.7358\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.65560\n",
      "Epoch 7/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.2786 - acc: 0.9113 - f1: 0.9105 - val_loss: 0.7649 - val_acc: 0.7528 - val_f1: 0.7411\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.65560\n",
      "Epoch 8/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.2479 - acc: 0.9247 - f1: 0.9242 - val_loss: 0.7767 - val_acc: 0.7714 - val_f1: 0.7571\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.65560\n",
      "Epoch 9/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.2250 - acc: 0.9273 - f1: 0.9269 - val_loss: 0.8376 - val_acc: 0.7640 - val_f1: 0.7537\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.65560\n",
      "Epoch 10/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.2203 - acc: 0.9318 - f1: 0.9318 - val_loss: 0.8582 - val_acc: 0.7453 - val_f1: 0.7343\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.65560\n",
      "Epoch 11/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.1974 - acc: 0.9417 - f1: 0.9398 - val_loss: 0.9434 - val_acc: 0.7056 - val_f1: 0.6965\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.65560\n",
      "Epoch 12/100\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.1952 - acc: 0.9353 - f1: 0.9350 - val_loss: 0.9087 - val_acc: 0.7528 - val_f1: 0.7434\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.65560\n",
      "Epoch 13/100\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.1769 - acc: 0.9414 - f1: 0.9427 - val_loss: 0.9263 - val_acc: 0.7590 - val_f1: 0.7470\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.65560\n",
      "Epoch 14/100\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.1744 - acc: 0.9449 - f1: 0.9452 - val_loss: 0.9251 - val_acc: 0.7441 - val_f1: 0.7317\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.65560\n",
      "Epoch 15/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.1671 - acc: 0.9438 - f1: 0.9442 - val_loss: 0.9659 - val_acc: 0.7466 - val_f1: 0.7358\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.65560\n",
      "Epoch 16/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.1610 - acc: 0.9465 - f1: 0.9473 - val_loss: 0.9725 - val_acc: 0.7677 - val_f1: 0.7698\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.65560\n",
      "Epoch 17/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.1503 - acc: 0.9505 - f1: 0.9504 - val_loss: 1.0066 - val_acc: 0.7516 - val_f1: 0.7398\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.65560\n",
      "Epoch 18/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.1442 - acc: 0.9550 - f1: 0.9556 - val_loss: 1.0167 - val_acc: 0.7441 - val_f1: 0.7335\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.65560\n",
      "Epoch 19/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.1503 - acc: 0.9510 - f1: 0.9515 - val_loss: 1.0503 - val_acc: 0.7528 - val_f1: 0.7410\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.65560\n",
      "Epoch 20/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.1220 - acc: 0.9606 - f1: 0.9597 - val_loss: 1.0248 - val_acc: 0.7627 - val_f1: 0.7530\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.65560\n",
      "Epoch 21/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.1276 - acc: 0.9614 - f1: 0.9614 - val_loss: 1.0401 - val_acc: 0.7553 - val_f1: 0.7448\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.65560\n",
      "Epoch 22/100\n",
      "3756/3756 [==============================] - 18s 5ms/step - loss: 0.1239 - acc: 0.9579 - f1: 0.9579 - val_loss: 1.0662 - val_acc: 0.7602 - val_f1: 0.7504\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.65560\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_rnn_unres = model_rnn_unres.fit(x_train, y_train, batch_size=12, epochs=100, \n",
    "                                            validation_data=(x_val, y_val), callbacks=callbacks_unres, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uwtCigXnLnSE",
    "outputId": "65b7b517-a056-472e-e8a3-7550d0eda97e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8145 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 1.0178 - acc: 0.5510 - f1: 0.5027 - val_loss: 0.9581 - val_acc: 0.6012 - val_f1: 0.5607\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.95807, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_res.h5\n",
      "Epoch 2/100\n",
      "8145/8145 [==============================] - 43s 5ms/step - loss: 0.7876 - acc: 0.6519 - f1: 0.6136 - val_loss: 0.9646 - val_acc: 0.6149 - val_f1: 0.5733\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.95807\n",
      "Epoch 3/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.7134 - acc: 0.6977 - f1: 0.6703 - val_loss: 1.0632 - val_acc: 0.5888 - val_f1: 0.5749\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.95807\n",
      "Epoch 4/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.6555 - acc: 0.7236 - f1: 0.7085 - val_loss: 1.2092 - val_acc: 0.5689 - val_f1: 0.5486\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.95807\n",
      "Epoch 5/100\n",
      "8145/8145 [==============================] - 43s 5ms/step - loss: 0.6040 - acc: 0.7556 - f1: 0.7470 - val_loss: 1.2045 - val_acc: 0.5789 - val_f1: 0.5593\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.95807\n",
      "Epoch 6/100\n",
      "8145/8145 [==============================] - 43s 5ms/step - loss: 0.5859 - acc: 0.7675 - f1: 0.7574 - val_loss: 1.1709 - val_acc: 0.6062 - val_f1: 0.5792\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.95807\n",
      "Epoch 7/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.5392 - acc: 0.7899 - f1: 0.7838 - val_loss: 1.2836 - val_acc: 0.5478 - val_f1: 0.5260\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.95807\n",
      "Epoch 8/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.5208 - acc: 0.7912 - f1: 0.7886 - val_loss: 1.2131 - val_acc: 0.6099 - val_f1: 0.5962\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.95807\n",
      "Epoch 9/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.5037 - acc: 0.8106 - f1: 0.8069 - val_loss: 1.3089 - val_acc: 0.5764 - val_f1: 0.5793\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.95807\n",
      "Epoch 10/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.4701 - acc: 0.8250 - f1: 0.8202 - val_loss: 1.3313 - val_acc: 0.5863 - val_f1: 0.5727\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.95807\n",
      "Epoch 11/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.4613 - acc: 0.8276 - f1: 0.8254 - val_loss: 1.3357 - val_acc: 0.5839 - val_f1: 0.5826\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.95807\n",
      "Epoch 12/100\n",
      "8145/8145 [==============================] - 43s 5ms/step - loss: 0.4369 - acc: 0.8384 - f1: 0.8361 - val_loss: 1.4519 - val_acc: 0.5578 - val_f1: 0.5558\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.95807\n",
      "Epoch 13/100\n",
      "8145/8145 [==============================] - 42s 5ms/step - loss: 0.4261 - acc: 0.8428 - f1: 0.8408 - val_loss: 1.3996 - val_acc: 0.5627 - val_f1: 0.5648\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.95807\n",
      "Epoch 14/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.4182 - acc: 0.8422 - f1: 0.8399 - val_loss: 1.5055 - val_acc: 0.5590 - val_f1: 0.5312\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.95807\n",
      "Epoch 15/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.4042 - acc: 0.8548 - f1: 0.8525 - val_loss: 1.5215 - val_acc: 0.5553 - val_f1: 0.5350\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.95807\n",
      "Epoch 16/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.3972 - acc: 0.8577 - f1: 0.8550 - val_loss: 1.4633 - val_acc: 0.5789 - val_f1: 0.5585\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.95807\n",
      "Epoch 17/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.3756 - acc: 0.8630 - f1: 0.8608 - val_loss: 1.5907 - val_acc: 0.5342 - val_f1: 0.5216\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.95807\n",
      "Epoch 18/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.3614 - acc: 0.8696 - f1: 0.8687 - val_loss: 1.5537 - val_acc: 0.5540 - val_f1: 0.5458\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.95807\n",
      "Epoch 19/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.3696 - acc: 0.8648 - f1: 0.8642 - val_loss: 1.5696 - val_acc: 0.5466 - val_f1: 0.5306\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.95807\n",
      "Epoch 20/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.3577 - acc: 0.8727 - f1: 0.8694 - val_loss: 1.5018 - val_acc: 0.5863 - val_f1: 0.5697\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.95807\n",
      "Epoch 21/100\n",
      "8145/8145 [==============================] - 44s 5ms/step - loss: 0.3529 - acc: 0.8719 - f1: 0.8701 - val_loss: 1.4951 - val_acc: 0.5776 - val_f1: 0.5680\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.95807\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_rnn_res = model_rnn_res.fit(x_res, y_res, batch_size=12, epochs=100, \n",
    "                                        validation_data=(x_val, y_val), callbacks=callbacks_res, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "tWG-jfs7aFlh",
    "outputId": "fd44909e-1864-409b-ef51-03c44c79a729"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model_rnn_unres, to_file='/content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres2.png', \n",
    "           show_shapes=False, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNlKx3wraGeY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "oCCZMLdzHSr2",
    "outputId": "c69b40f6-d841-4807-9dad-f0eeddbc647e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RNN UNRES VEC\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 1000, 300)         1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_7 (Spatial (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 16)                5072      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,910,123\n",
      "Trainable params: 1,910,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model RNN RES VEC\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 1000, 300)         1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_7 (Spatial (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 16)                5072      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,910,123\n",
      "Trainable params: 1,910,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.2\n",
    "output_size = 16\n",
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "maxlen_vec = td\n",
    "rnn_activation = 'tanh' #'relu' \n",
    "\n",
    "inputs = Input(shape=(maxlen_vec,))\n",
    "#embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           # EMBEDDING_DIM,\n",
    "                            #weights=[embedding_matrix],\n",
    "                           # trainable=True)\n",
    "#embedding = embedding_layer(inputs)\n",
    "\n",
    "emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "s_drop = SpatialDropout1D(dropout_rate)(emb2)\n",
    "rnn = SimpleRNN(\n",
    "    units=output_size, \n",
    "    activation=rnn_activation, \n",
    "    kernel_regularizer=regularizers.l2(0.1))(s_drop)\n",
    "drop = Dropout(dropout_rate)(rnn)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "model_rnn_unres_vec = Model(inputs, output)\n",
    "model_rnn_res_vec = Model(inputs, output)\n",
    "\n",
    "\n",
    "model_rnn_unres_vec.compile(loss='categorical_crossentropy', metrics=['acc', f1_vec], optimizer=Adam(learning_rate=1e-3))\n",
    "model_rnn_res_vec.compile(loss='categorical_crossentropy', metrics=['acc', f1_vec], optimizer=Adam(learning_rate=1e-3))\n",
    "\n",
    "callbacks_unres_vec = [EarlyStopping(monitor='val_loss', verbose= 1, patience=20, mode='auto'), \n",
    "                       ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres_vec.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                       ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=0.001)]\n",
    "\n",
    "callbacks_res_vec = [EarlyStopping(monitor='val_loss', verbose= 1, patience=20, mode='auto'), \n",
    "                     ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_res_vec.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                     ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=0.001)]\n",
    "\n",
    "print('Model RNN UNRES VEC')\n",
    "model_rnn_unres_vec.summary()\n",
    "print('Model RNN RES VEC')\n",
    "model_rnn_res_vec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "noETNCfjlJbP",
    "outputId": "02b7d002-d1ab-475e-d883-7c4734842d8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4025 samples, validate on 1006 samples\n",
      "Epoch 1/100\n",
      "4025/4025 [==============================] - 102s 25ms/step - loss: 1.4740 - acc: 0.7180 - f1_vec: 0.7070 - val_loss: 0.8118 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81179, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres_vec.h5\n",
      "Epoch 2/100\n",
      "4025/4025 [==============================] - 103s 26ms/step - loss: 0.8105 - acc: 0.7262 - f1_vec: 0.7211 - val_loss: 0.7986 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.81179 to 0.79863, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres_vec.h5\n",
      "Epoch 3/100\n",
      "4025/4025 [==============================] - 102s 25ms/step - loss: 0.7913 - acc: 0.7277 - f1_vec: 0.7253 - val_loss: 0.7798 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.79863 to 0.77979, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres_vec.h5\n",
      "Epoch 4/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7869 - acc: 0.7277 - f1_vec: 0.7267 - val_loss: 0.7773 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.77979 to 0.77732, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres_vec.h5\n",
      "Epoch 5/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7898 - acc: 0.7277 - f1_vec: 0.7245 - val_loss: 0.7762 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.77732 to 0.77618, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres_vec.h5\n",
      "Epoch 6/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7798 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7974 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.77618\n",
      "Epoch 7/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7788 - acc: 0.7277 - f1_vec: 0.7268 - val_loss: 0.7655 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.77618 to 0.76547, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres_vec.h5\n",
      "Epoch 8/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7795 - acc: 0.7277 - f1_vec: 0.7276 - val_loss: 0.7657 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.76547\n",
      "Epoch 9/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7759 - acc: 0.7277 - f1_vec: 0.7280 - val_loss: 0.7665 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.76547\n",
      "Epoch 10/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7791 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7713 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.76547\n",
      "Epoch 11/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7763 - acc: 0.7277 - f1_vec: 0.7271 - val_loss: 0.7654 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.76547 to 0.76536, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_unres_vec.h5\n",
      "Epoch 12/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7837 - acc: 0.7277 - f1_vec: 0.7276 - val_loss: 0.7689 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.76536\n",
      "Epoch 13/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7932 - acc: 0.7277 - f1_vec: 0.7268 - val_loss: 0.7667 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.76536\n",
      "Epoch 14/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7746 - acc: 0.7277 - f1_vec: 0.7279 - val_loss: 0.7654 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.76536\n",
      "Epoch 15/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.8337 - acc: 0.7275 - f1_vec: 0.7191 - val_loss: 0.7888 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.76536\n",
      "Epoch 16/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.7899 - acc: 0.7277 - f1_vec: 0.7276 - val_loss: 0.7722 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.76536\n",
      "Epoch 17/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.8413 - acc: 0.7225 - f1_vec: 0.7013 - val_loss: 0.9903 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.76536\n",
      "Epoch 18/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.8450 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7814 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.76536\n",
      "Epoch 19/100\n",
      "4025/4025 [==============================] - 101s 25ms/step - loss: 0.8074 - acc: 0.7267 - f1_vec: 0.7068 - val_loss: 0.8555 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.76536\n",
      "Epoch 20/100\n",
      "4025/4025 [==============================] - 102s 25ms/step - loss: 0.8285 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7979 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.76536\n",
      "Epoch 21/100\n",
      "4025/4025 [==============================] - 102s 25ms/step - loss: 0.7911 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7851 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.76536\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_rnn_unres_vec = model_rnn_unres_vec.fit(x2train_vec, y2train, batch_size=12, epochs=100, \n",
    "                                                    validation_data=(x2val_vec, y2val), callbacks=callbacks_unres_vec, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "colab_type": "code",
    "id": "dpWK8o2LQrVE",
    "outputId": "05344353-4706-492d-9dc8-34f554d98048"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8786 samples, validate on 1006 samples\n",
      "Epoch 1/100\n",
      "8786/8786 [==============================] - 252s 29ms/step - loss: 1.1536 - acc: 0.3270 - f1_vec: 0.0303 - val_loss: 0.9806 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.98055, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/RNN/tesis_model_rnn_res_vec.h5\n",
      "Epoch 2/100\n",
      "8786/8786 [==============================] - 254s 29ms/step - loss: 1.1839 - acc: 0.3407 - f1_vec: 0.0013 - val_loss: 1.1379 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.98055\n",
      "Epoch 3/100\n",
      "8786/8786 [==============================] - 254s 29ms/step - loss: 1.1365 - acc: 0.3408 - f1_vec: 0.0000e+00 - val_loss: 1.0435 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.98055\n",
      "Epoch 4/100\n",
      "8786/8786 [==============================] - 263s 30ms/step - loss: 1.1222 - acc: 0.3326 - f1_vec: 2.0989e-04 - val_loss: 1.1382 - val_acc: 0.1809 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.98055\n",
      "Epoch 5/100\n",
      "8786/8786 [==============================] - 260s 30ms/step - loss: 1.1169 - acc: 0.3366 - f1_vec: 0.0000e+00 - val_loss: 1.0708 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.98055\n",
      "Epoch 6/100\n",
      "8786/8786 [==============================] - 261s 30ms/step - loss: 1.1144 - acc: 0.3399 - f1_vec: 0.0000e+00 - val_loss: 1.0779 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.98055\n",
      "Epoch 7/100\n",
      "8786/8786 [==============================] - 261s 30ms/step - loss: 1.1082 - acc: 0.3326 - f1_vec: 0.0000e+00 - val_loss: 1.0446 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.98055\n",
      "Epoch 8/100\n",
      "8786/8786 [==============================] - 261s 30ms/step - loss: 1.1258 - acc: 0.3397 - f1_vec: 0.0078 - val_loss: 1.1324 - val_acc: 0.0915 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.98055\n",
      "Epoch 9/100\n",
      "8786/8786 [==============================] - 262s 30ms/step - loss: 1.1800 - acc: 0.3294 - f1_vec: 0.0106 - val_loss: 1.2010 - val_acc: 0.1809 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.98055\n",
      "Epoch 10/100\n",
      "8786/8786 [==============================] - 263s 30ms/step - loss: 1.1748 - acc: 0.3384 - f1_vec: 0.0000e+00 - val_loss: 1.2219 - val_acc: 0.1809 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.98055\n",
      "Epoch 11/100\n",
      "8786/8786 [==============================] - 262s 30ms/step - loss: 1.1577 - acc: 0.3402 - f1_vec: 0.0000e+00 - val_loss: 1.1505 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.98055\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_rnn_res_vec = model_rnn_res_vec.fit(x2res, y2res, batch_size=12, epochs=100, \n",
    "                                                validation_data=(x2val_vec, y2val), callbacks=callbacks_res_vec, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IDcLu6E2NXl0"
   },
   "source": [
    "### **GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "l3Y6JosERZST",
    "outputId": "b60471f4-b247-477f-ff51-0b140d9731ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GRU UNRES\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 50, 300)           1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_7 (Spatial (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 16)                15216     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,920,267\n",
      "Trainable params: 1,920,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model GRU RES\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 50, 300)           1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_7 (Spatial (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 16)                15216     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,920,267\n",
      "Trainable params: 1,920,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.5\n",
    "output_size = 16\n",
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "    \n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "#emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "#                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "s_drop = SpatialDropout1D(dropout_rate)(embedding)\n",
    "gru = GRU(units=output_size, return_sequences=True)(s_drop)\n",
    "gru = GRU(units=output_size, return_sequences=False)(s_drop)\n",
    "drop = Dropout(dropout_rate)(gru)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "model_gru_unres = Model(inputs, output)\n",
    "model_gru_res = Model(inputs, output)\n",
    "\n",
    "model_gru_unres.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc', f1])\n",
    "model_gru_res.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc', f1])\n",
    "\n",
    "callbacks_unres = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "callbacks_res = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                 ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_res.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "print('Model GRU UNRES')\n",
    "model_gru_unres.summary()\n",
    "print('Model GRU RES')\n",
    "model_gru_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "colab_type": "code",
    "id": "WtM2ondXqR-F",
    "outputId": "c3da802c-5b3e-4563-fc44-d4f2e4e685da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3756 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "3756/3756 [==============================] - 57s 15ms/step - loss: 0.7090 - acc: 0.7460 - f1: 0.7222 - val_loss: 0.6062 - val_acc: 0.7677 - val_f1: 0.7697\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60624, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres.h5\n",
      "Epoch 2/100\n",
      "3756/3756 [==============================] - 56s 15ms/step - loss: 0.4997 - acc: 0.8198 - f1: 0.8150 - val_loss: 0.5614 - val_acc: 0.7888 - val_f1: 0.7772\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60624 to 0.56144, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres.h5\n",
      "Epoch 3/100\n",
      "3756/3756 [==============================] - 56s 15ms/step - loss: 0.3700 - acc: 0.8717 - f1: 0.8654 - val_loss: 0.5662 - val_acc: 0.7950 - val_f1: 0.7844\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.56144\n",
      "Epoch 4/100\n",
      "3756/3756 [==============================] - 56s 15ms/step - loss: 0.2731 - acc: 0.9058 - f1: 0.9032 - val_loss: 0.6183 - val_acc: 0.7988 - val_f1: 0.8005\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.56144\n",
      "Epoch 5/100\n",
      "3756/3756 [==============================] - 56s 15ms/step - loss: 0.2252 - acc: 0.9225 - f1: 0.9222 - val_loss: 0.6680 - val_acc: 0.7876 - val_f1: 0.7874\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.56144\n",
      "Epoch 6/100\n",
      "3756/3756 [==============================] - 56s 15ms/step - loss: 0.1952 - acc: 0.9326 - f1: 0.9326 - val_loss: 0.7347 - val_acc: 0.7814 - val_f1: 0.7696\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.56144\n",
      "Epoch 7/100\n",
      "3756/3756 [==============================] - 56s 15ms/step - loss: 0.1607 - acc: 0.9507 - f1: 0.9501 - val_loss: 0.7858 - val_acc: 0.7727 - val_f1: 0.7745\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56144\n",
      "Epoch 8/100\n",
      "3756/3756 [==============================] - 57s 15ms/step - loss: 0.1393 - acc: 0.9579 - f1: 0.9581 - val_loss: 0.8243 - val_acc: 0.7652 - val_f1: 0.7555\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.56144\n",
      "Epoch 9/100\n",
      "3756/3756 [==============================] - 56s 15ms/step - loss: 0.1237 - acc: 0.9601 - f1: 0.9584 - val_loss: 0.9120 - val_acc: 0.7714 - val_f1: 0.7741\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.56144\n",
      "Epoch 10/100\n",
      "3756/3756 [==============================] - 56s 15ms/step - loss: 0.1151 - acc: 0.9638 - f1: 0.9631 - val_loss: 0.9552 - val_acc: 0.7640 - val_f1: 0.7672\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.56144\n",
      "Epoch 11/100\n",
      "3756/3756 [==============================] - 56s 15ms/step - loss: 0.1032 - acc: 0.9678 - f1: 0.9678 - val_loss: 1.0160 - val_acc: 0.7702 - val_f1: 0.7731\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.56144\n",
      "Epoch 12/100\n",
      "3756/3756 [==============================] - 56s 15ms/step - loss: 0.0852 - acc: 0.9728 - f1: 0.9725 - val_loss: 1.0422 - val_acc: 0.7615 - val_f1: 0.7649\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.56144\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_gru_unres = model_gru_unres.fit(x_train, y_train, batch_size=12, epochs=100,\n",
    "                                            validation_data=(x_val, y_val), callbacks=callbacks_unres, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "colab_type": "code",
    "id": "wkH1K6lJLw39",
    "outputId": "a36b6ccd-e6f8-4671-810e-b02e5b76c2a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8145 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "8145/8145 [==============================] - 112s 14ms/step - loss: 0.9606 - acc: 0.5785 - f1: 0.5328 - val_loss: 0.9644 - val_acc: 0.6025 - val_f1: 0.5819\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.96442, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_res.h5\n",
      "Epoch 2/100\n",
      "8145/8145 [==============================] - 111s 14ms/step - loss: 0.7248 - acc: 0.6819 - f1: 0.6465 - val_loss: 1.1201 - val_acc: 0.5801 - val_f1: 0.5471\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.96442\n",
      "Epoch 3/100\n",
      "8145/8145 [==============================] - 110s 14ms/step - loss: 0.6112 - acc: 0.7449 - f1: 0.7303 - val_loss: 1.2435 - val_acc: 0.5640 - val_f1: 0.5534\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.96442\n",
      "Epoch 4/100\n",
      "8145/8145 [==============================] - 111s 14ms/step - loss: 0.5388 - acc: 0.7849 - f1: 0.7730 - val_loss: 1.3620 - val_acc: 0.5677 - val_f1: 0.5518\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.96442\n",
      "Epoch 5/100\n",
      "8145/8145 [==============================] - 110s 13ms/step - loss: 0.4766 - acc: 0.8081 - f1: 0.8034 - val_loss: 1.6538 - val_acc: 0.5155 - val_f1: 0.4999\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.96442\n",
      "Epoch 6/100\n",
      "8145/8145 [==============================] - 109s 13ms/step - loss: 0.4219 - acc: 0.8432 - f1: 0.8403 - val_loss: 1.6167 - val_acc: 0.5503 - val_f1: 0.5335\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.96442\n",
      "Epoch 7/100\n",
      "8145/8145 [==============================] - 110s 13ms/step - loss: 0.3778 - acc: 0.8527 - f1: 0.8504 - val_loss: 1.8664 - val_acc: 0.5242 - val_f1: 0.5085\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.96442\n",
      "Epoch 8/100\n",
      "8145/8145 [==============================] - 109s 13ms/step - loss: 0.3470 - acc: 0.8767 - f1: 0.8736 - val_loss: 1.8373 - val_acc: 0.5342 - val_f1: 0.5178\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.96442\n",
      "Epoch 9/100\n",
      "2208/8145 [=======>......................] - ETA: 1:19 - loss: 0.2939 - acc: 0.8976 - f1: 0.8970"
     ]
    }
   ],
   "source": [
    "tesis_model_gru_res = model_gru_res.fit(x_res, y_res, batch_size=12, epochs=100, \n",
    "                                        validation_data=(x_val, y_val), callbacks=callbacks_res, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "ud3dhUGlgGOK",
    "outputId": "716333ce-51ee-4c76-f261-b22fc0e773ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model_gru_unres, to_file='/content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres2.png', \n",
    "           show_shapes=False, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "dFZ3v1TSH6fv",
    "outputId": "21633299-bf41-45ba-9462-71a55252d3ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GRU UNRES VEC\n",
      "Model: \"model_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 1000, 300)         1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_13 (Spatia (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 16)                15216     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,920,267\n",
      "Trainable params: 1,920,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "          \n",
      "Model GRU RES VEC\n",
      "Model: \"model_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 1000, 300)         1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_13 (Spatia (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 16)                15216     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,920,267\n",
      "Trainable params: 1,920,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.2\n",
    "output_size = 16\n",
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "maxlen_vec = td\n",
    "    \n",
    "inputs = Input(shape=(maxlen_vec,))\n",
    "#embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           # EMBEDDING_DIM,\n",
    "                            #weights=[embedding_matrix],\n",
    "                           # trainable=True)\n",
    "#embedding = embedding_layer(inputs)\n",
    "\n",
    "emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "s_drop = SpatialDropout1D(dropout_rate)(emb2)\n",
    "gru = GRU(units=output_size, return_sequences=False, kernel_regularizer=regularizers.l2(0.1))(s_drop)\n",
    "drop = Dropout(dropout_rate)(gru)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "model_gru_unres_vec = Model(inputs, output)\n",
    "model_gru_res_vec = Model(inputs, output)\n",
    "\n",
    "model_gru_unres_vec.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['acc', f1_vec])\n",
    "model_gru_res_vec.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['acc', f1_vec])\n",
    "\n",
    "callbacks_unres_vec = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                       ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
    "                       ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "callbacks_res_vec = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                     ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_res_vec.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
    "                     ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "print('Model GRU UNRES VEC')\n",
    "model_gru_unres_vec.summary()\n",
    "print(' '*10)\n",
    "print('Model GRU RES VEC')\n",
    "model_gru_res_vec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eoSdWo_xqmI7",
    "outputId": "6be57f61-9929-4784-de48-565ca2cb15eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4025 samples, validate on 1006 samples\n",
      "Epoch 1/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 2.0961 - acc: 0.7178 - f1_vec: 0.7055 - val_loss: 0.8579 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.85793, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 2/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.8179 - acc: 0.7272 - f1_vec: 0.7185 - val_loss: 0.8140 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.85793 to 0.81398, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 3/100\n",
      "4025/4025 [==============================] - 215s 54ms/step - loss: 0.7900 - acc: 0.7275 - f1_vec: 0.7258 - val_loss: 0.7782 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.81398 to 0.77818, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 4/100\n",
      "4025/4025 [==============================] - 215s 54ms/step - loss: 0.7875 - acc: 0.7277 - f1_vec: 0.7255 - val_loss: 0.7754 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.77818 to 0.77535, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 5/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7903 - acc: 0.7277 - f1_vec: 0.7269 - val_loss: 0.7813 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.77535\n",
      "Epoch 6/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7828 - acc: 0.7277 - f1_vec: 0.7265 - val_loss: 0.7745 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.77535 to 0.77446, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 7/100\n",
      "4025/4025 [==============================] - 220s 55ms/step - loss: 0.7811 - acc: 0.7277 - f1_vec: 0.7269 - val_loss: 0.7912 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.77446\n",
      "Epoch 8/100\n",
      "4025/4025 [==============================] - 226s 56ms/step - loss: 0.7800 - acc: 0.7277 - f1_vec: 0.7276 - val_loss: 0.7702 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.77446 to 0.77021, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 9/100\n",
      "4025/4025 [==============================] - 224s 56ms/step - loss: 0.7792 - acc: 0.7277 - f1_vec: 0.7283 - val_loss: 0.7655 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.77021 to 0.76546, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 10/100\n",
      "4025/4025 [==============================] - 223s 55ms/step - loss: 0.7740 - acc: 0.7277 - f1_vec: 0.7273 - val_loss: 0.7660 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.76546\n",
      "Epoch 11/100\n",
      "4025/4025 [==============================] - 222s 55ms/step - loss: 0.7735 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7649 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.76546 to 0.76486, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 12/100\n",
      "4025/4025 [==============================] - 213s 53ms/step - loss: 0.7734 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7669 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.76486\n",
      "Epoch 13/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7697 - acc: 0.7277 - f1_vec: 0.7279 - val_loss: 0.7646 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.76486 to 0.76462, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 14/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7718 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7685 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.76462\n",
      "Epoch 15/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7694 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7689 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.76462\n",
      "Epoch 16/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7701 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7636 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.76462 to 0.76360, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 17/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7703 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7684 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.76360\n",
      "Epoch 18/100\n",
      "4025/4025 [==============================] - 216s 54ms/step - loss: 0.7681 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7621 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.76360 to 0.76213, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 19/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7669 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7671 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.76213\n",
      "Epoch 20/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7689 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7630 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.76213\n",
      "Epoch 21/100\n",
      "4025/4025 [==============================] - 215s 54ms/step - loss: 0.7653 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7640 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.76213\n",
      "Epoch 22/100\n",
      "4025/4025 [==============================] - 213s 53ms/step - loss: 0.7657 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7616 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.76213 to 0.76162, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 23/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7643 - acc: 0.7277 - f1_vec: 0.7268 - val_loss: 0.7624 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.76162\n",
      "Epoch 24/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7670 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7607 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.76162 to 0.76070, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 25/100\n",
      "4025/4025 [==============================] - 216s 54ms/step - loss: 0.7638 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7607 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.76070 to 0.76068, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 26/100\n",
      "4025/4025 [==============================] - 217s 54ms/step - loss: 0.7642 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7609 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.76068\n",
      "Epoch 27/100\n",
      "4025/4025 [==============================] - 216s 54ms/step - loss: 0.7634 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7610 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.76068\n",
      "Epoch 28/100\n",
      "4025/4025 [==============================] - 216s 54ms/step - loss: 0.7626 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7606 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.76068 to 0.76055, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 29/100\n",
      "4025/4025 [==============================] - 217s 54ms/step - loss: 0.7631 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7603 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.76055 to 0.76031, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 30/100\n",
      "4025/4025 [==============================] - 216s 54ms/step - loss: 0.7632 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7620 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.76031\n",
      "Epoch 31/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7622 - acc: 0.7277 - f1_vec: 0.7268 - val_loss: 0.7603 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.76031\n",
      "Epoch 32/100\n",
      "4025/4025 [==============================] - 217s 54ms/step - loss: 0.7623 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7629 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.76031\n",
      "Epoch 33/100\n",
      "4025/4025 [==============================] - 217s 54ms/step - loss: 0.7603 - acc: 0.7277 - f1_vec: 0.7271 - val_loss: 0.7606 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.76031\n",
      "Epoch 34/100\n",
      "4025/4025 [==============================] - 217s 54ms/step - loss: 0.7627 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7633 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.76031\n",
      "Epoch 35/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7616 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7601 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.76031 to 0.76010, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 36/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7628 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7607 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.76010\n",
      "Epoch 37/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7632 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7607 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.76010\n",
      "Epoch 38/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7627 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7603 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.76010\n",
      "Epoch 39/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7615 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7614 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.76010\n",
      "Epoch 40/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7616 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7603 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.76010\n",
      "Epoch 41/100\n",
      "4025/4025 [==============================] - 213s 53ms/step - loss: 0.7623 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7606 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.76010\n",
      "Epoch 42/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7618 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7606 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.76010\n",
      "Epoch 43/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7612 - acc: 0.7277 - f1_vec: 0.7271 - val_loss: 0.7607 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.76010\n",
      "Epoch 44/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7614 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7602 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.76010\n",
      "Epoch 45/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7623 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7599 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.76010 to 0.75991, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 46/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7622 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7599 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.75991 to 0.75985, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 47/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7604 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7611 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.75985\n",
      "Epoch 48/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7616 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7605 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.75985\n",
      "Epoch 49/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7609 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7598 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.75985 to 0.75979, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 50/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7611 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7601 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.75979\n",
      "Epoch 51/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7610 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7597 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.75979 to 0.75965, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 52/100\n",
      "4025/4025 [==============================] - 214s 53ms/step - loss: 0.7600 - acc: 0.7277 - f1_vec: 0.7268 - val_loss: 0.7603 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.75965\n",
      "Epoch 53/100\n",
      "4025/4025 [==============================] - 213s 53ms/step - loss: 0.7613 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7601 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.75965\n",
      "Epoch 54/100\n",
      "4025/4025 [==============================] - 212s 53ms/step - loss: 0.7604 - acc: 0.7277 - f1_vec: 0.7271 - val_loss: 0.7605 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.75965\n",
      "Epoch 55/100\n",
      "4025/4025 [==============================] - 212s 53ms/step - loss: 0.7614 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7600 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.75965\n",
      "Epoch 56/100\n",
      "4025/4025 [==============================] - 212s 53ms/step - loss: 0.7616 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7599 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.75965\n",
      "Epoch 57/100\n",
      "4025/4025 [==============================] - 212s 53ms/step - loss: 0.7600 - acc: 0.7277 - f1_vec: 0.7264 - val_loss: 0.7600 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.75965\n",
      "Epoch 58/100\n",
      "4025/4025 [==============================] - 212s 53ms/step - loss: 0.7611 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7597 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.75965\n",
      "Epoch 59/100\n",
      "4025/4025 [==============================] - 215s 53ms/step - loss: 0.7608 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7596 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.75965 to 0.75961, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 60/100\n",
      "4025/4025 [==============================] - 216s 54ms/step - loss: 0.7614 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7599 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.75961\n",
      "Epoch 61/100\n",
      "4025/4025 [==============================] - 221s 55ms/step - loss: 0.7602 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7596 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.75961 to 0.75958, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_unres_vec.h5\n",
      "Epoch 62/100\n",
      "4025/4025 [==============================] - 221s 55ms/step - loss: 0.7611 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7598 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.75958\n",
      "Epoch 63/100\n",
      "4025/4025 [==============================] - 222s 55ms/step - loss: 0.7603 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7600 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.75958\n",
      "Epoch 64/100\n",
      "4025/4025 [==============================] - 220s 55ms/step - loss: 0.7610 - acc: 0.7277 - f1_vec: 0.7271 - val_loss: 0.7598 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.75958\n",
      "Epoch 65/100\n",
      "4025/4025 [==============================] - 220s 55ms/step - loss: 0.7608 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7608 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.75958\n",
      "Epoch 66/100\n",
      "4025/4025 [==============================] - 220s 55ms/step - loss: 0.7618 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7600 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.75958\n",
      "Epoch 67/100\n",
      "4025/4025 [==============================] - 221s 55ms/step - loss: 0.7604 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7597 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.75958\n",
      "Epoch 68/100\n",
      "4025/4025 [==============================] - 222s 55ms/step - loss: 0.7603 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.7597 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.75958\n",
      "Epoch 69/100\n",
      "4025/4025 [==============================] - 222s 55ms/step - loss: 0.7600 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.7605 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.75958\n",
      "Epoch 70/100\n",
      "4025/4025 [==============================] - 222s 55ms/step - loss: 0.7619 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7610 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.75958\n",
      "Epoch 71/100\n",
      "4025/4025 [==============================] - 222s 55ms/step - loss: 0.7619 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7604 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.75958\n",
      "Epoch 00071: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_gru_unres_vec = model_gru_unres_vec.fit(x2train_vec, y2train, batch_size=12, epochs=100, \n",
    "                                                    validation_data=(x2val_vec, y2val), callbacks=callbacks_unres_vec, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XP8YTUW8quTP",
    "outputId": "566aa231-4adc-4b75-fc0e-e9f983e2cc20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8786 samples, validate on 1006 samples\n",
      "Epoch 1/100\n",
      "8786/8786 [==============================] - 496s 56ms/step - loss: 1.1397 - acc: 0.3383 - f1_vec: 0.0373 - val_loss: 1.1066 - val_acc: 0.0915 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.10656, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_res_vec.h5\n",
      "Epoch 2/100\n",
      "8786/8786 [==============================] - 503s 57ms/step - loss: 1.1073 - acc: 0.3318 - f1_vec: 8.3954e-04 - val_loss: 1.0468 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.10656 to 1.04675, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_res_vec.h5\n",
      "Epoch 3/100\n",
      "8786/8786 [==============================] - 501s 57ms/step - loss: 1.1066 - acc: 0.3206 - f1_vec: 0.0000e+00 - val_loss: 1.0435 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.04675 to 1.04345, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/GRU/tesis_model_gru_res_vec.h5\n",
      "Epoch 4/100\n",
      "8786/8786 [==============================] - 502s 57ms/step - loss: 1.1022 - acc: 0.3375 - f1_vec: 0.0000e+00 - val_loss: 1.0854 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.04345\n",
      "Epoch 5/100\n",
      "8786/8786 [==============================] - 498s 57ms/step - loss: 1.1030 - acc: 0.3321 - f1_vec: 0.0000e+00 - val_loss: 1.0912 - val_acc: 0.0915 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.04345\n",
      "Epoch 6/100\n",
      "8786/8786 [==============================] - 498s 57ms/step - loss: 1.1026 - acc: 0.3356 - f1_vec: 0.0000e+00 - val_loss: 1.1414 - val_acc: 0.0915 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.04345\n",
      "Epoch 7/100\n",
      "8786/8786 [==============================] - 497s 57ms/step - loss: 1.1037 - acc: 0.3296 - f1_vec: 0.0000e+00 - val_loss: 1.0613 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.04345\n",
      "Epoch 8/100\n",
      "8786/8786 [==============================] - 499s 57ms/step - loss: 1.1018 - acc: 0.3341 - f1_vec: 0.0000e+00 - val_loss: 1.0957 - val_acc: 0.0915 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.04345\n",
      "Epoch 9/100\n",
      "8786/8786 [==============================] - 498s 57ms/step - loss: 1.1020 - acc: 0.3321 - f1_vec: 0.0000e+00 - val_loss: 1.1165 - val_acc: 0.0915 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.04345\n",
      "Epoch 10/100\n",
      "8786/8786 [==============================] - 500s 57ms/step - loss: 1.1007 - acc: 0.3384 - f1_vec: 0.0000e+00 - val_loss: 1.1773 - val_acc: 0.0915 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.04345\n",
      "Epoch 11/100\n",
      "8786/8786 [==============================] - 506s 58ms/step - loss: 1.1017 - acc: 0.3231 - f1_vec: 0.0000e+00 - val_loss: 1.0971 - val_acc: 0.1809 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.04345\n",
      "Epoch 12/100\n",
      "8786/8786 [==============================] - 506s 58ms/step - loss: 1.1000 - acc: 0.3438 - f1_vec: 0.0000e+00 - val_loss: 1.0802 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.04345\n",
      "Epoch 13/100\n",
      "8786/8786 [==============================] - 506s 58ms/step - loss: 1.1011 - acc: 0.3305 - f1_vec: 0.0000e+00 - val_loss: 1.0748 - val_acc: 0.7276 - val_f1_vec: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.04345\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_gru_res_vec = model_gru_res_vec.fit(x2res, y2res, batch_size=12, epochs=100, \n",
    "                                                validation_data=(x2val_vec, y2val), callbacks=callbacks_res_vec, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ongj2Jaty29o"
   },
   "source": [
    "### **CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYogn-MKPEIH"
   },
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eaUVVY_IOFg_",
    "outputId": "59a3f042-f33a-464f-ee1c-f3b752da554b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model CNN UNRES\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 50, 300)      1905000     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 46, 128)      192128      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 46, 128)      192128      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 46, 128)      192128      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 46, 128)      512         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 46, 128)      512         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 46, 128)      512         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1, 128)       0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 1, 128)       0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 128)       0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 128)       0           max_pooling1d_13[0][0]           \n",
      "                                                                 max_pooling1d_14[0][0]           \n",
      "                                                                 max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 384)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 384)          0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 3)            1155        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,484,075\n",
      "Trainable params: 2,483,307\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "Model CNN RES\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 50, 300)      1905000     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 46, 128)      192128      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 46, 128)      192128      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 46, 128)      192128      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 46, 128)      512         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 46, 128)      512         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 46, 128)      512         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1, 128)       0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 1, 128)       0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 128)       0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 128)       0           max_pooling1d_13[0][0]           \n",
      "                                                                 max_pooling1d_14[0][0]           \n",
      "                                                                 max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 384)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 384)          0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 3)            1155        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,484,075\n",
      "Trainable params: 2,483,307\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_filters = 128\n",
    "border_mode = 'same'\n",
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "#maxlen_vec = td\n",
    "kernel_sizes = [5,5,5]\n",
    "dropout_rate = 0.5\n",
    "\n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "#emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "#                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "conv_0 = Conv1D(num_filters, kernel_sizes[0], activation = 'relu')(embedding) #padding=border_mode,\n",
    "conv_0 = BatchNormalization()(conv_0)\n",
    "maxpool_0 = MaxPooling1D(pool_size = (maxlen - kernel_sizes[0] + 1), strides=1, padding='valid')(conv_0)\n",
    "    \n",
    "conv_1 = Conv1D(num_filters, kernel_sizes[1], activation = 'relu')(embedding) #padding=border_mode,\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "maxpool_1 = MaxPooling1D(pool_size = (maxlen - kernel_sizes[1] + 1), strides=1, padding='valid')(conv_1)\n",
    "    \n",
    "conv_2 = Conv1D(num_filters, kernel_sizes[2], activation = 'relu')(embedding) #padding=border_mode,\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "maxpool_2 = MaxPooling1D(pool_size = (maxlen - kernel_sizes[2] + 1), strides=1, padding='valid')(conv_2)\n",
    "    \n",
    "merged = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(merged)\n",
    "drop = Dropout(dropout_rate)(flatten)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "model_cnn_unres = Model(inputs, output)\n",
    "model_cnn_res = Model(inputs, output)\n",
    "\n",
    "model_cnn_unres.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1])\n",
    "model_cnn_res.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1])\n",
    "\n",
    "callbacks_unres = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_unres.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "callbacks_res = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                 ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_res.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "print('Model CNN UNRES')\n",
    "model_cnn_unres.summary()\n",
    "print('Model CNN RES')\n",
    "model_cnn_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "82Q_u97repXH",
    "outputId": "356a6307-2890-4ec2-fb66-53e2bf7d8a2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3756 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "3756/3756 [==============================] - 6s 2ms/step - loss: 2.0938 - acc: 0.6374 - f1: 0.6339 - val_loss: 0.9706 - val_acc: 0.7292 - val_f1: 0.7328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.97059, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_unres.h5\n",
      "Epoch 2/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.8859 - acc: 0.7274 - f1: 0.7247 - val_loss: 0.7658 - val_acc: 0.7453 - val_f1: 0.7519\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.97059 to 0.76583, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_unres.h5\n",
      "Epoch 3/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.6677 - acc: 0.7833 - f1: 0.7822 - val_loss: 0.7127 - val_acc: 0.7627 - val_f1: 0.7612\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.76583 to 0.71267, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_unres.h5\n",
      "Epoch 4/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.4864 - acc: 0.8357 - f1: 0.8338 - val_loss: 0.7677 - val_acc: 0.7590 - val_f1: 0.7601\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.71267\n",
      "Epoch 5/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.4107 - acc: 0.8618 - f1: 0.8636 - val_loss: 0.8178 - val_acc: 0.7453 - val_f1: 0.7464\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.71267\n",
      "Epoch 6/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.3410 - acc: 0.8834 - f1: 0.8822 - val_loss: 0.8955 - val_acc: 0.7652 - val_f1: 0.7715\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.71267\n",
      "Epoch 7/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.3153 - acc: 0.8938 - f1: 0.8922 - val_loss: 0.9723 - val_acc: 0.7627 - val_f1: 0.7623\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.71267\n",
      "Epoch 8/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.2859 - acc: 0.9065 - f1: 0.9061 - val_loss: 1.0097 - val_acc: 0.7466 - val_f1: 0.7515\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.71267\n",
      "Epoch 9/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.2681 - acc: 0.9116 - f1: 0.9110 - val_loss: 1.0582 - val_acc: 0.7665 - val_f1: 0.7544\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.71267\n",
      "Epoch 10/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.2570 - acc: 0.9132 - f1: 0.9136 - val_loss: 1.1965 - val_acc: 0.7329 - val_f1: 0.7179\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.71267\n",
      "Epoch 11/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.2426 - acc: 0.9153 - f1: 0.9156 - val_loss: 1.2450 - val_acc: 0.7528 - val_f1: 0.7411\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.71267\n",
      "Epoch 12/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.2632 - acc: 0.9180 - f1: 0.9161 - val_loss: 1.3745 - val_acc: 0.7540 - val_f1: 0.7454\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.71267\n",
      "Epoch 13/100\n",
      "3756/3756 [==============================] - 5s 1ms/step - loss: 0.1980 - acc: 0.9297 - f1: 0.9297 - val_loss: 1.5177 - val_acc: 0.7578 - val_f1: 0.7490\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.71267\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_cnn_unres = model_cnn_unres.fit(x_train, y_train, batch_size=12, epochs=100,\n",
    "                                            validation_data=(x_val, y_val), callbacks=callbacks_unres, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "colab_type": "code",
    "id": "KLLXIHsFepgi",
    "outputId": "f85fab9f-18c3-4654-ae5d-f228a1dd2d52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8145 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "8145/8145 [==============================] - 11s 1ms/step - loss: 1.8133 - acc: 0.4265 - f1: 0.3957 - val_loss: 1.1102 - val_acc: 0.4075 - val_f1: 0.3298\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.11016, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_res.h5\n",
      "Epoch 2/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 1.0908 - acc: 0.4981 - f1: 0.4469 - val_loss: 0.8754 - val_acc: 0.6422 - val_f1: 0.5614\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.11016 to 0.87537, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_res.h5\n",
      "Epoch 3/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 0.9333 - acc: 0.5723 - f1: 0.5369 - val_loss: 1.2009 - val_acc: 0.4932 - val_f1: 0.4581\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.87537\n",
      "Epoch 4/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 0.8442 - acc: 0.6303 - f1: 0.6075 - val_loss: 0.9183 - val_acc: 0.6596 - val_f1: 0.6259\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.87537\n",
      "Epoch 5/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 0.7325 - acc: 0.6859 - f1: 0.6706 - val_loss: 1.2576 - val_acc: 0.5304 - val_f1: 0.4860\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.87537\n",
      "Epoch 6/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 0.6243 - acc: 0.7380 - f1: 0.7276 - val_loss: 1.2928 - val_acc: 0.5578 - val_f1: 0.5325\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.87537\n",
      "Epoch 7/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 0.5457 - acc: 0.7738 - f1: 0.7648 - val_loss: 1.4445 - val_acc: 0.5665 - val_f1: 0.5248\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.87537\n",
      "Epoch 8/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 0.4937 - acc: 0.7967 - f1: 0.7895 - val_loss: 1.4236 - val_acc: 0.5876 - val_f1: 0.5503\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.87537\n",
      "Epoch 9/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 0.4573 - acc: 0.8110 - f1: 0.8070 - val_loss: 1.7238 - val_acc: 0.5888 - val_f1: 0.5639\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.87537\n",
      "Epoch 10/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 0.4282 - acc: 0.8303 - f1: 0.8292 - val_loss: 1.8862 - val_acc: 0.5143 - val_f1: 0.4858\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.87537\n",
      "Epoch 11/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 0.3766 - acc: 0.8506 - f1: 0.8469 - val_loss: 1.8239 - val_acc: 0.6025 - val_f1: 0.5787\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.87537\n",
      "Epoch 12/100\n",
      "8145/8145 [==============================] - 10s 1ms/step - loss: 0.3764 - acc: 0.8577 - f1: 0.8558 - val_loss: 1.9502 - val_acc: 0.6037 - val_f1: 0.5771\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.87537\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_cnn_res = model_cnn_res.fit(x_res, y_res, batch_size=12, epochs=100, \n",
    "                                        validation_data=(x_val, y_val), callbacks=callbacks_res, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 856
    },
    "colab_type": "code",
    "id": "4iwww1SvgV7X",
    "outputId": "5de95bc5-490c-4a4f-913d-3bc440690839"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model_cnn_unres, to_file='/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_unres2.png', \n",
    "           show_shapes=False, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mjUnuqiyLzgt",
    "outputId": "5355bb0a-3b48-4705-fd72-edc6369c1dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model CNN UNRES VEC\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1000, 300)    1905000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 128)    115328      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 128)    153728      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 128)    192128      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000, 128)    512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 128)    512         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 128)    512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 3, 128)       0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 4, 128)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 5, 128)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12, 128)      0           max_pooling1d_4[0][0]            \n",
      "                                                                 max_pooling1d_5[0][0]            \n",
      "                                                                 max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1536)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1536)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            4611        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,372,331\n",
      "Trainable params: 2,371,563\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "Model CNN RES VEC\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1000, 300)    1905000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 128)    115328      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 128)    153728      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 128)    192128      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000, 128)    512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 128)    512         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 128)    512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 3, 128)       0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 4, 128)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 5, 128)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12, 128)      0           max_pooling1d_4[0][0]            \n",
      "                                                                 max_pooling1d_5[0][0]            \n",
      "                                                                 max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1536)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1536)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            4611        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,372,331\n",
      "Trainable params: 2,371,563\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_filters = 128\n",
    "border_mode = 'same'\n",
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "maxlen_vec = td\n",
    "kernel_sizes = [3,4,5]\n",
    "dropout_rate = 0.5\n",
    "\n",
    "inputs = Input(shape=(maxlen_vec,))\n",
    "#embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           # EMBEDDING_DIM,\n",
    "                            #weights=[embedding_matrix],\n",
    "                           # trainable=True)\n",
    "#embedding = embedding_layer(inputs)\n",
    "\n",
    "emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "                 weights=[embedding_matrix], \n",
    "                 trainable=True)(inputs)\n",
    "\n",
    "conv_0 = Conv1D(num_filters, kernel_sizes[0], padding=border_mode, activation = 'relu', kernel_regularizer=regularizers.l2(0.1))(emb2)\n",
    "conv_0 = BatchNormalization()(conv_0)\n",
    "maxpool_0 = MaxPooling1D(pool_size = (maxlen_vec - kernel_sizes[0] + 1), strides=1, padding='valid')(conv_0)\n",
    "    \n",
    "conv_1 = Conv1D(num_filters, kernel_sizes[1], padding=border_mode, activation = 'relu', kernel_regularizer=regularizers.l2(0.1))(emb2)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "maxpool_1 = MaxPooling1D(pool_size = (maxlen_vec - kernel_sizes[1] + 1), strides=1, padding='valid')(conv_1)\n",
    "    \n",
    "conv_2 = Conv1D(num_filters, kernel_sizes[2], padding=border_mode, activation = 'relu', kernel_regularizer=regularizers.l2(0.1))(emb2)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "maxpool_2 = MaxPooling1D(pool_size = (maxlen_vec - kernel_sizes[2] + 1), strides=1, padding='valid')(conv_2)\n",
    "    \n",
    "merged = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(merged)\n",
    "drop = Dropout(dropout_rate)(flatten)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "model_cnn_unres_vec = Model(inputs, output)\n",
    "model_cnn_res_vec = Model(inputs, output)\n",
    "\n",
    "model_cnn_unres_vec.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['acc', f1_vec])\n",
    "model_cnn_res_vec.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['acc', f1_vec])\n",
    "\n",
    "callbacks_unres_vec = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_unres_vec.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "callbacks_res_vec = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                 ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_res_vec.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "print('Model CNN UNRES VEC')\n",
    "model_cnn_unres_vec.summary()\n",
    "print('Model CNN RES VEC')\n",
    "model_cnn_res_vec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9CWFUID4DoGF",
    "outputId": "4a03a609-f063-4c1e-fe84-7de8bf7694c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4025 samples, validate on 1006 samples\n",
      "Epoch 1/50\n",
      "4025/4025 [==============================] - 303s 75ms/step - loss: 2.9654 - acc: 0.7257 - f1_vec: 0.7203 - val_loss: 0.7870 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78704, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_unres_vec.h5\n",
      "Epoch 2/50\n",
      "4025/4025 [==============================] - 298s 74ms/step - loss: 0.7881 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.8121 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.78704\n",
      "Epoch 3/50\n",
      "4025/4025 [==============================] - 295s 73ms/step - loss: 0.7792 - acc: 0.7277 - f1_vec: 0.7271 - val_loss: 0.7948 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.78704\n",
      "Epoch 4/50\n",
      "4025/4025 [==============================] - 292s 73ms/step - loss: 0.7803 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.8748 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.78704\n",
      "Epoch 5/50\n",
      "4025/4025 [==============================] - 292s 72ms/step - loss: 0.7810 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.8591 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.78704\n",
      "Epoch 6/50\n",
      "4025/4025 [==============================] - 292s 72ms/step - loss: 0.7840 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.7858 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.78704 to 0.78575, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_unres_vec.h5\n",
      "Epoch 7/50\n",
      "4025/4025 [==============================] - 289s 72ms/step - loss: 0.7822 - acc: 0.7272 - f1_vec: 0.7266 - val_loss: 0.8044 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.78575\n",
      "Epoch 8/50\n",
      "4025/4025 [==============================] - 292s 73ms/step - loss: 0.7865 - acc: 0.7275 - f1_vec: 0.7276 - val_loss: 0.9835 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.78575\n",
      "Epoch 9/50\n",
      "4025/4025 [==============================] - 297s 74ms/step - loss: 0.7896 - acc: 0.7275 - f1_vec: 0.7272 - val_loss: 0.7999 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.78575\n",
      "Epoch 10/50\n",
      "4025/4025 [==============================] - 297s 74ms/step - loss: 0.7912 - acc: 0.7275 - f1_vec: 0.7279 - val_loss: 0.9299 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.78575\n",
      "Epoch 11/50\n",
      "4025/4025 [==============================] - 296s 74ms/step - loss: 0.7809 - acc: 0.7277 - f1_vec: 0.7282 - val_loss: 0.8754 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.78575\n",
      "Epoch 12/50\n",
      "4025/4025 [==============================] - 295s 73ms/step - loss: 0.7850 - acc: 0.7275 - f1_vec: 0.7279 - val_loss: 0.8410 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.78575\n",
      "Epoch 13/50\n",
      "4025/4025 [==============================] - 295s 73ms/step - loss: 0.7793 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.8128 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.78575\n",
      "Epoch 14/50\n",
      "4025/4025 [==============================] - 293s 73ms/step - loss: 0.7807 - acc: 0.7277 - f1_vec: 0.7278 - val_loss: 0.8251 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.78575\n",
      "Epoch 15/50\n",
      "4025/4025 [==============================] - 291s 72ms/step - loss: 0.7813 - acc: 0.7277 - f1_vec: 0.7275 - val_loss: 0.8425 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.78575\n",
      "Epoch 16/50\n",
      "4025/4025 [==============================] - 291s 72ms/step - loss: 0.7889 - acc: 0.7275 - f1_vec: 0.7279 - val_loss: 0.8937 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.78575\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_cnn_unres_vec = model_cnn_unres_vec.fit(x2train_vec, y2train, batch_size=12, epochs=100, \n",
    "                                                    validation_data=(x2val_vec, y2val), callbacks=callbacks_unres_vec, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rxpuvB9LDuF-",
    "outputId": "7290db4d-eca4-4843-d4d7-be1a0101d5e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8786 samples, validate on 1006 samples\n",
      "Epoch 1/100\n",
      "8786/8786 [==============================] - 56s 6ms/step - loss: 5.8211 - acc: 0.3393 - f1_vec: 0.0905 - val_loss: 16.1502 - val_acc: 0.1809 - val_f1_vec: 0.1808\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 16.15022, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_res_vec.h5\n",
      "Epoch 2/100\n",
      "8786/8786 [==============================] - 49s 6ms/step - loss: 1.3756 - acc: 0.3405 - f1_vec: 0.0412 - val_loss: 12.9978 - val_acc: 0.1809 - val_f1_vec: 0.1808\n",
      "\n",
      "Epoch 00002: val_loss improved from 16.15022 to 12.99776, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_res_vec.h5\n",
      "Epoch 3/100\n",
      "8786/8786 [==============================] - 49s 6ms/step - loss: 1.2734 - acc: 0.3440 - f1_vec: 0.0365 - val_loss: 16.7113 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 12.99776\n",
      "Epoch 4/100\n",
      "8786/8786 [==============================] - 48s 6ms/step - loss: 1.2221 - acc: 0.3309 - f1_vec: 0.0285 - val_loss: 9.2815 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00004: val_loss improved from 12.99776 to 9.28153, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_res_vec.h5\n",
      "Epoch 5/100\n",
      "8786/8786 [==============================] - 49s 6ms/step - loss: 1.2026 - acc: 0.3325 - f1_vec: 0.0208 - val_loss: 9.8767 - val_acc: 0.1809 - val_f1_vec: 0.1808\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 9.28153\n",
      "Epoch 6/100\n",
      "8786/8786 [==============================] - 49s 6ms/step - loss: 1.1909 - acc: 0.3443 - f1_vec: 0.0272 - val_loss: 11.8231 - val_acc: 0.0915 - val_f1_vec: 0.0917\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 9.28153\n",
      "Epoch 7/100\n",
      "8786/8786 [==============================] - 50s 6ms/step - loss: 1.1586 - acc: 0.3384 - f1_vec: 0.0182 - val_loss: 14.2645 - val_acc: 0.0915 - val_f1_vec: 0.0917\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 9.28153\n",
      "Epoch 8/100\n",
      "8786/8786 [==============================] - 51s 6ms/step - loss: 1.1394 - acc: 0.3418 - f1_vec: 0.0237 - val_loss: 1.0001 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00008: val_loss improved from 9.28153 to 1.00012, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN/tesis_model_cnn_res_vec.h5\n",
      "Epoch 9/100\n",
      "8786/8786 [==============================] - 50s 6ms/step - loss: 1.1272 - acc: 0.3366 - f1_vec: 0.0170 - val_loss: 5.3780 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00012\n",
      "Epoch 10/100\n",
      "8786/8786 [==============================] - 49s 6ms/step - loss: 1.1277 - acc: 0.3420 - f1_vec: 0.0195 - val_loss: 7.7153 - val_acc: 0.0915 - val_f1_vec: 0.0908\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00012\n",
      "Epoch 11/100\n",
      "8786/8786 [==============================] - 49s 6ms/step - loss: 1.1160 - acc: 0.3337 - f1_vec: 0.0183 - val_loss: 10.0656 - val_acc: 0.1809 - val_f1_vec: 0.1808\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00012\n",
      "Epoch 12/100\n",
      "8786/8786 [==============================] - 48s 6ms/step - loss: 1.1141 - acc: 0.3420 - f1_vec: 0.0162 - val_loss: 7.8445 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.00012\n",
      "Epoch 13/100\n",
      "8786/8786 [==============================] - 48s 6ms/step - loss: 1.1097 - acc: 0.3455 - f1_vec: 0.0162 - val_loss: 2.7951 - val_acc: 0.1988 - val_f1_vec: 0.1988\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.00012\n",
      "Epoch 14/100\n",
      "8786/8786 [==============================] - 49s 6ms/step - loss: 1.1080 - acc: 0.3327 - f1_vec: 0.0153 - val_loss: 6.7362 - val_acc: 0.1809 - val_f1_vec: 0.1808\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.00012\n",
      "Epoch 15/100\n",
      "8786/8786 [==============================] - 48s 6ms/step - loss: 1.1098 - acc: 0.3437 - f1_vec: 0.0177 - val_loss: 1.1074 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.00012\n",
      "Epoch 16/100\n",
      "8786/8786 [==============================] - 48s 6ms/step - loss: 1.1122 - acc: 0.3350 - f1_vec: 0.0180 - val_loss: 1.5401 - val_acc: 0.7276 - val_f1_vec: 0.7276\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.00012\n",
      "Epoch 17/100\n",
      "8786/8786 [==============================] - 48s 6ms/step - loss: 1.1027 - acc: 0.3442 - f1_vec: 0.0169 - val_loss: 3.1276 - val_acc: 0.1988 - val_f1_vec: 0.1988\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.00012\n",
      "Epoch 18/100\n",
      "8786/8786 [==============================] - 48s 6ms/step - loss: 1.0973 - acc: 0.3408 - f1_vec: 0.0156 - val_loss: 3.2320 - val_acc: 0.1988 - val_f1_vec: 0.1988\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.00012\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_cnn_res_vec = model_cnn_res_vec.fit(x2res, y2res, batch_size=12, epochs=100, \n",
    "                                                validation_data=(x2val_vec, y2val), callbacks=callbacks_res_vec, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdrgR2xtDuPh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJIBzWiODuXr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Wqx9y0oXYML"
   },
   "source": [
    "### **LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSFb7e4F-Ov5"
   },
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "2e9yq4LV-Nj0",
    "outputId": "74b8fc7b-8ff0-4e8b-befc-56bc6061a266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LSTM UNRES\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 50, 300)           1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_8 (Spatial (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,125,035\n",
      "Trainable params: 2,125,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model LSTM RES\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 50, 300)           1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_8 (Spatial (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,125,035\n",
      "Trainable params: 2,125,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "#maxlen_vec = td\n",
    "lstm_cell = 128\n",
    "dropout_rate = 0.5\n",
    "\n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "#emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "#                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "s_drop = SpatialDropout1D(dropout_rate)(embedding)\n",
    "lstm = LSTM((lstm_cell), return_sequences=True)(s_drop)\n",
    "lstm = LSTM((lstm_cell), return_sequences=False)(s_drop)\n",
    "drop = Dropout(dropout_rate)(lstm)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "model_lstm_unres = Model(inputs, output)\n",
    "model_lstm_res = Model(inputs, output)\n",
    "\n",
    "model_lstm_unres.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1, TP, TN])\n",
    "model_lstm_res.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1, TP, TN])\n",
    "\n",
    "callbacks_unres = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres2.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "callbacks_res = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                 ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_res2.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "print('Model LSTM UNRES')\n",
    "model_lstm_unres.summary()\n",
    "print('Model LSTM RES')\n",
    "model_lstm_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "colab_type": "code",
    "id": "yFv2ip8S-T5i",
    "outputId": "80d7a4e4-6c32-442d-9f74-f2ad99e1c506"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3756 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "3756/3756 [==============================] - 47s 12ms/step - loss: 0.6882 - acc: 0.7463 - f1: 0.7368 - val_loss: 0.6056 - val_acc: 0.7752 - val_f1: 0.7591\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60560, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres.h5\n",
      "Epoch 2/100\n",
      "3756/3756 [==============================] - 46s 12ms/step - loss: 0.4634 - acc: 0.8320 - f1: 0.8241 - val_loss: 0.5684 - val_acc: 0.7901 - val_f1: 0.7745\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60560 to 0.56845, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres.h5\n",
      "Epoch 3/100\n",
      "3756/3756 [==============================] - 47s 12ms/step - loss: 0.3058 - acc: 0.8932 - f1: 0.8915 - val_loss: 0.5864 - val_acc: 0.7801 - val_f1: 0.7677\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.56845\n",
      "Epoch 4/100\n",
      "3756/3756 [==============================] - 46s 12ms/step - loss: 0.2211 - acc: 0.9183 - f1: 0.9172 - val_loss: 0.7318 - val_acc: 0.7689 - val_f1: 0.7600\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.56845\n",
      "Epoch 5/100\n",
      "3756/3756 [==============================] - 46s 12ms/step - loss: 0.1792 - acc: 0.9361 - f1: 0.9353 - val_loss: 0.7418 - val_acc: 0.7602 - val_f1: 0.7503\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.56845\n",
      "Epoch 6/100\n",
      "3756/3756 [==============================] - 45s 12ms/step - loss: 0.1424 - acc: 0.9497 - f1: 0.9483 - val_loss: 0.8298 - val_acc: 0.7714 - val_f1: 0.7576\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.56845\n",
      "Epoch 7/100\n",
      "3756/3756 [==============================] - 46s 12ms/step - loss: 0.1145 - acc: 0.9609 - f1: 0.9605 - val_loss: 0.9203 - val_acc: 0.7727 - val_f1: 0.7610\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56845\n",
      "Epoch 8/100\n",
      "3756/3756 [==============================] - 45s 12ms/step - loss: 0.0935 - acc: 0.9681 - f1: 0.9678 - val_loss: 1.0286 - val_acc: 0.7640 - val_f1: 0.7514\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.56845\n",
      "Epoch 9/100\n",
      "3756/3756 [==============================] - 45s 12ms/step - loss: 0.0788 - acc: 0.9731 - f1: 0.9726 - val_loss: 0.9903 - val_acc: 0.7689 - val_f1: 0.7726\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.56845\n",
      "Epoch 10/100\n",
      "3756/3756 [==============================] - 46s 12ms/step - loss: 0.0713 - acc: 0.9763 - f1: 0.9755 - val_loss: 1.0908 - val_acc: 0.7516 - val_f1: 0.7558\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.56845\n",
      "Epoch 11/100\n",
      "3756/3756 [==============================] - 46s 12ms/step - loss: 0.0643 - acc: 0.9766 - f1: 0.9759 - val_loss: 1.2091 - val_acc: 0.7665 - val_f1: 0.7720\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.56845\n",
      "Epoch 12/100\n",
      "3756/3756 [==============================] - 47s 12ms/step - loss: 0.0553 - acc: 0.9806 - f1: 0.9798 - val_loss: 1.3651 - val_acc: 0.7578 - val_f1: 0.7600\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.56845\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_lstm_unres = model_lstm_unres.fit(x_train, y_train, batch_size=12, epochs=100,\n",
    "                                            validation_data=(x_val, y_val), callbacks=callbacks_unres, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "colab_type": "code",
    "id": "jNvv20sa-ULi",
    "outputId": "c9a2e38d-06a8-4cec-cda1-a2207eb88c2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8145 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "8145/8145 [==============================] - 86s 11ms/step - loss: 0.8559 - acc: 0.6041 - f1: 0.5675 - val_loss: 0.8053 - val_acc: 0.6882 - val_f1: 0.6663\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80527, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_res.h5\n",
      "Epoch 2/100\n",
      "8145/8145 [==============================] - 85s 10ms/step - loss: 0.6054 - acc: 0.7254 - f1: 0.7169 - val_loss: 1.3855 - val_acc: 0.5789 - val_f1: 0.5682\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.80527\n",
      "Epoch 3/100\n",
      "8145/8145 [==============================] - 84s 10ms/step - loss: 0.4822 - acc: 0.7929 - f1: 0.7855 - val_loss: 1.3981 - val_acc: 0.5789 - val_f1: 0.5684\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.80527\n",
      "Epoch 4/100\n",
      "8145/8145 [==============================] - 85s 10ms/step - loss: 0.3894 - acc: 0.8381 - f1: 0.8362 - val_loss: 1.6045 - val_acc: 0.6099 - val_f1: 0.5915\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.80527\n",
      "Epoch 5/100\n",
      "8145/8145 [==============================] - 84s 10ms/step - loss: 0.3258 - acc: 0.8697 - f1: 0.8677 - val_loss: 1.7278 - val_acc: 0.5839 - val_f1: 0.5798\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.80527\n",
      "Epoch 6/100\n",
      "8145/8145 [==============================] - 83s 10ms/step - loss: 0.2569 - acc: 0.8982 - f1: 0.8973 - val_loss: 1.9543 - val_acc: 0.5789 - val_f1: 0.5700\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.80527\n",
      "Epoch 7/100\n",
      "8145/8145 [==============================] - 84s 10ms/step - loss: 0.2201 - acc: 0.9142 - f1: 0.9137 - val_loss: 2.2334 - val_acc: 0.5814 - val_f1: 0.5600\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.80527\n",
      "Epoch 8/100\n",
      "8145/8145 [==============================] - 84s 10ms/step - loss: 0.1915 - acc: 0.9244 - f1: 0.9237 - val_loss: 2.1304 - val_acc: 0.5963 - val_f1: 0.5845\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.80527\n",
      "Epoch 9/100\n",
      "8145/8145 [==============================] - 84s 10ms/step - loss: 0.1562 - acc: 0.9412 - f1: 0.9423 - val_loss: 2.2959 - val_acc: 0.6062 - val_f1: 0.5953\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.80527\n",
      "Epoch 10/100\n",
      "8145/8145 [==============================] - 84s 10ms/step - loss: 0.1344 - acc: 0.9483 - f1: 0.9481 - val_loss: 2.4828 - val_acc: 0.5727 - val_f1: 0.5611\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.80527\n",
      "Epoch 11/100\n",
      "8145/8145 [==============================] - 84s 10ms/step - loss: 0.1238 - acc: 0.9559 - f1: 0.9559 - val_loss: 2.5713 - val_acc: 0.5814 - val_f1: 0.5729\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.80527\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_lstm_res = model_lstm_res.fit(x_res, y_res, batch_size=12, epochs=100, \n",
    "                                        validation_data=(x_val, y_val), callbacks=callbacks_res, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "jaI_AmOlgi9Q",
    "outputId": "cab7439f-e1cd-4d4a-901e-2c8888055f30"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model_lstm_unres, to_file='/content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres2.png', \n",
    "           show_shapes=False, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dq6zVwCiIIJx"
   },
   "source": [
    "##### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "1c65R5DrOU3M",
    "outputId": "0e21ea74-787c-4999-95ba-72ed9f4514e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model BiLSTM UNRES\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_17 (Embedding)     (None, 50, 300)           1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_11 (Spatia (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 256)               439296    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,345,067\n",
      "Trainable params: 2,345,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model BiLSTM RES\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_17 (Embedding)     (None, 50, 300)           1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_11 (Spatia (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 256)               439296    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,345,067\n",
      "Trainable params: 2,345,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "#maxlen_vec = td\n",
    "lstm_cell = 128\n",
    "dropout_rate = 0.5\n",
    "\n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "#emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "#                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "s_drop = SpatialDropout1D(dropout_rate)(embedding)\n",
    "lstm = Bidirectional(LSTM((lstm_cell), return_sequences=True))(s_drop)\n",
    "lstm = Bidirectional(LSTM((lstm_cell), return_sequences=False))(s_drop)\n",
    "drop = Dropout(dropout_rate)(lstm)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "model_bilstm_unres = Model(inputs, output)\n",
    "model_bilstm_res = Model(inputs, output)\n",
    "\n",
    "model_bilstm_unres.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1])\n",
    "model_bilstm_res.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1])\n",
    "\n",
    "callbacks_unres = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_bilstm_unres.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "callbacks_res = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                 ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_bilstm_res.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "print('Model BiLSTM UNRES')\n",
    "model_bilstm_unres.summary()\n",
    "print('Model BiLSTM RES')\n",
    "model_bilstm_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "Q974H5resfhW",
    "outputId": "fcf06a02-e867-4b25-c135-e5b51d9bf4bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LSTM UNRES VEC\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 1000, 300)         1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,125,035\n",
      "Trainable params: 2,125,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model LSTM RES VEC\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 1000, 300)         1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,125,035\n",
      "Trainable params: 2,125,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "maxlen_vec = td\n",
    "lstm_cell = 128\n",
    "dropout_rate = 0.5\n",
    "\n",
    "inputs = Input(shape=(maxlen_vec,))\n",
    "#embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           # EMBEDDING_DIM,\n",
    "                            #weights=[embedding_matrix],\n",
    "                           # trainable=True)\n",
    "#embedding = embedding_layer(inputs)\n",
    "\n",
    "emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "s_drop = SpatialDropout1D(dropout_rate)(emb2)\n",
    "lstm = LSTM((lstm_cell), return_sequences=False)(s_drop)\n",
    "drop = Dropout(dropout_rate)(lstm)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "model_lstm_unres_vec = Model(inputs, output)\n",
    "model_lstm_res_vec = Model(inputs, output)\n",
    "\n",
    "model_lstm_unres_vec.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1])\n",
    "model_lstm_res_vec.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc', f1])\n",
    "\n",
    "callbacks_unres_vec = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres_vec.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "callbacks_res_vec = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                 ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_res_vec.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "print('Model LSTM UNRES VEC')\n",
    "model_lstm_unres_vec.summary()\n",
    "print('Model LSTM RES VEC')\n",
    "model_lstm_res_vec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iVlJT1Avsfxv",
    "outputId": "b97bcd51-faf9-4201-e2c7-36db7524653d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3756 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "3756/3756 [==============================] - 88s 23ms/step - loss: 0.7625 - acc: 0.7228 - f1: 0.7096 - val_loss: 0.6915 - val_acc: 0.7354 - val_f1: 0.7393\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69148, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres.h5\n",
      "Epoch 2/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.6363 - acc: 0.7654 - f1: 0.7567 - val_loss: 0.6082 - val_acc: 0.7689 - val_f1: 0.7669\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69148 to 0.60825, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres.h5\n",
      "Epoch 3/100\n",
      "3756/3756 [==============================] - 87s 23ms/step - loss: 0.5388 - acc: 0.7913 - f1: 0.7892 - val_loss: 0.5706 - val_acc: 0.7752 - val_f1: 0.7580\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60825 to 0.57055, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres.h5\n",
      "Epoch 4/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.4898 - acc: 0.8182 - f1: 0.8139 - val_loss: 0.5800 - val_acc: 0.7988 - val_f1: 0.7895\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.57055\n",
      "Epoch 5/100\n",
      "3756/3756 [==============================] - 87s 23ms/step - loss: 0.4388 - acc: 0.8400 - f1: 0.8370 - val_loss: 0.5505 - val_acc: 0.7851 - val_f1: 0.7603\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57055 to 0.55051, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres.h5\n",
      "Epoch 6/100\n",
      "3756/3756 [==============================] - 87s 23ms/step - loss: 0.3978 - acc: 0.8517 - f1: 0.8495 - val_loss: 0.5536 - val_acc: 0.8025 - val_f1: 0.7855\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.55051\n",
      "Epoch 7/100\n",
      "3756/3756 [==============================] - 85s 23ms/step - loss: 0.3732 - acc: 0.8613 - f1: 0.8618 - val_loss: 0.5459 - val_acc: 0.7888 - val_f1: 0.7724\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.55051 to 0.54588, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres.h5\n",
      "Epoch 8/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.3394 - acc: 0.8757 - f1: 0.8749 - val_loss: 0.5498 - val_acc: 0.8000 - val_f1: 0.7885\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.54588\n",
      "Epoch 9/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.3088 - acc: 0.8884 - f1: 0.8866 - val_loss: 0.6286 - val_acc: 0.8000 - val_f1: 0.7990\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.54588\n",
      "Epoch 10/100\n",
      "3756/3756 [==============================] - 84s 22ms/step - loss: 0.2920 - acc: 0.8932 - f1: 0.8923 - val_loss: 0.5910 - val_acc: 0.7963 - val_f1: 0.7814\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.54588\n",
      "Epoch 11/100\n",
      "3756/3756 [==============================] - 84s 22ms/step - loss: 0.2656 - acc: 0.9073 - f1: 0.9065 - val_loss: 0.6224 - val_acc: 0.7950 - val_f1: 0.7830\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.54588\n",
      "Epoch 12/100\n",
      "3756/3756 [==============================] - 84s 22ms/step - loss: 0.2414 - acc: 0.9105 - f1: 0.9109 - val_loss: 0.6567 - val_acc: 0.7727 - val_f1: 0.7618\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.54588\n",
      "Epoch 13/100\n",
      "3756/3756 [==============================] - 84s 22ms/step - loss: 0.2244 - acc: 0.9153 - f1: 0.9157 - val_loss: 0.6957 - val_acc: 0.7901 - val_f1: 0.7793\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.54588\n",
      "Epoch 14/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.2108 - acc: 0.9223 - f1: 0.9216 - val_loss: 0.7482 - val_acc: 0.7677 - val_f1: 0.7652\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.54588\n",
      "Epoch 15/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.2006 - acc: 0.9342 - f1: 0.9340 - val_loss: 0.7000 - val_acc: 0.7826 - val_f1: 0.7850\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.54588\n",
      "Epoch 16/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.1803 - acc: 0.9385 - f1: 0.9388 - val_loss: 0.8235 - val_acc: 0.7590 - val_f1: 0.7481\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.54588\n",
      "Epoch 17/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.1677 - acc: 0.9420 - f1: 0.9415 - val_loss: 0.8201 - val_acc: 0.7503 - val_f1: 0.7522\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.54588\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_bilstm_unres = model_bilstm_unres.fit(x_train, y_train, batch_size=12, epochs=100,\n",
    "                                            validation_data=(x_val, y_val), callbacks=callbacks_unres, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8iJGZgzosgCP",
    "outputId": "fd337103-1b03-46ad-e8c2-c8f239600d7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8145 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "8145/8145 [==============================] - 185s 23ms/step - loss: 1.0306 - acc: 0.4653 - f1: 0.3174 - val_loss: 0.8370 - val_acc: 0.6547 - val_f1: 0.5342\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.83699, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_res.h5\n",
      "Epoch 2/100\n",
      "8145/8145 [==============================] - 183s 23ms/step - loss: 0.9061 - acc: 0.5599 - f1: 0.4954 - val_loss: 0.7982 - val_acc: 0.6832 - val_f1: 0.6132\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.83699 to 0.79819, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_res.h5\n",
      "Epoch 3/100\n",
      "8145/8145 [==============================] - 182s 22ms/step - loss: 0.8312 - acc: 0.6180 - f1: 0.5755 - val_loss: 0.8145 - val_acc: 0.6522 - val_f1: 0.6321\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.79819\n",
      "Epoch 4/100\n",
      "8145/8145 [==============================] - 182s 22ms/step - loss: 0.7640 - acc: 0.6546 - f1: 0.6304 - val_loss: 0.7399 - val_acc: 0.6832 - val_f1: 0.6787\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.79819 to 0.73995, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_res.h5\n",
      "Epoch 5/100\n",
      "8145/8145 [==============================] - 183s 22ms/step - loss: 0.7007 - acc: 0.6952 - f1: 0.6758 - val_loss: 0.8532 - val_acc: 0.6696 - val_f1: 0.6618\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.73995\n",
      "Epoch 6/100\n",
      "8145/8145 [==============================] - 182s 22ms/step - loss: 0.6465 - acc: 0.7184 - f1: 0.7084 - val_loss: 0.8034 - val_acc: 0.6882 - val_f1: 0.6765\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.73995\n",
      "Epoch 7/100\n",
      "8145/8145 [==============================] - 181s 22ms/step - loss: 0.5916 - acc: 0.7537 - f1: 0.7447 - val_loss: 0.7445 - val_acc: 0.7205 - val_f1: 0.7122\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.73995\n",
      "Epoch 8/100\n",
      "8145/8145 [==============================] - 181s 22ms/step - loss: 0.5451 - acc: 0.7692 - f1: 0.7649 - val_loss: 0.8075 - val_acc: 0.7093 - val_f1: 0.7132\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.73995\n",
      "Epoch 9/100\n",
      "8145/8145 [==============================] - 181s 22ms/step - loss: 0.4988 - acc: 0.7914 - f1: 0.7880 - val_loss: 0.9647 - val_acc: 0.6261 - val_f1: 0.6278\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.73995\n",
      "Epoch 10/100\n",
      "8145/8145 [==============================] - 181s 22ms/step - loss: 0.4618 - acc: 0.8130 - f1: 0.8135 - val_loss: 1.0010 - val_acc: 0.6435 - val_f1: 0.6252\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.73995\n",
      "Epoch 11/100\n",
      "8145/8145 [==============================] - 179s 22ms/step - loss: 0.4213 - acc: 0.8318 - f1: 0.8285 - val_loss: 0.8425 - val_acc: 0.6919 - val_f1: 0.6942\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.73995\n",
      "Epoch 12/100\n",
      "8145/8145 [==============================] - 182s 22ms/step - loss: 0.3880 - acc: 0.8485 - f1: 0.8487 - val_loss: 1.0466 - val_acc: 0.6422 - val_f1: 0.6349\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.73995\n",
      "Epoch 13/100\n",
      "8145/8145 [==============================] - 179s 22ms/step - loss: 0.3455 - acc: 0.8638 - f1: 0.8640 - val_loss: 1.0598 - val_acc: 0.6509 - val_f1: 0.6448\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.73995\n",
      "Epoch 14/100\n",
      "8145/8145 [==============================] - 180s 22ms/step - loss: 0.3153 - acc: 0.8796 - f1: 0.8792 - val_loss: 1.0445 - val_acc: 0.6733 - val_f1: 0.6602\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.73995\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_bilstm_res = model_bilstm_res.fit(x_res, y_res, batch_size=12, epochs=100, \n",
    "                                        validation_data=(x_val, y_val), callbacks=callbacks_res, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0YyjYKX9sgUH",
    "outputId": "626cc506-b414-4b5c-ed07-23b883fba466"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4025 samples, validate on 1006 samples\n",
      "Epoch 1/100\n",
      "4025/4025 [==============================] - 1096s 272ms/step - loss: 0.7984 - acc: 0.7215 - f1: 0.7176 - val_loss: 0.7928 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79276, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres_vec.h5\n",
      "Epoch 2/100\n",
      "4025/4025 [==============================] - 1091s 271ms/step - loss: 0.7832 - acc: 0.7277 - f1: 0.7275 - val_loss: 0.7815 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79276 to 0.78146, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres_vec.h5\n",
      "Epoch 3/100\n",
      "4025/4025 [==============================] - 1112s 276ms/step - loss: 0.7892 - acc: 0.7277 - f1: 0.7276 - val_loss: 0.7631 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.78146 to 0.76305, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres_vec.h5\n",
      "Epoch 4/100\n",
      "4025/4025 [==============================] - 1065s 265ms/step - loss: 0.7837 - acc: 0.7277 - f1: 0.7278 - val_loss: 0.7677 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.76305\n",
      "Epoch 5/100\n",
      "4025/4025 [==============================] - 1025s 255ms/step - loss: 0.7816 - acc: 0.7277 - f1: 0.7278 - val_loss: 0.7727 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.76305\n",
      "Epoch 6/100\n",
      "4025/4025 [==============================] - 1045s 260ms/step - loss: 0.7790 - acc: 0.7277 - f1: 0.7272 - val_loss: 0.7619 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.76305 to 0.76190, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres_vec.h5\n",
      "Epoch 7/100\n",
      "4025/4025 [==============================] - 1034s 257ms/step - loss: 0.7823 - acc: 0.7277 - f1: 0.7278 - val_loss: 0.7646 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.76190\n",
      "Epoch 8/100\n",
      "4025/4025 [==============================] - 1131s 281ms/step - loss: 0.7765 - acc: 0.7277 - f1: 0.7279 - val_loss: 0.7792 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.76190\n",
      "Epoch 9/100\n",
      "4025/4025 [==============================] - 1104s 274ms/step - loss: 0.7796 - acc: 0.7277 - f1: 0.7275 - val_loss: 0.7600 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.76190 to 0.75998, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres_vec.h5\n",
      "Epoch 10/100\n",
      "4025/4025 [==============================] - 1116s 277ms/step - loss: 0.7809 - acc: 0.7277 - f1: 0.7276 - val_loss: 0.7604 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.75998\n",
      "Epoch 11/100\n",
      "4025/4025 [==============================] - 1112s 276ms/step - loss: 0.7754 - acc: 0.7277 - f1: 0.7270 - val_loss: 0.7623 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.75998\n",
      "Epoch 12/100\n",
      "4025/4025 [==============================] - 1115s 277ms/step - loss: 0.7787 - acc: 0.7277 - f1: 0.7273 - val_loss: 0.7597 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.75998 to 0.75971, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres_vec.h5\n",
      "Epoch 13/100\n",
      "4025/4025 [==============================] - 1100s 273ms/step - loss: 0.7783 - acc: 0.7277 - f1: 0.7274 - val_loss: 0.7636 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.75971\n",
      "Epoch 14/100\n",
      "4025/4025 [==============================] - 1090s 271ms/step - loss: 0.7780 - acc: 0.7277 - f1: 0.7278 - val_loss: 0.7662 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.75971\n",
      "Epoch 15/100\n",
      "4025/4025 [==============================] - 1052s 261ms/step - loss: 0.7797 - acc: 0.7277 - f1: 0.7280 - val_loss: 0.7724 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.75971\n",
      "Epoch 16/100\n",
      "4025/4025 [==============================] - 1045s 260ms/step - loss: 0.7763 - acc: 0.7277 - f1: 0.7278 - val_loss: 0.7681 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.75971\n",
      "Epoch 17/100\n",
      "4025/4025 [==============================] - 1026s 255ms/step - loss: 0.7730 - acc: 0.7277 - f1: 0.7272 - val_loss: 0.7649 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.75971\n",
      "Epoch 18/100\n",
      "4025/4025 [==============================] - 1036s 257ms/step - loss: 0.7777 - acc: 0.7277 - f1: 0.7279 - val_loss: 0.7697 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.75971\n",
      "Epoch 19/100\n",
      "4025/4025 [==============================] - 1059s 263ms/step - loss: 0.7779 - acc: 0.7277 - f1: 0.7277 - val_loss: 0.7614 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.75971\n",
      "Epoch 20/100\n",
      "4025/4025 [==============================] - 1063s 264ms/step - loss: 0.7790 - acc: 0.7277 - f1: 0.7278 - val_loss: 0.7596 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.75971 to 0.75958, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/LSTM/tesis_model_lstm_unres_vec.h5\n",
      "Epoch 21/100\n",
      "4025/4025 [==============================] - 1053s 262ms/step - loss: 0.7749 - acc: 0.7277 - f1: 0.7276 - val_loss: 0.7669 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.75958\n",
      "Epoch 22/100\n",
      "4025/4025 [==============================] - 1066s 265ms/step - loss: 0.7778 - acc: 0.7277 - f1: 0.7274 - val_loss: 0.7639 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.75958\n",
      "Epoch 23/100\n",
      "4025/4025 [==============================] - 1060s 263ms/step - loss: 0.7763 - acc: 0.7277 - f1: 0.7277 - val_loss: 0.7599 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.75958\n",
      "Epoch 24/100\n",
      "4025/4025 [==============================] - 1058s 263ms/step - loss: 0.7788 - acc: 0.7277 - f1: 0.7273 - val_loss: 0.7600 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.75958\n",
      "Epoch 25/100\n",
      "4025/4025 [==============================] - 1025s 255ms/step - loss: 0.7761 - acc: 0.7277 - f1: 0.7274 - val_loss: 0.7600 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.75958\n",
      "Epoch 26/100\n",
      "4025/4025 [==============================] - 1105s 275ms/step - loss: 0.7761 - acc: 0.7277 - f1: 0.7278 - val_loss: 0.7680 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.75958\n",
      "Epoch 27/100\n",
      "4025/4025 [==============================] - 1050s 261ms/step - loss: 0.7777 - acc: 0.7277 - f1: 0.7278 - val_loss: 0.7640 - val_acc: 0.7276 - val_f1: 0.7276\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.75958\n",
      "Epoch 28/100\n",
      "3660/4025 [==========================>...] - ETA: 1:36 - loss: 0.7708 - acc: 0.7303 - f1: 0.7301"
     ]
    }
   ],
   "source": [
    "tesis_model_lstm_unres_vec = model_lstm_unres_vec.fit(x2train_vec, y2train, batch_size=12, epochs=100, \n",
    "                                                    validation_data=(x2val_vec, y2val), callbacks=callbacks_unres_vec, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfNdk7KXsglS"
   },
   "outputs": [],
   "source": [
    "tesis_model_lstm_res_vec = model_lstm_res_vec.fit(x2res, y2res, batch_size=32, epochs=100, \n",
    "                                                validation_data=(x2val_vec, y2val), callbacks=callbacks_res_vec, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1DN1kGds2Xd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QHJBxeRCrEn"
   },
   "source": [
    "### **CNN LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "N27Gi8brQxgd",
    "outputId": "75cd8299-d232-421c-e354-5d18cf94e2a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-self-attention\n",
      "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.3.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
      "Building wheels for collected packages: keras-self-attention\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=1f775888026d2157a966503a3e30374057d5e189932aad5c6e185204c910a33d\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
      "Successfully built keras-self-attention\n",
      "Installing collected packages: keras-self-attention\n",
      "Successfully installed keras-self-attention-0.46.0\n"
     ]
    }
   ],
   "source": [
    "pip install keras-self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84y0G-VjQ3vv"
   },
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jWPXQiP0Vr1P"
   },
   "source": [
    "##### CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5L3d8MvfOb1R",
    "outputId": "d3965d29-0a95-4756-e78b-095aa26660e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model CNN LSTM UNRES\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 300)      1905000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 50, 300)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 50, 128)      38528       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 50, 128)      76928       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 50, 128)      115328      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50, 128)      512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 50, 128)      512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 50, 128)      512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 128)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 2, 128)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 3, 128)       0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 128)       0           max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 6, 128)       131584      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_1 (SeqSelfAt (None, 6, 128)       33025       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 768)          0           seq_self_attention_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            2307        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,304,236\n",
      "Trainable params: 2,303,468\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "Model CNN LSTM RES\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 300)      1905000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 50, 300)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 50, 128)      38528       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 50, 128)      76928       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 50, 128)      115328      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50, 128)      512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 50, 128)      512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 50, 128)      512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 128)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 2, 128)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 3, 128)       0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 128)       0           max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 6, 128)       131584      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_1 (SeqSelfAt (None, 6, 128)       33025       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 768)          0           seq_self_attention_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            2307        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,304,236\n",
      "Trainable params: 2,303,468\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "#maxlen_vec = td\n",
    "num_filters = 128\n",
    "border_mode = 'same'\n",
    "filter_length = 5\n",
    "dropout_rate = 0.5\n",
    "lstm_cell = 128\n",
    "fc_cell = 128\n",
    "pool_length = 2\n",
    "kernel_sizes = [1,2,3]\n",
    "\n",
    "\n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "#emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "#                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "s_drop = SpatialDropout1D(dropout_rate)(embedding)\n",
    "#conv = Conv1D(num_filters, kernel_size=filter_length, activation = 'relu')(s_drop) #padding=border_mode,\n",
    "#conv = BatchNormalization()(conv)\n",
    "#maxpool = MaxPooling1D(pool_size=pool_length)(conv)\n",
    "\n",
    "conv_0 = Conv1D(num_filters, kernel_sizes[0], padding=border_mode, activation = 'relu')(s_drop) #padding=border_mode,\n",
    "conv_0 = BatchNormalization()(conv_0)\n",
    "maxpool_0 = MaxPooling1D(pool_size = (maxlen - kernel_sizes[0] + 1), strides=1, padding='valid')(conv_0)\n",
    "    \n",
    "conv_1 = Conv1D(num_filters, kernel_sizes[1], padding=border_mode, activation = 'relu')(s_drop) #padding=border_mode,\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "maxpool_1 = MaxPooling1D(pool_size = (maxlen - kernel_sizes[1] + 1), strides=1, padding='valid')(conv_1)\n",
    "    \n",
    "conv_2 = Conv1D(num_filters, kernel_sizes[2], padding=border_mode, activation = 'relu')(s_drop) #padding=border_mode,\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "maxpool_2 = MaxPooling1D(pool_size = (maxlen - kernel_sizes[2] + 1), strides=1, padding='valid')(conv_2)\n",
    "    \n",
    "merged = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "lstm = LSTM((lstm_cell), return_sequences=True)(merged)\n",
    "seq = SeqSelfAttention(units=lstm_cell)(lstm)\n",
    "flatten = Flatten()(seq)\n",
    "\n",
    "\n",
    "#dense1 = Dense(fc_cell*2)(flatten)\n",
    "#lstm = Bidirectional(LSTM((lstm_cell), return_sequences=False))(dense1)\n",
    "drop = Dropout(dropout_rate)(flatten)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "\n",
    "model_cnn_lstm_unres = Model(inputs, output)\n",
    "model_cnn_lstm_res = Model(inputs, output)\n",
    "\n",
    "model_cnn_lstm_unres.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1])\n",
    "model_cnn_lstm_res.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1])\n",
    "\n",
    "callbacks_unres = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_unres2.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "callbacks_res = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                 ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_res2.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "print('Model CNN LSTM UNRES')\n",
    "model_cnn_lstm_unres.summary()\n",
    "print('Model CNN LSTM RES')\n",
    "model_cnn_lstm_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c0bDbH0e42Uv",
    "outputId": "151c4c8c-1cc2-4145-eb0f-58a3625f3b22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3756 samples, validate on 805 samples\n",
      "Epoch 1/50\n",
      "3756/3756 [==============================] - 36s 10ms/step - loss: 0.7695 - acc: 0.7181 - f1: 0.6997 - val_loss: 1.0481 - val_acc: 0.7280 - val_f1: 0.7316\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.04806, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_unres2.h5\n",
      "Epoch 2/50\n",
      "3756/3756 [==============================] - 35s 9ms/step - loss: 0.6441 - acc: 0.7716 - f1: 0.7605 - val_loss: 0.6568 - val_acc: 0.8000 - val_f1: 0.8028\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.04806 to 0.65680, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_unres2.h5\n",
      "Epoch 3/50\n",
      "3756/3756 [==============================] - 37s 10ms/step - loss: 0.5661 - acc: 0.7854 - f1: 0.7801 - val_loss: 0.5902 - val_acc: 0.8062 - val_f1: 0.8119\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65680 to 0.59016, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_unres2.h5\n",
      "Epoch 4/50\n",
      "3756/3756 [==============================] - 35s 9ms/step - loss: 0.5159 - acc: 0.8072 - f1: 0.8051 - val_loss: 0.5558 - val_acc: 0.8161 - val_f1: 0.8182\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59016 to 0.55577, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_unres2.h5\n",
      "Epoch 5/50\n",
      "3756/3756 [==============================] - 30s 8ms/step - loss: 0.4780 - acc: 0.8341 - f1: 0.8282 - val_loss: 0.5448 - val_acc: 0.8112 - val_f1: 0.8130\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55577 to 0.54476, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_unres2.h5\n",
      "Epoch 6/50\n",
      "3756/3756 [==============================] - 30s 8ms/step - loss: 0.4337 - acc: 0.8453 - f1: 0.8425 - val_loss: 0.5246 - val_acc: 0.8099 - val_f1: 0.8118\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54476 to 0.52461, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_unres2.h5\n",
      "Epoch 7/50\n",
      "3756/3756 [==============================] - 34s 9ms/step - loss: 0.4058 - acc: 0.8522 - f1: 0.8479 - val_loss: 0.5516 - val_acc: 0.8099 - val_f1: 0.8092\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.52461\n",
      "Epoch 8/50\n",
      "3756/3756 [==============================] - 30s 8ms/step - loss: 0.3696 - acc: 0.8671 - f1: 0.8647 - val_loss: 0.5639 - val_acc: 0.8211 - val_f1: 0.8210\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.52461\n",
      "Epoch 9/50\n",
      "3756/3756 [==============================] - 27s 7ms/step - loss: 0.3307 - acc: 0.8858 - f1: 0.8848 - val_loss: 0.5777 - val_acc: 0.8149 - val_f1: 0.8200\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.52461\n",
      "Epoch 10/50\n",
      "3756/3756 [==============================] - 30s 8ms/step - loss: 0.3131 - acc: 0.8940 - f1: 0.8934 - val_loss: 0.7265 - val_acc: 0.8075 - val_f1: 0.8113\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.52461\n",
      "Epoch 11/50\n",
      "3756/3756 [==============================] - 30s 8ms/step - loss: 0.2883 - acc: 0.9015 - f1: 0.9004 - val_loss: 0.5969 - val_acc: 0.7876 - val_f1: 0.7909\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.52461\n",
      "Epoch 12/50\n",
      "3756/3756 [==============================] - 28s 7ms/step - loss: 0.2600 - acc: 0.9156 - f1: 0.9148 - val_loss: 0.7415 - val_acc: 0.7938 - val_f1: 0.7973\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.52461\n",
      "Epoch 13/50\n",
      "3756/3756 [==============================] - 29s 8ms/step - loss: 0.2573 - acc: 0.9188 - f1: 0.9189 - val_loss: 0.6798 - val_acc: 0.7913 - val_f1: 0.7947\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.52461\n",
      "Epoch 14/50\n",
      "3756/3756 [==============================] - 28s 7ms/step - loss: 0.2167 - acc: 0.9255 - f1: 0.9244 - val_loss: 0.7777 - val_acc: 0.7863 - val_f1: 0.7904\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.52461\n",
      "Epoch 15/50\n",
      "3756/3756 [==============================] - 28s 7ms/step - loss: 0.2070 - acc: 0.9332 - f1: 0.9330 - val_loss: 0.7554 - val_acc: 0.8025 - val_f1: 0.8044\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.52461\n",
      "Epoch 16/50\n",
      "3756/3756 [==============================] - 31s 8ms/step - loss: 0.1954 - acc: 0.9369 - f1: 0.9366 - val_loss: 0.8397 - val_acc: 0.8037 - val_f1: 0.8054\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.52461\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_cnn_lstm_unres = model_cnn_lstm_unres.fit(x_train, y_train, batch_size=12, epochs=50,\n",
    "                                            validation_data=(x_val, y_val), callbacks=callbacks_unres, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zWY2t1QB42gc",
    "outputId": "bac7a0cb-974b-47a9-936a-819c9f681772"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8145 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "8145/8145 [==============================] - 60s 7ms/step - loss: 1.0399 - acc: 0.4438 - f1: 0.2704 - val_loss: 0.9995 - val_acc: 0.4758 - val_f1: 0.4275\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.99953, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_res.h5\n",
      "Epoch 2/100\n",
      "8145/8145 [==============================] - 60s 7ms/step - loss: 0.9619 - acc: 0.5012 - f1: 0.3819 - val_loss: 0.9528 - val_acc: 0.5739 - val_f1: 0.4925\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.99953 to 0.95285, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_res.h5\n",
      "Epoch 3/100\n",
      "8145/8145 [==============================] - 61s 8ms/step - loss: 0.9153 - acc: 0.5405 - f1: 0.4550 - val_loss: 0.7605 - val_acc: 0.7093 - val_f1: 0.6892\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.95285 to 0.76047, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_res.h5\n",
      "Epoch 4/100\n",
      "8145/8145 [==============================] - 61s 8ms/step - loss: 0.8587 - acc: 0.5789 - f1: 0.5193 - val_loss: 0.7447 - val_acc: 0.7155 - val_f1: 0.7087\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.76047 to 0.74467, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_res.h5\n",
      "Epoch 5/100\n",
      "8145/8145 [==============================] - 61s 7ms/step - loss: 0.8030 - acc: 0.6250 - f1: 0.5928 - val_loss: 0.9101 - val_acc: 0.6273 - val_f1: 0.6094\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.74467\n",
      "Epoch 6/100\n",
      "8145/8145 [==============================] - 61s 7ms/step - loss: 0.7629 - acc: 0.6533 - f1: 0.6289 - val_loss: 0.7351 - val_acc: 0.7491 - val_f1: 0.7367\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.74467 to 0.73507, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_res.h5\n",
      "Epoch 7/100\n",
      "8145/8145 [==============================] - 61s 7ms/step - loss: 0.6922 - acc: 0.6948 - f1: 0.6805 - val_loss: 0.7918 - val_acc: 0.6981 - val_f1: 0.6886\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.73507\n",
      "Epoch 8/100\n",
      "8145/8145 [==============================] - 61s 7ms/step - loss: 0.6305 - acc: 0.7343 - f1: 0.7216 - val_loss: 0.9617 - val_acc: 0.6720 - val_f1: 0.6732\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.73507\n",
      "Epoch 9/100\n",
      "8145/8145 [==============================] - 60s 7ms/step - loss: 0.5856 - acc: 0.7548 - f1: 0.7485 - val_loss: 0.8785 - val_acc: 0.7143 - val_f1: 0.7105\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.73507\n",
      "Epoch 10/100\n",
      "8145/8145 [==============================] - 60s 7ms/step - loss: 0.5395 - acc: 0.7827 - f1: 0.7772 - val_loss: 0.9157 - val_acc: 0.6646 - val_f1: 0.6573\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.73507\n",
      "Epoch 11/100\n",
      "8145/8145 [==============================] - 61s 7ms/step - loss: 0.5007 - acc: 0.7993 - f1: 0.7956 - val_loss: 1.0916 - val_acc: 0.6584 - val_f1: 0.6612\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.73507\n",
      "Epoch 12/100\n",
      "8145/8145 [==============================] - 61s 7ms/step - loss: 0.4597 - acc: 0.8201 - f1: 0.8159 - val_loss: 1.1444 - val_acc: 0.6137 - val_f1: 0.6037\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.73507\n",
      "Epoch 13/100\n",
      "8145/8145 [==============================] - 61s 7ms/step - loss: 0.4205 - acc: 0.8379 - f1: 0.8344 - val_loss: 1.1694 - val_acc: 0.6534 - val_f1: 0.6369\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.73507\n",
      "Epoch 14/100\n",
      "8145/8145 [==============================] - 61s 7ms/step - loss: 0.3967 - acc: 0.8517 - f1: 0.8505 - val_loss: 1.0491 - val_acc: 0.6944 - val_f1: 0.6983\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.73507\n",
      "Epoch 15/100\n",
      "8145/8145 [==============================] - 61s 7ms/step - loss: 0.3685 - acc: 0.8607 - f1: 0.8599 - val_loss: 1.1221 - val_acc: 0.6634 - val_f1: 0.6650\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.73507\n",
      "Epoch 16/100\n",
      "8145/8145 [==============================] - 61s 7ms/step - loss: 0.3498 - acc: 0.8722 - f1: 0.8710 - val_loss: 1.1911 - val_acc: 0.6559 - val_f1: 0.6456\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.73507\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_cnn_lstm_res = model_cnn_lstm_res.fit(x_res, y_res, batch_size=12, epochs=50,\n",
    "                                            validation_data=(x_val, y_val), callbacks=callbacks_res, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KJ_incpYgwu-",
    "outputId": "29f35c8d-24c9-4ed3-9175-f56891c008f9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model_cnn_lstm_unres, to_file='/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_unres3.png', \n",
    "           show_shapes=False, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aoR1T2Az4z6Y"
   },
   "outputs": [],
   "source": [
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "maxlen_vec = td\n",
    "num_filters = 128\n",
    "border_mode = 'same'\n",
    "filter_length = 3\n",
    "dropout_rate = 0.5\n",
    "lstm_cell = 128\n",
    "fc_cell = 128\n",
    "pool_length = 2\n",
    "\n",
    "\n",
    "inputs = Input(shape=(maxlen_vec,))\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "#embedding = embedding_layer(inputs)\n",
    "\n",
    "emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "s_drop = SpatialDropout1D(dropout_rate)(emb2)\n",
    "conv = Conv1D(num_filters, kernel_size=filter_length, padding=border_mode, activation = 'relu')(s_drop)\n",
    "conv = BatchNormalization()(conv)\n",
    "maxpool = MaxPooling1D(pool_size=pool_length)(conv)\n",
    "\n",
    "lstm = LSTM((lstm_cell), return_sequences=False)(maxpool)\n",
    "dense1 = Dense(fc_cell*2)(lstm)\n",
    "drop = Dropout(dropout_rate)(dense1)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "\n",
    "model_cnn_lstm_unres_vec = Model(inputs, output)\n",
    "model_cnn_lstm_res_vec = Model(inputs, output)\n",
    "\n",
    "model_cnn_lstm_unres_vec.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1])\n",
    "model_cnn_lstm_res_vec.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc', f1])\n",
    "\n",
    "callbacks_unres_vec = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_unres_vec.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "callbacks_res_vec = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                 ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_lstm_res_vec.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "print('Model CNN LSTM UNRES VEC')\n",
    "model_cnn_lstm_unres_vec.summary()\n",
    "print('Model CNN LSTM RES VEC')\n",
    "model_cnn_lstm_res_vec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Es2fFrjM42ye"
   },
   "outputs": [],
   "source": [
    "tesis_model_cnn_lstm_unres_vec = model_cnn_lstm_unres_vec.fit(x2train_vec, y2train, batch_size=32, epochs=100, \n",
    "                                                    validation_data=(x2val_vec, y2val), callbacks=callbacks_unres_vec, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2zHkKPH43A_"
   },
   "outputs": [],
   "source": [
    "tesis_model_cnn_lstm_res_vec = model_cnn_lstm_res_vec.fit(x2res, y2res, batch_size=32, epochs=100, \n",
    "                                                    validation_data=(x2val_vec, y2val), callbacks=callbacks_res_vec, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sr6Geij243PP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4joQNlpEVicX"
   },
   "source": [
    "##### CNN BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RvY6_r2043uz",
    "outputId": "2eaf0304-15ff-403e-d07c-aa7ccf0e29c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model CNN BiLSTM UNRES\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_21 (Embedding)     (None, 50, 300)           1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_15 (Spatia (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 50, 128)           192128    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 50, 128)           512       \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 50, 128)           131584    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_3 (SeqSel (None, 50, 128)           33025     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 256)               1638656   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 3,901,676\n",
      "Trainable params: 3,901,420\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Model CNN BiLSTM RES\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_21 (Embedding)     (None, 50, 300)           1905000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_15 (Spatia (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 50, 128)           192128    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 50, 128)           512       \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 50, 128)           131584    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_3 (SeqSel (None, 50, 128)           33025     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 256)               1638656   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 3,901,676\n",
      "Trainable params: 3,901,420\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "#maxlen_vec = td\n",
    "num_filters = 128\n",
    "border_mode = 'same'\n",
    "filter_length = 5\n",
    "dropout_rate = 0.5\n",
    "lstm_cell = 128\n",
    "fc_cell = 128\n",
    "pool_length = 2\n",
    "kernel_sizes = [5,5,5]\n",
    "\n",
    "\n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "#emb2 = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
    "#                 weights=[embedding_matrix], trainable=True)(inputs)\n",
    "\n",
    "s_drop = SpatialDropout1D(dropout_rate)(embedding)\n",
    "#conv = Conv1D(num_filters, kernel_size=filter_length, activation = 'relu')(s_drop) #padding=border_mode,\n",
    "#conv = BatchNormalization()(conv)\n",
    "#maxpool = MaxPooling1D(pool_size=pool_length)(conv)\n",
    "\n",
    "\n",
    "\n",
    "conv = Conv1D(num_filters, kernel_sizes[0], padding=border_mode, activation = 'relu')(s_drop) #padding=border_mode,\n",
    "conv = BatchNormalization()(conv)\n",
    "maxpool = MaxPooling1D(pool_size = (maxlen - kernel_sizes[0] + 1), strides=1, padding='valid')(conv)\n",
    "    \n",
    "conv = Conv1D(num_filters, kernel_sizes[1], padding=border_mode, activation = 'relu')(s_drop) #padding=border_mode,\n",
    "conv = BatchNormalization()(conv)\n",
    "maxpool = MaxPooling1D(pool_size = (maxlen - kernel_sizes[1] + 1), strides=1, padding='valid')(conv)\n",
    "    \n",
    "conv = Conv1D(num_filters, kernel_sizes[2], padding=border_mode, activation = 'relu')(s_drop) #padding=border_mode,\n",
    "conv = BatchNormalization()(conv)\n",
    "maxpool = MaxPooling1D(pool_size = (maxlen - kernel_sizes[2] + 1), strides=1, padding='valid')(conv)\n",
    "    \n",
    "#merged = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "lstm = Bidirectional(LSTM((lstm_cell), return_sequences=True))(conv)\n",
    "seq = SeqSelfAttention(units=lstm_cell)(lstm)\n",
    "flatten = Flatten()(seq)\n",
    "\n",
    "\n",
    "dense1 = Dense(fc_cell*2)(flatten)\n",
    "#lstm = Bidirectional(LSTM((lstm_cell), return_sequences=False))(dense1)\n",
    "drop = Dropout(dropout_rate)(dense1)\n",
    "output = Dense(units=num_classes, activation='softmax')(drop)\n",
    "\n",
    "\n",
    "model_cnn_bilstm_unres = Model(inputs, output)\n",
    "model_cnn_bilstm_res = Model(inputs, output)\n",
    "\n",
    "model_cnn_bilstm_unres.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1])\n",
    "model_cnn_bilstm_res.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['acc', f1])\n",
    "\n",
    "callbacks_unres = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                   ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_bilstm_unres.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "callbacks_res = [EarlyStopping(monitor='val_loss', verbose= 1, patience=10, mode='auto'), \n",
    "                 ModelCheckpoint('/content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_bilstm_res.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'), \n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)]\n",
    "\n",
    "print('Model CNN BiLSTM UNRES')\n",
    "model_cnn_lstm_unres.summary()\n",
    "print('Model CNN BiLSTM RES')\n",
    "model_cnn_lstm_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gpsg2azB42sF",
    "outputId": "cda0a205-5716-45ea-b1a8-d93c44da660c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3756 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "3756/3756 [==============================] - 88s 23ms/step - loss: 2.1310 - acc: 0.6368 - f1: 0.6171 - val_loss: 0.7634 - val_acc: 0.7280 - val_f1: 0.6823\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76337, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_bilstm_unres.h5\n",
      "Epoch 2/100\n",
      "3756/3756 [==============================] - 87s 23ms/step - loss: 0.7195 - acc: 0.7441 - f1: 0.7359 - val_loss: 0.6571 - val_acc: 0.7478 - val_f1: 0.7487\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76337 to 0.65709, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_bilstm_unres.h5\n",
      "Epoch 3/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.6329 - acc: 0.7766 - f1: 0.7731 - val_loss: 0.5987 - val_acc: 0.7851 - val_f1: 0.7732\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65709 to 0.59869, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_bilstm_unres.h5\n",
      "Epoch 4/100\n",
      "3756/3756 [==============================] - 87s 23ms/step - loss: 0.5789 - acc: 0.8056 - f1: 0.8018 - val_loss: 0.6066 - val_acc: 0.7814 - val_f1: 0.7681\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59869\n",
      "Epoch 5/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.5164 - acc: 0.8219 - f1: 0.8205 - val_loss: 0.6103 - val_acc: 0.7727 - val_f1: 0.7765\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.59869\n",
      "Epoch 6/100\n",
      "3756/3756 [==============================] - 87s 23ms/step - loss: 0.4703 - acc: 0.8395 - f1: 0.8385 - val_loss: 0.5893 - val_acc: 0.8062 - val_f1: 0.7964\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.59869 to 0.58929, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_bilstm_unres.h5\n",
      "Epoch 7/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.4299 - acc: 0.8549 - f1: 0.8545 - val_loss: 0.6657 - val_acc: 0.7851 - val_f1: 0.7743\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.58929\n",
      "Epoch 8/100\n",
      "3756/3756 [==============================] - 87s 23ms/step - loss: 0.3917 - acc: 0.8749 - f1: 0.8738 - val_loss: 0.6253 - val_acc: 0.7975 - val_f1: 0.7834\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.58929\n",
      "Epoch 9/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.3562 - acc: 0.8791 - f1: 0.8777 - val_loss: 0.6780 - val_acc: 0.7938 - val_f1: 0.7954\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.58929\n",
      "Epoch 10/100\n",
      "3756/3756 [==============================] - 87s 23ms/step - loss: 0.3484 - acc: 0.8943 - f1: 0.8945 - val_loss: 0.8033 - val_acc: 0.7901 - val_f1: 0.7935\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.58929\n",
      "Epoch 11/100\n",
      "3756/3756 [==============================] - 88s 23ms/step - loss: 0.3275 - acc: 0.8988 - f1: 0.8978 - val_loss: 0.6685 - val_acc: 0.7988 - val_f1: 0.7975\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.58929\n",
      "Epoch 12/100\n",
      "3756/3756 [==============================] - 87s 23ms/step - loss: 0.3073 - acc: 0.9097 - f1: 0.9097 - val_loss: 0.9085 - val_acc: 0.7988 - val_f1: 0.8022\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.58929\n",
      "Epoch 13/100\n",
      "3756/3756 [==============================] - 86s 23ms/step - loss: 0.2759 - acc: 0.9167 - f1: 0.9151 - val_loss: 0.8309 - val_acc: 0.8012 - val_f1: 0.8042\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.58929\n",
      "Epoch 14/100\n",
      "3756/3756 [==============================] - 87s 23ms/step - loss: 0.3004 - acc: 0.9156 - f1: 0.9156 - val_loss: 0.8736 - val_acc: 0.7789 - val_f1: 0.7846\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.58929\n",
      "Epoch 15/100\n",
      "3756/3756 [==============================] - 88s 23ms/step - loss: 0.2662 - acc: 0.9225 - f1: 0.9222 - val_loss: 0.9149 - val_acc: 0.7801 - val_f1: 0.7707\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.58929\n",
      "Epoch 16/100\n",
      "3756/3756 [==============================] - 88s 23ms/step - loss: 0.2418 - acc: 0.9308 - f1: 0.9306 - val_loss: 0.9284 - val_acc: 0.7950 - val_f1: 0.7827\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.58929\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_cnn_bilstm_unres = model_cnn_bilstm_unres.fit(x_train, y_train, batch_size=12, epochs=100, \n",
    "                                                      validation_data=(x_val, y_val), callbacks=callbacks_unres, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mfOCCdVqWBRG",
    "outputId": "0dc15fa0-3c70-4a2c-a36e-b4a0bd3aca92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8145 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "8145/8145 [==============================] - 162s 20ms/step - loss: 0.9439 - acc: 0.5538 - f1: 0.4712 - val_loss: 0.9141 - val_acc: 0.6497 - val_f1: 0.5568\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.91406, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_bilstm_res.h5\n",
      "Epoch 2/100\n",
      "8145/8145 [==============================] - 161s 20ms/step - loss: 0.8536 - acc: 0.6106 - f1: 0.5589 - val_loss: 0.8099 - val_acc: 0.7230 - val_f1: 0.6608\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.91406 to 0.80994, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_bilstm_res.h5\n",
      "Epoch 3/100\n",
      "8145/8145 [==============================] - 161s 20ms/step - loss: 0.7958 - acc: 0.6394 - f1: 0.6035 - val_loss: 0.8067 - val_acc: 0.7006 - val_f1: 0.6557\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.80994 to 0.80672, saving model to /content/drive/My Drive/Tesis/Hasil NN Tesis/CNN LSTM/tesis_model_cnn_bilstm_res.h5\n",
      "Epoch 4/100\n",
      "8145/8145 [==============================] - 161s 20ms/step - loss: 0.7681 - acc: 0.6566 - f1: 0.6320 - val_loss: 0.8521 - val_acc: 0.6708 - val_f1: 0.6293\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.80672\n",
      "Epoch 5/100\n",
      "8145/8145 [==============================] - 160s 20ms/step - loss: 0.7322 - acc: 0.6814 - f1: 0.6602 - val_loss: 0.8367 - val_acc: 0.7006 - val_f1: 0.6701\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.80672\n",
      "Epoch 6/100\n",
      "8145/8145 [==============================] - 160s 20ms/step - loss: 0.6839 - acc: 0.7024 - f1: 0.6859 - val_loss: 0.8816 - val_acc: 0.6894 - val_f1: 0.6592\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.80672\n",
      "Epoch 7/100\n",
      "8145/8145 [==============================] - 160s 20ms/step - loss: 0.6569 - acc: 0.7164 - f1: 0.7042 - val_loss: 1.0142 - val_acc: 0.6634 - val_f1: 0.6372\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.80672\n",
      "Epoch 8/100\n",
      "8145/8145 [==============================] - 160s 20ms/step - loss: 0.6400 - acc: 0.7337 - f1: 0.7222 - val_loss: 1.0351 - val_acc: 0.6298 - val_f1: 0.6088\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.80672\n",
      "Epoch 9/100\n",
      "8145/8145 [==============================] - 160s 20ms/step - loss: 0.6026 - acc: 0.7495 - f1: 0.7415 - val_loss: 1.0352 - val_acc: 0.6335 - val_f1: 0.6190\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.80672\n",
      "Epoch 10/100\n",
      "8145/8145 [==============================] - 160s 20ms/step - loss: 0.5607 - acc: 0.7699 - f1: 0.7647 - val_loss: 1.1260 - val_acc: 0.6087 - val_f1: 0.5903\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.80672\n",
      "Epoch 11/100\n",
      "8145/8145 [==============================] - 161s 20ms/step - loss: 0.5430 - acc: 0.7801 - f1: 0.7747 - val_loss: 1.2641 - val_acc: 0.6559 - val_f1: 0.6477\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.80672\n",
      "Epoch 12/100\n",
      "8145/8145 [==============================] - 160s 20ms/step - loss: 0.5182 - acc: 0.7934 - f1: 0.7888 - val_loss: 1.4062 - val_acc: 0.6149 - val_f1: 0.5919\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.80672\n",
      "Epoch 13/100\n",
      "8145/8145 [==============================] - 161s 20ms/step - loss: 0.4989 - acc: 0.8025 - f1: 0.8017 - val_loss: 1.0826 - val_acc: 0.6646 - val_f1: 0.6365\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.80672\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "tesis_model_cnn_bilstm_res = model_cnn_bilstm_res.fit(x_res, y_res, batch_size=12, epochs=100,\n",
    "                                            validation_data=(x_val, y_val), callbacks=callbacks_res, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXTczluqBeqy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "O2vAZuaSb4qv",
    "4oK_DLvUluim",
    "KxJeqfNhPsAC",
    "M4I5XAkDuMcs",
    "kdAMjcSrKLd1"
   ],
   "name": "FINAL TESIS SUMMARY",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
